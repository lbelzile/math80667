# Complete factorial designs

We next consider experiments and designs in which there are multiple factors being manipulated by the experimenter simultaneously. 

Before jumping into the statistical analysis, let us discuss briefly some examples that will be covered in the sequel.

:::{ .example name="Replication of 'Precision of the anchor influences the amount of adjustment'"}


We consider data from a replication by Chandler (2016) of Study 4a of Janiszewski and Uy (2008). Both studies measured the amount of adjustment when presented with vague or precise range of value for objects, with potential encouragement for adjusting more the value.

@Chandler:2016 described the effect in the replication report:

> Janiszewski and Uy (2008) conceptualized peopleâ€™s attempt to adjust following presentation of an anchor as movement along a subjective representation scale by a certain number of units. Precise numbers (e.g. $9.99) imply a finer-resolution scale than round numbers (e.g. $10). Consequently, adjustment along a subjectively finer resolution scale will result in less objective adjustment than adjustment by the same number of units along a subjectively coarse resolution scale.

The experiment is a 2 by 2 factorial design (two-way ANOVA) with `anchor` (either round or precise) and `magnitude` (`0` for small, `1` for big adjustment) as experimental factors. A total of 120 students were recruited and randomly assigned to one of the four experimental sub-condition, for a total of 30 observations per subgroup (`anchor`, `magnitude`). The response variable is `majust`, the mean adjustment for the price estimate of the item.

:::



:::{.example name="Psychological ownership of borrowed money"}

Supplemental Study 5 from @Sharma.Tully.Cryder:2021 checks the psychological perception of borrowing money depending on the label. The authors conducted a 2 by 2 between-subject comparison (two-way ANOVA) varying the type of debt (whether the money was advertised as credit or loan) and the type of purchase the latter would be used for (discretionary spending or need). The response is the average of the likelihood and interest in the product, both measured using a 9 point Likert scale from 1 to 9.


:::

:::{.example name="Spatial orientation shrinks and expands psychological distance"}

@Maglio.Polman:2014 measured the subjective distance on travel based on the direction of travel. They conducted an experiment in the Toronto subway green line, asking commuters from Bay station to answer the question "How far away does the [name] station feel to you?" using a 7 point Likert scale ranging from very close (1) to very far (7). The stations name were one of Spadina, St. George, Bloor--Yonge and Sherbourne (from West to East).

As there are four stations and two directions of travel (a 4 by 2 design), the scientific question of interest for subjective measures of distance would consist of perceiving differently the distance depending on the direction of travel. We could also wonder whether destinations that are two stations away from Bay (Spadina and Sherbourne) would be considered equidistant, and similarly for the other two.

:::




```{r}
#| label: Janiewski-replication
#| eval: false
#| echo: false
data(C16, package = "hecedsm")
```


## Efficiency of multiway analysis of variance.


Consider the setting of @Sharma.Tully.Cryder:2021 and suppose we want to check the impact of debt and collect a certain number of observations in each group. If we suspected the label had an influence, we could run a one-way analysis of variance for each spending type separately (thus, two one-way ANOVA each with two groups). We could do likewise if we wanted instead to focus on whether the spending was discretionary in nature or not, for each label: together, this would give a total of eight sets of observations. Combining the two factors allows us to halve the number of groups/samples we collect in this simple setting: this highlights the efficiency of running an experiment modifying all of these instances at once, over a series of one-way analysis of variance. This concept extends to higher dimension when we manipulate two or more factors. Factorial designs allow us to study the impact of multiple variables simultaneously with **fewer overall observations**. 



The drawback is that as we increase the number of factors, the total number of subgroups increases: with a complete design^[By complete design, it is meant that we gather observations for each subcategory.] and with factors $A$, $B$, $C$, etc. with $a$, $b$, $c$, $\ldots$ levels, we have a total of $a\times b \times c \times \cdots$ combinations and the number of observations needed to efficiently measure the group means increases quickly. This is the **curse of dimensionality**: the larger the number of experimental treatments manipulated together, the larger the sample size needed. A more efficient approach, which we will cover in later section, relies on measuring multiple observations from the same experimental units, for example by giving multiple tasks (randomly ordered) to participants.

Intrinsically, the multiway factorial design model description does not change relative to a one-way design: the analysis of variance describes the sample mean for the response in each subgroup,

Consider a two-way analysis of variance model. This is a linear model with two factors, $A$ and $B$, with respectively $a$ and $b$ levels. The response $Y_{ijk}$ of the $k$th measurement in group $(a_i, b_j)$ is
$$Y_{ijk} = \mu_{ij} + \varepsilon_{ijk}$$
where 

- $Y_{ijk}$ is the $k$th replicate for $i$th level of factor $A$ and $j$th level of factor $B$
- $\mu_{ij}$ is the average response of measurements in group $(a_i, b_j)$
- $\varepsilon_{ijk}$ are independent error terms with mean zero and standard deviation $\sigma$.

This, it turns out, is a special case of linear regression model. We could build contrasts for comparing group averages, but it will more convenient to reparametrize the model so that hypotheses of interest are directly expressed in terms of the parameters.

For example, in the @Maglio.Polman:2014 study, we could gather observations for each factor combination in a table, where `direction` is the row and `station` the column.


| $A$ `direction` \\ $B$ `station` | $B_1$ (`Spadina`) | $b_2$ (`St. George`) | $b_3$ (`Bloor-Yonge`) | $b_4$ (`Sherbourne`) |  *row mean* |
|---|:---:|:---:|:---:|:---:|:--:|
| $a_1$ (`east`) | $\mu_{11}$ | $\mu_{12}$ | $\mu_{13}$ |  $\mu_{14}$ |  $\mu_{1.}$ |
| $a_2$ (`west) |  $\mu_{21}$ | $\mu_{22}$ | $\mu_{23}$ |  $\mu_{24}$ |  $\mu_{2.}$ |
| **column mean** | $\mu_{.1}$ | $\mu_{.2}$ | $\mu_{.3}$ | $\mu_{.4}$ |  $\mu$ |


The $i$th row mean represents the average response across all levels of $B$,
$\mu_{i.} = (\mu_{i1} + \cdots + \mu_{ib})/b$ and similarly for the average of the $j$th column, $\mu_{.j} = (\mu_{1j} + \cdots + \mu_{aj})/a.$ Finally, the overall average is 
$$\mu = \frac{\sum_{i=1}^a \sum_{j=1}^b \mu_{ij}}{ab}.$$

## Interactions



```{r}
#| label: fig-2by2
#| fig-cap: "Line graph for example patterns for means for each of the possible kinds of general outcomes in a 2 by 2 design. Illustration adapted from Figure 10.2 of @Crump.Navarro.Suzuki:2019 by Matthew Crump (CC BY-SA 4.0 license)."
#| out-width: "100%"
p1 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(5, 5, 5, 5)
)
p2 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(10, 10, 5, 5)
)
p3 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(10, 13, 5, 2)
)
p4 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(5, 10, 10, 15)
)
p5 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(10, 18, 5, 7)
)
p6 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(5, 10, 5, 10)
)
p7 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(2, 12, 5, 9)
)
p8 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(5, 10, 10, 5)
)
all_22s <- rbind(p1, p2, p3, p4, p5, p6, p7, p8)
type <- factor(rep(1:8, each = 4), 
               labels = c("no effect",
                          "main effect of A only",
                          "main effect of A and interaction",
                          "both main effects",
                          "both main effects and interaction",
                          "main effect of B only",
                          "main effect of B and interaction",
                          "interaction only"))
all_22s <- cbind(all_22s, type)
options(ggplot2.discrete.colour= MetBrewer::met.brewer(name = "Hiroshige", 2))
ggplot(all_22s, 
       mapping = aes(x = factorA, 
                     y = means, 
                     type = type,
                     group = factorB, 
                     color = factorB))+
  geom_point() +
  geom_line() +
  labs(x = "factor A",
       subtitle = "mean response",
       y = "",
       color = "factor B") +
  facet_wrap(~type, nrow = 2) +
  theme_classic() +
  theme(legend.position = "bottom")
```


We call $\mu_{i.}$ and $\mu_{.j}$ **main** effects: in the case of balanced sample, which are samples in which the number of observations in each subgroup is the same, the estimated average will simply be the pooled average of everyone in this row or column representing the experimental condition. In general, however, we assign equal weight to each average so the resulting estimate will be different from the summary statistics. Likewise, the overall average will be the equiweighted average of each cell average.

In general designs, some experimental factors may (or not) impact the response but they can also coupled together have different impacts than the superposition of each. We term such effects **interactions**: an interaction between two factors occurs when the average effect of one independent variable depends on the level of the other.

To better understand, we consider the average response and suppose we have access to the true population average for each sub-treatment. We represent the latter using a line graph. Figure \@ref(fig:fig-2by2) shows what happens under all possible scenarios with a 2 by 2 design. When there is no overall effect, the mean is constant and the means are overlaid. If there is an effect of $B$ or an interaction, the two colored curves don't overlay. There isn't a main effect of $A$, the average of the two mean response for $a_1$ and $a_2$ are the same, etc. 

It's clear from Figure \@ref(fig:fig-2by2) that looking only at the average of $A$ alone (the main effect) isn't instructive when we are in the presence of an interaction: rather, we should be comparing the values of $A$ for $b_1$ separately than those for $b_2$, and vice-versa.  

:::{.example name="Interaction plots for @Maglio.Polman:2014"}

The hypothesis of interest is the interaction; for the time being, we can simply plot the average per group. Since the summary statistics can hide important information such as the uncertainty, we add 95% confidence intervals for the subgroup averages and superimpose jittered observations to show the spread of the data. Based on Figure \@ref(fig:fig-interactionplotMP), there appears to be at least an interaction between station and direction of travel, in addition to a main effect for station. Formal hypothesis testing can help check this intuition.

```{r}
#| label: fig-interactionplotMP
#| eval: true
#| echo: false
#| fig.cap: "Interaction plot for Study 1 of @Maglio.Polman:2014, showing group averages and 95% confidence intervals for the means. Observations are overlaid on the graph."
data(MP14_S1, package = "hecedsm")
model <- aov(distance ~ direction*station, 
             data = MP14_S1)
mean_tab <- MP14_S1 |>
  dplyr::group_by(direction, station) |>
  dplyr::summarize(mean = mean(distance),
            se = sigma(model) / sqrt(dplyr::n()),
            lower = mean - qt(0.975, df = model$df.residual) * se,
            upper = mean + qt(0.975, df = model$df.residual) * se)
  ggplot(data = MP14_S1,
         mapping = aes(x = station,
                       y = distance, 
                       group = direction,
                       col = direction)) + 
  geom_line(data = mean_tab, 
            mapping = aes(y = mean)) +
  geom_jitter(alpha = 0.2) +
  geom_errorbar(data = mean_tab, 
                aes(ymin = lower, 
                    y = mean,
                   ymax = upper),
                 width = 0.2) + 
  theme_classic() +
  theme(legend.position = "bottom") + 
  labs(y = "subjective distance",
       x = "subway station",
       col = "direction of travel")
```

:::

## Model parametrization

The model parameterized in terms of cell average is okay, but it doesn't help us if we want to check for the presence of main effects and interaction, even if it would be possible to specify the contrasts required to test these hypotheses.

We consider the alternative formulation
$$Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \varepsilon_{ijk} $$
where
- $\alpha_i = \mu_{i.} - \mu$, the mean of level $A_i$ minus the overall mean.
- $\beta_j  = \mu_{.j} - \mu$, the mean of level $B_j$ minus overall mean.
- $(\alpha\beta)_{ij} = \mu_{ij} - \mu_{i.} - \mu_{.j} + \mu$, the interaction term for $A_i$ and $B_j$.

A rapid calculation shows that there are more coefficients than the number of cells and subgroups ($ab$ cells overall) in our table. The model is **overparametrized**: to get away with this, we impose sum-to-zero constraints to remove redundancies. The idea is that if we know $a-1$ and the global average, we can deduce the last value. The model formulation in terms of difference from the global average or main effect ensures that we can test for main effects for factor $A$ by setting $\mathscr{H}_0: \alpha_1 = \cdots = \alpha_{a-1}=0$. The constraints,
$$\sum_{i=1}^a \alpha_i=0, \quad \sum_{j=1}^b \beta_j=0, \quad  \sum_{j=1}^b (\alpha\beta)_{ij}=0, \quad \sum_{i=1}^a (\alpha\beta)_{ij}=0,$$ restore identifiability as it imposes 
which imposes $1 +  a + b$ constraints.


We only tests hypothesis that are of interest. If there is a significant interaction, the marginal means are **not** of interest since they are misleading. Rather, we will compute the simple effects by making the comparison one at level at the time.

The first test to carry out is for the interaction: if the effect of one factor depends on the level of the other, as shown in \@ref(fig:interaction), then we need to compare the label of debt type separately for each type of purchase and vice-versa using so called **simple effects**. If the interaction on the contrary isn't significant, then we could pool observations instead and average across either of the two factors, resulting in the marginal comparisons with the main effects.

Fitting the model including the interaction between factors ensures that we keep the additivity assumption and that our conclusions aren't misleading: the price to pay is additional mean parameters to be estimated, which isn't an issue if you collect enough data, but can be critical when data collection is extremely costly and only a few runs are allowed.

@Sharma.Tully.Cryder:2021 first proceeded with the test for the interaction. Since there are one global average and two main effect (additional difference in average for both factors `debttype` and `purchase`), the interaction involves one degree of freedom since we go from a model with three parameters describing the mean to one that has a different average for each of the four subgroups.

```{r}
#| eval: true
#| echo: true
# Analysing Supplementary Study 5
# of Sharma, Tully, and Cryder (2021)
data(STC21_SS5, package = "hecedsm")
mod <- aov(likelihood ~ purchase*debttype, 
           data = STC21_SS5)
model.tables(mod, type = "means")
# Analysis of variance reveals 
# non-significant interaction
# of purchase and type
car::Anova(mod, type = 3)
# Main effect
# Marginal effect
emmeans::emmeans(mod, 
                 specs = "debttype",
                 contr = "pairwise")
  
# Pairwise comparisons within levels of purchase
# Simple effect
emmeans::emmeans(mod, 
                 specs = c("purchase", "debttype"),
                 by = "purchase",
                 contr = "pairwise")

```

In the analysis of variance table, we only focus on the last line with the sum of squares for `purchase:debttype`. The $F$ statistic is `r car::Anova(mod, type = 3)[4,3]`; using the $\mathsf{F}$ (`r car::Anova(mod, type = 3)[4,2]`, `r car::Anova(mod, type = 3)[5,2]`) distribution as benchmark, we obtain a $p$-value of `r format.pval(car::Anova(mod, type = 3)[4,4], digits=2)` so there is no evidence the effect of purchase depends on debt type.

We can thus pool data and look at the effect of debt type (`loan` or `credit`) overall by combining the results for all purchase types, one of the planned comparison reported in the Supplementary material. To do this in **R** with the `emmeans` package, we use the `emmeans` function and we quote the factor of interest (i.e., the one we want to keep) in `specs`. By default, this will compute the estimate marginal means: the `contr = "pairwise"` indicates that we want the difference between the two, which gives us the contrasts.

To get the simple effects, we give both variables in `specs` as factors for which to compute subgroup means, then set additionally the `by` command to specify which variable we want separate results for. We get the difference in average between `credit` and `loan` labels for each purchase type along with the $t$ statistics for the marginal contrast and the $p$-value. The simple effects suggest that the label has an impact on perception only for discretionary expenses rather than needed ones, which runs counter-intuitively with the lack of interaction.



:::keyidea

**Summary**:

* Complete factorial designs consist of experiments in which we manipulate multiple experimental factors at once and collect observations for each subgroup.
* Factorial designs are more efficient than running repeatedly one-way analysis of variance with the same sample size per group.
* Interactions occur when the effect of a variable depends on the levels of the others.
* Interaction plots (group average per group) can help capture this difference, but beware of overinterpretation in small samples
* If there is an interaction, we consider differences and contrasts for each level of the other factor (**simple effects**)
* If there is no interaction, we can pool observations and look at **main effects**
* A multiway analysis of variance can be treated as a one-way analysis of variance by collapsing categories; however, only specific contrasts will be of interest.
* The number of observations increases quickly with the dimension as we increase the number of factors considered.


:::
