

```{r flowcharttests, echo = FALSE, fig.cap = "Flowchart of statistical tests (Figure 1.1 from @McElreath:2020)."}
knitr::include_graphics("figures/flowchart_stat_tests_McElreath.png")
```

Richard McElreath in the [first chapter](http://xcelab.net/rmpubs/sr2/statisticalrethinking2_chapters1and2.pdf) of his book [@McElreath:2020] draws a parallel between statistical tests and golems (i.e., robots): neither

> discern when the context is inapropriate for its answers. It just knows its own procedure [...] It just does as it's told.

The responsibility therefore lies with the user to correctly use statistical procedures and be aware of their limitations: most common research questions cannot be answered by simple tools. Researchers wishing to perform innovative methodological research should contact experts and consult with statisticians **before** they collect their data to get information on how best to proceed for what they have in mind so as to avoid the risk of making misleading and false claims based on incorrect analysis or data collection.


Given data, a researcher will be interested in estimating particular characteristics of the population. We can characterize the set of all potential values their measurements can take, together with their frequency, via a distribution. The latter can be represented graphically using an histogram or a density plot if the data are continuous, or a bar plot for discrete or categorical measurements.

```{r distributionplot, fig.cap = "Graphical representation of the distribution of outcomes for continuous (left) and discrete (right) data."}
set.seed(1234)
samp1 <- c(round(TruncatedNormal::rtmvt(n = 100, 
                                mu = 80, 
                                sigma = matrix(20),
                                df = 2,
                                lb = 0, ub = 100)))
ggplot(data = data.frame(samp1)) + 
  geom_histogram(aes(x=samp1, y = ..density..))

```


Many technical statistics terms are sometimes encountered in discussions. For example,

- The sample mean is an **unbiased estimator**, meaning that its expectation ('theoretical' average) is the true mean $\mu$ regardless of the sample size $n$ (it is not systematically off).
- The sample mean is also a **consistent** estimator. This means that, if we had an infinite number of observations, we would observe $\mu$ to arbitrary precision and would know its exact value.


---------------------------

Usually, hypothesis tests involve a parameter, say $\theta$, which characterizes the underlying distribution at the population level and whose value is unknown. A two-sided hypothesis test regarding a parameter $\theta$ has the form $\mathscr{H}_0: \theta$ equals some postulated values
\begin{align*}
\mathscr{H}_0: \theta=\theta_0 \qquad \text{versus} \qquad \mathscr{H}_a:\theta \neq \theta_0.
\end{align*}
We are testing whether or not $\theta$ is precisely equal to the numerical value $\theta_0$. 

Consider the example of a two-sided test involving the population mean $\mathscr{H}_0:\mu=0$ against the alternative $\mathscr{H}_1:\mu \neq 0$. Assuming the random sample comes from a normal (population) $\mathsf{No}(\mu, \sigma^2)$, it can be shown that if $\mathscr{H}_0$ is true (that is, if $\mu=0$), the test statistic
\begin{align*}
T = \frac{\overline{X}}{S/\sqrt{n}}
\end{align*}
follows a Student-*t* distribution with $n-1$ degrees of freedom, denoted $\mathsf{St}_{n-1}$. This allows us to calculate the *p*-value (either from a table, or using some statistical software). The Student-*t* distribution is symmetric about zero, so the _p_-value is $P = 2\times\mathsf{Pr}(T_{n-1} > |t|)$, where $T \sim \mathsf{St}_{n-1}$.



To calculate the power of a test, we need to single out a specific alternative hypothesis: for example, the one-sample *t*-test statistic $T=\sqrt{n}(\overline{X}_n-\mu_0)/S_n \sim \mathcal{T}_{n-1}$ for a normal sample follows a noncentral Student-$t$ distribution with noncentrality parameter $\Delta$ if the expectation of the population is $\Delta + \mu_0$. In general, such closed-form expressions are not easily obtained and we compute instead the power of a test through Monte Carlo methods. 
