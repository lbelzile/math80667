<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>5 Complete factorial designs | Experimental Design and Statistical Methods</title>
<meta name="author" content="Léo Belzile">
<meta name="description" content="We next consider experiments and designs in which there are multiple factors being manipulated by the experimenter simultaneously. Before jumping into the statistical analysis, let us discuss...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="5 Complete factorial designs | Experimental Design and Statistical Methods">
<meta property="og:type" content="book">
<meta property="og:description" content="We next consider experiments and designs in which there are multiple factors being manipulated by the experimenter simultaneously. Before jumping into the statistical analysis, let us discuss...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="5 Complete factorial designs | Experimental Design and Statistical Methods">
<meta name="twitter:description" content="We next consider experiments and designs in which there are multiple factors being manipulated by the experimenter simultaneously. Before jumping into the statistical analysis, let us discuss...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.1/transition.js"></script><script src="libs/bs3compat-0.4.1/tabs.js"></script><script src="libs/bs3compat-0.4.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Experimental Design and Statistical Methods</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Experimental Design and Statistical Methods</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">2</span> Hypothesis testing</a></li>
<li><a class="" href="CRT.html"><span class="header-section-number">3</span> Completely randomized designs</a></li>
<li><a class="" href="contrasts-multiple-testing.html"><span class="header-section-number">4</span> Contrasts and multiple testing</a></li>
<li><a class="active" href="complete-factorial-designs.html"><span class="header-section-number">5</span> Complete factorial designs</a></li>
<li><a class="" href="designs-to-reduce-the-error.html"><span class="header-section-number">6</span> Designs to reduce the error</a></li>
<li><a class="" href="effect-sizes-and-power.html"><span class="header-section-number">7</span> Effect sizes and power</a></li>
<li><a class="" href="replication-crisis.html"><span class="header-section-number">8</span> Replication crisis</a></li>
<li><a class="" href="repeated-measures-and-multivariate-models.html"><span class="header-section-number">9</span> Repeated measures and multivariate models</a></li>
<li><a class="" href="introduction-to-mixed-models.html"><span class="header-section-number">10</span> Introduction to mixed models</a></li>
<li><a class="" href="causal-inference.html"><span class="header-section-number">11</span> Causal inference</a></li>
<li><a class="" href="nonparametric-tests.html"><span class="header-section-number">12</span> Nonparametric tests</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/lbelzile/math80667a">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="complete-factorial-designs" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> Complete factorial designs<a class="anchor" aria-label="anchor" href="#complete-factorial-designs"><i class="fas fa-link"></i></a>
</h1>
<p>We next consider experiments and designs in which there are multiple factors being manipulated by the experimenter simultaneously.</p>
<p>Before jumping into the statistical analysis, let us discuss briefly some examples that will be covered in the sequel.</p>
<div class="example">
<p><span id="exm:unlabeled-div-19" class="example"><strong>Example 5.1  (Psychological ownership of borrowed money) </strong></span>Supplemental Study 5 from <span class="citation">Sharma, Tully, and Cryder (<a href="references.html#ref-Sharma.Tully.Cryder:2021" role="doc-biblioref">2021</a>)</span> checks the psychological perception of borrowing money depending on the label. The authors conducted a 2 by 2 between-subject comparison (two-way ANOVA) varying the type of debt (whether the money was advertised as credit or loan) and the type of purchase the latter would be used for (discretionary spending or need). The response is the average of the likelihood and interest in the product, both measured using a 9 point Likert scale from 1 to 9.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-20" class="example"><strong>Example 5.2  (Spatial orientation shrinks and expands psychological distance) </strong></span><span class="citation">Maglio and Polman (<a href="references.html#ref-Maglio.Polman:2014" role="doc-biblioref">2014</a>)</span> measured the subjective distance on travel based on the direction of travel. They conducted an experiment in the Toronto subway green line, asking commuters from Bay station to answer the question “How far away does the [name] station feel to you?” using a 7 point Likert scale ranging from very close (1) to very far (7). The stations name were one of Spadina, St. George, Bloor–Yonge and Sherbourne (from West to East).</p>
<p>As there are four stations and two directions of travel (a 4 by 2 design), the scientific question of interest for subjective measures of distance would consist of perceiving differently the distance depending on the direction of travel. We could also wonder whether destinations that are two stations away from Bay (Spadina and Sherbourne) would be considered equidistant, and similarly for the other two.</p>
</div>
<div id="efficiency-of-multiway-analysis-of-variance." class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Efficiency of multiway analysis of variance.<a class="anchor" aria-label="anchor" href="#efficiency-of-multiway-analysis-of-variance."><i class="fas fa-link"></i></a>
</h2>
<p>Consider the setting of <span class="citation">Sharma, Tully, and Cryder (<a href="references.html#ref-Sharma.Tully.Cryder:2021" role="doc-biblioref">2021</a>)</span> and suppose we want to check the impact of debt and collect a certain number of observations in each group. If we suspected the label had an influence, we could run a one-way analysis of variance for each spending type separately (thus, two one-way ANOVA each with two groups). We could do likewise if we wanted instead to focus on whether the spending was discretionary in nature or not, for each label: together, this would give a total of eight sets of observations. Combining the two factors allows us to halve the number of groups/samples we collect in this simple setting: this highlights the efficiency of running an experiment modifying all of these instances at once, over a series of one-way analysis of variance. This concept extends to higher dimension when we manipulate two or more factors. Factorial designs allow us to study the impact of multiple variables simultaneously with <strong>fewer overall observations</strong>.</p>
<p>The drawback is that as we increase the number of factors, the total number of subgroups increases: with a complete design<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;By complete design, it is meant that we gather observations for each subcategory.&lt;/p&gt;"><sup>37</sup></a> and with factors <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(C\)</span>, etc. with <span class="math inline">\(n_a\)</span>, <span class="math inline">\(n_b\)</span>, <span class="math inline">\(n_c\)</span>, <span class="math inline">\(\ldots\)</span> levels, we have a total of <span class="math inline">\(n_a\times n_b \times n_c \times \cdots\)</span> combinations and the number of observations needed to efficiently measure the group means increases quickly. This is the <strong>curse of dimensionality</strong>: the larger the number of experimental treatments manipulated together, the larger the sample size needed. A more efficient approach, which we will cover in later section, relies on measuring multiple observations from the same experimental units, for example by giving multiple tasks (randomly ordered) to participants.</p>
<p>Intrinsically, the multiway factorial design model description does not change relative to a one-way design: the analysis of variance describes the sample mean for the response in each subgroup,</p>
<p>Consider a two-way analysis of variance model. This is a linear model with two factors, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, with respectively <span class="math inline">\(n_a\)</span> and <span class="math inline">\(n_b\)</span> levels. The response <span class="math inline">\(Y_{ijk}\)</span> of the <span class="math inline">\(k\)</span>th measurement in group <span class="math inline">\((a_i, b_j)\)</span> is
<span class="math display" id="eq:twowayasoneway">\[\begin{align}
\underset{\text{response}\vphantom{b}}{Y_{ijk}} = \underset{\text{subgroup mean}}{\mu_{ij}} + \underset{\text{error term}}{\varepsilon_{ijk}}
\tag{5.1}
\end{align}\]</span>
where</p>
<ul>
<li>
<span class="math inline">\(Y_{ijk}\)</span> is the <span class="math inline">\(k\)</span>th replicate for <span class="math inline">\(i\)</span>th level of factor <span class="math inline">\(A\)</span> and <span class="math inline">\(j\)</span>th level of factor <span class="math inline">\(B\)</span>
</li>
<li>
<span class="math inline">\(\mu_{ij}\)</span> is the average response of measurements in group <span class="math inline">\((a_i, b_j)\)</span>
</li>
<li>
<span class="math inline">\(\varepsilon_{ijk}\)</span> are independent error terms with mean zero and standard deviation <span class="math inline">\(\sigma\)</span>.</li>
</ul>
<p>This, it turns out, is a special case of linear regression model. We could build contrasts for comparing group averages, but it will more convenient to reparametrize the model so that hypotheses of interest are directly expressed in terms of the parameters.</p>
<p>For example, in the <span class="citation">Maglio and Polman (<a href="references.html#ref-Maglio.Polman:2014" role="doc-biblioref">2014</a>)</span> study, we could gather observations for each factor combination in a table, where <code>direction</code> is the row and <code>station</code> the column.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:cellmeansMP14">Table 5.1: </span> Conceptual depiction of cell average for the two by two design of <span class="citation">Maglio and Polman (<a href="references.html#ref-Maglio.Polman:2014" role="doc-biblioref">2014</a>)</span>
</caption>
<colgroup>
<col width="30%">
<col width="2%">
<col width="30%">
<col width="17%">
<col width="17%">
</colgroup>
<thead><tr class="header">
<th>
<span class="math inline">\(A\)</span> <code>station</code>
</th>
<th>
<span class="math inline">\(B\)</span> <code>direction</code>
</th>
<th align="center">
<span class="math inline">\(b_1\)</span> (<code>east</code>)</th>
<th align="center">
<span class="math inline">\(b_2\)</span> (<code>west</code>)</th>
<th align="center"><em>row mean</em></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<span class="math inline">\(a_1\)</span> (<code>Spadina</code>)</td>
<td></td>
<td align="center"><span class="math inline">\(\mu_{11}\)</span></td>
<td align="center"><span class="math inline">\(\mu_{12}\)</span></td>
<td align="center"><span class="math inline">\(\mu_{1.}\)</span></td>
</tr>
<tr class="even">
<td>
<span class="math inline">\(a_2\)</span> (<code>St. George</code>)</td>
<td></td>
<td align="center"><span class="math inline">\(\mu_{21}\)</span></td>
<td align="center"><span class="math inline">\(\mu_{22}\)</span></td>
<td align="center"><span class="math inline">\(\mu_{2.}\)</span></td>
</tr>
<tr class="odd">
<td>
<span class="math inline">\(a_3\)</span> (<code>Bloor-Yonge</code>)</td>
<td></td>
<td align="center"><span class="math inline">\(\mu_{31}\)</span></td>
<td align="center"><span class="math inline">\(\mu_{32}\)</span></td>
<td align="center"><span class="math inline">\(\mu_{3.}\)</span></td>
</tr>
<tr class="even">
<td>
<span class="math inline">\(a_4\)</span> (<code>Sherbourne</code>)</td>
<td></td>
<td align="center"><span class="math inline">\(\mu_{41}\)</span></td>
<td align="center"><span class="math inline">\(\mu_{42}\)</span></td>
<td align="center"><span class="math inline">\(\mu_{4.}\)</span></td>
</tr>
<tr class="odd">
<td><em>column mean</em></td>
<td></td>
<td align="center"><span class="math inline">\(\mu_{.1}\)</span></td>
<td align="center"><span class="math inline">\(\mu_{.2}\)</span></td>
<td align="center"><span class="math inline">\(\mu\)</span></td>
</tr>
</tbody>
</table></div>
<p>The <span class="math inline">\(i\)</span>th row mean represents the average response across all levels of <span class="math inline">\(B\)</span>,
<span class="math inline">\(\mu_{i.} = (\mu_{i1} + \cdots + \mu_{in_b})/n_b\)</span> and similarly for the average of the <span class="math inline">\(j\)</span>th column, <span class="math inline">\(\mu_{.j} = (\mu_{1j} + \cdots + \mu_{n_aj})/n_a.\)</span> Finally, the overall average is
<span class="math display">\[\mu = \frac{\sum_{i=1}^{n_a} \sum_{j=1}^{n_b} \mu_{ij}}{n_an_b}.\]</span></p>
<p>Each subgroup average <span class="math inline">\(\mu_{ij}\)</span> will be estimated as the sample mean of observations in their group and we would use the above formulae to obtain estimates of the row, column and overall means <span class="math inline">\(\widehat{\mu}_{i.}\)</span>, <span class="math inline">\(\widehat{\mu}_{.j}\)</span> and <span class="math inline">\(\widehat{\mu}\)</span>. If the sample is balanced, meaning the number of observations is the same, these will be the same as summing over all observations in a row, column or table and then averaging. In general setup, however, we will give equal weight to each subgroup average.</p>
</div>
<div id="interactions" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> Interactions<a class="anchor" aria-label="anchor" href="#interactions"><i class="fas fa-link"></i></a>
</h2>
<p>Table <a href="complete-factorial-designs.html#tab:cellmeansMP14">5.1</a> shows the individual mean of each subgroup. From these, we may be interested in looking at the experiment as a single one-way analysis of variance model with eight subgroups, or as a series of one-way analysis of variance with either <code>direction</code> or <code>station</code> as sole factor.</p>
<p>We will use particular terminology to refer to these:</p>
<ul>
<li>
<strong>simple effects</strong>: difference between levels of one in a fixed combination of others. Simple effects are comparing cell averages within a given row or column.</li>
<li>
<strong>main effects</strong>: differences relative to average for each condition of a factor. Main effects are row/column averages.</li>
<li>
<strong>interaction effects</strong>: when simple effects differ depending on levels of another factor. Interactions effects are difference relative to the row or column average.</li>
</ul>
<p>In other words, an interaction occurs when some experimental factors, when coupled together, have different impacts than the superposition of each. An interaction between two factors occurs when the average effect of one independent variable depends on the level of the other.</p>
<p>If there is a significant interaction, the main effects are <strong>not</strong> of interest since they are misleading. Rather, we will compute the simple effects by making the comparison one at level at the time.</p>
<p>In our example of <span class="citation">Maglio and Polman (<a href="references.html#ref-Maglio.Polman:2014" role="doc-biblioref">2014</a>)</span>, a simple effect would be comparing the distance between Spadina and Sherbourne for east. The main effect for the direction would be the average perceived distance for east and for west. Finally, the interaction would measure how much these differ by station depending on direction.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-2by2"></span>
<img src="05-interactions_multiway_files/figure-html/fig-2by2-1.png" alt="interaction plots (line graphs) for example patterns for means for each of the possible kinds of general outcomes in a 2 by 2 design. Illustration adapted from Figure 10.2 of @Crump.Navarro.Suzuki:2019 by Matthew Crump (CC BY-SA 4.0 license)." width="100%"><p class="caption">
Figure 5.1: interaction plots (line graphs) for example patterns for means for each of the possible kinds of general outcomes in a 2 by 2 design. Illustration adapted from Figure 10.2 of <span class="citation">Crump, Navarro, and Suzuki (<a href="references.html#ref-Crump.Navarro.Suzuki:2019" role="doc-biblioref">2019</a>)</span> by Matthew Crump (CC BY-SA 4.0 license).
</p>
</div>
<p>To better understand, we consider the average response and suppose we have access to the true population average for each sub-treatment. We can then represent the population using a line graph with the two factors, one being mapped to color and another to the <span class="math inline">\(x\)</span>-axis. Figure <a href="complete-factorial-designs.html#fig:fig-2by2">5.1</a> shows what happens under all possible scenarios with a 2 by 2 design. When there is no overall effect, the mean is constant. If there isn’t a main effect of <span class="math inline">\(A\)</span>, the average of the two mean response for <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span> are the same, etc. Interactions are depicted by <strong>non-parallel lines</strong>.</p>
<p>It’s clear from Figure <a href="complete-factorial-designs.html#fig:fig-2by2">5.1</a> that looking only at the average of <span class="math inline">\(A\)</span> alone (the main effect) isn’t instructive when we are in the presence of an interaction: rather, we should be comparing the values of <span class="math inline">\(A\)</span> for <span class="math inline">\(b_1\)</span> separately than those for <span class="math inline">\(b_2\)</span>, and vice-versa using simple effects, otherwise our conclusions may be misleading.</p>
<div class="example">
<p><span id="exm:unlabeled-div-21" class="example"><strong>Example 5.3  (Interaction plots for Maglio and Polman (2014)) </strong></span>The hypothesis of interest is the interaction; for the time being, we can simply plot the average per group. Since the summary statistics can hide important information such as the uncertainty, we add 95% confidence intervals for the subgroup averages and superimpose jittered observations to show the spread of the data. Based on Figure <a href="complete-factorial-designs.html#fig:fig-interactionplotMP">5.2</a>, there appears to be at least an interaction between station and direction of travel, in addition to a main effect for station. Formal hypothesis testing can help check this intuition.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-interactionplotMP"></span>
<img src="05-interactions_multiway_files/figure-html/fig-interactionplotMP-1.png" alt="Interaction plot for Study 1 of @Maglio.Polman:2014, showing group averages and 95% confidence intervals for the means. Observations are overlaid on the graph." width="85%"><p class="caption">
Figure 5.2: Interaction plot for Study 1 of <span class="citation">Maglio and Polman (<a href="references.html#ref-Maglio.Polman:2014" role="doc-biblioref">2014</a>)</span>, showing group averages and 95% confidence intervals for the means. Observations are overlaid on the graph.
</p>
</div>
</div>
</div>
<div id="model-parametrization" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> Model parametrization<a class="anchor" aria-label="anchor" href="#model-parametrization"><i class="fas fa-link"></i></a>
</h2>
<p>The model parametrized in terms of subgroup or cell average is okay in Equation <a href="complete-factorial-designs.html#eq:twowayasoneway">(5.1)</a>, but it doesn’t help us if we want to check for the presence of main effects and interaction, even if it would be possible to specify the contrasts required to test these hypotheses. We can however express the model in terms of main effects and interactions.</p>
<p>We consider the alternative formulation
<span class="math display">\[\begin{align*}
Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \varepsilon_{ijk},
\end{align*}\]</span>
where</p>
<ul>
<li>
<span class="math inline">\(\mu\)</span> is the average of all subgroup averages, termed overall mean.</li>
<li>
<span class="math inline">\(\alpha_i = \mu_{i.} - \mu\)</span> is the mean of level <span class="math inline">\(A_i\)</span> minus the overall mean.</li>
<li>
<span class="math inline">\(\beta_j = \mu_{.j} - \mu\)</span> is the mean of level <span class="math inline">\(B_j\)</span> minus overall mean.</li>
<li>
<span class="math inline">\((\alpha\beta)_{ij} = \mu_{ij} - \mu_{i.} - \mu_{.j} + \mu\)</span> is the interaction term for <span class="math inline">\(A_i\)</span> and <span class="math inline">\(B_j\)</span> which encodes the effect of both variable not already captured by the main effects.</li>
</ul>
<p>A rapid calculation shows that there are more coefficients than the number of cells and subgroups (<span class="math inline">\(n_an_b\)</span> cells overall) in our table. The model is <strong>overparametrized</strong>: to get away with this, we impose constraints to remove redundancies. The idea is that if we know <span class="math inline">\(n_a-1\)</span> of the mean for factor <span class="math inline">\(A\)</span> and the global average is a combination of these, we can deduce the value for the last row mean. The model formulation in terms of difference from the global average or main effect ensures that we can test for main effects for factor <span class="math inline">\(A\)</span> by setting <span class="math inline">\(\mathscr{H}_0: \alpha_1 = \cdots = \alpha_{n_a-1}=0\)</span>. The <strong>sum to zero</strong> constraints,
<span class="math display">\[\sum_{i=1}^{n_a} \alpha_i=0, \quad \sum_{j=1}^{n_b} \beta_j=0, \quad  \sum_{j=1}^{n_b} (\alpha\beta)_{ij}=0, \quad \sum_{i=1}^{n_a} (\alpha\beta)_{ij}=0,\]</span> restore identifiability as they imposes
which imposes <span class="math inline">\(1 + n_a + n_b\)</span> constraints.</p>
<p>The redundancy in information, due to the fact main effects are expressible as row and column averages, and the overall mean as the average of all observations, will arise again when we consider degrees of freedom for tests.</p>
<p><strong>To be continued</strong>…</p>
<div class="example">
<p><span id="exm:unlabeled-div-22" class="example"><strong>Example 5.4  (Testing for Psychological ownership of borrowed money) </strong></span><span class="citation">Sharma, Tully, and Cryder (<a href="references.html#ref-Sharma.Tully.Cryder:2021" role="doc-biblioref">2021</a>)</span> first proceeded with the test for the interaction. Since there are one global average and two main effect (additional difference in average for both factors <code>debttype</code> and <code>purchase</code>), the interaction involves one degree of freedom since we go from a model with three parameters describing the mean to one that has a different average for each of the four subgroups.</p>
<p>The reason why this is first test to carry out is that if the effect of one factor depends on the level of the other, as shown in <a href="complete-factorial-designs.html#fig:fig-2by2">5.1</a>, then we need to compare the label of debt type separately for each type of purchase and vice-versa using simple effects. If the interaction on the contrary isn’t significant, then we could pool observations instead and average across either of the two factors, resulting in the marginal comparisons with the main effects.</p>
<p>Fitting the model including the interaction between factors ensures that we keep the additivity assumption and that our conclusions aren’t misleading: the price to pay is additional mean parameters to be estimated, which isn’t an issue if you collect enough data, but can be critical when data collection is extremely costly and only a few runs are allowed.</p>
<p>In <strong>R</strong>, we include both factors in a formula as
<code>response ~ factorA * factorB</code>, the <code>*</code> symbol indicating that both are allowed to interact; in the main effect model, we would use instead <code>+</code> to reflect that the effects of both factors add up.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Analysing Supplementary Study 5</span></span>
<span><span class="co"># of Sharma, Tully, and Cryder (2021)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">STC21_SS5</span>, package <span class="op">=</span> <span class="st">"hecedsm"</span><span class="op">)</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/aov.html">aov</a></span><span class="op">(</span><span class="va">likelihood</span> <span class="op">~</span> <span class="va">purchase</span><span class="op">*</span><span class="va">debttype</span>, </span>
<span>           data <span class="op">=</span> <span class="va">STC21_SS5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/model.tables.html">model.tables</a></span><span class="op">(</span><span class="va">mod</span>, type <span class="op">=</span> <span class="st">"means"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Tables of means</span></span>
<span><span class="co">#&gt; Grand mean</span></span>
<span><span class="co">#&gt;      </span></span>
<span><span class="co">#&gt; 4.88 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  purchase </span></span>
<span><span class="co">#&gt;     discretionary    need</span></span>
<span><span class="co">#&gt;             4.182   5.579</span></span>
<span><span class="co">#&gt; rep       751.000 750.000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  debttype </span></span>
<span><span class="co">#&gt;      credit    loan</span></span>
<span><span class="co">#&gt;       5.127   4.631</span></span>
<span><span class="co">#&gt; rep 753.000 748.000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  purchase:debttype </span></span>
<span><span class="co">#&gt;                debttype</span></span>
<span><span class="co">#&gt; purchase        credit loan </span></span>
<span><span class="co">#&gt;   discretionary   4.5    3.8</span></span>
<span><span class="co">#&gt;   rep           392.0  359.0</span></span>
<span><span class="co">#&gt;   need            5.7    5.4</span></span>
<span><span class="co">#&gt;   rep           361.0  389.0</span></span>
<span><span class="co"># Analysis of variance reveals </span></span>
<span><span class="co"># non-significant interaction</span></span>
<span><span class="co"># of purchase and type</span></span>
<span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/Anova.html">Anova</a></span><span class="op">(</span><span class="va">mod</span>, type <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt; Anova Table (Type III tests)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Response: likelihood</span></span>
<span><span class="co">#&gt;                   Sum Sq   Df F value  Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; (Intercept)         7974    1 1040.96 &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; purchase             283    1   36.91 1.6e-09 ***</span></span>
<span><span class="co">#&gt; debttype              88    1   11.55  0.0007 ***</span></span>
<span><span class="co">#&gt; purchase:debttype     14    1    1.79  0.1817    </span></span>
<span><span class="co">#&gt; Residuals          11467 1497                    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co"># Main effects</span></span>
<span><span class="fu">emmeans</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">mod</span>, </span>
<span>                 specs <span class="op">=</span> <span class="st">"debttype"</span>,</span>
<span>                 contr <span class="op">=</span> <span class="st">"pairwise"</span><span class="op">)</span></span>
<span><span class="co">#&gt; $emmeans</span></span>
<span><span class="co">#&gt;  debttype emmean    SE   df lower.CL upper.CL</span></span>
<span><span class="co">#&gt;  credit     5.12 0.101 1497     4.93     5.32</span></span>
<span><span class="co">#&gt;  loan       4.63 0.101 1497     4.43     4.83</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Results are averaged over the levels of: purchase </span></span>
<span><span class="co">#&gt; Confidence level used: 0.95 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $contrasts</span></span>
<span><span class="co">#&gt;  contrast      estimate    SE   df t.ratio p.value</span></span>
<span><span class="co">#&gt;  credit - loan    0.496 0.143 1497   3.470  0.0005</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Results are averaged over the levels of: purchase</span></span>
<span>  </span>
<span><span class="co"># Pairwise comparisons within levels of purchase</span></span>
<span><span class="co"># Simple effect</span></span>
<span><span class="fu">emmeans</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">mod</span>, </span>
<span>                 specs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"purchase"</span>, <span class="st">"debttype"</span><span class="op">)</span>,</span>
<span>                 by <span class="op">=</span> <span class="st">"purchase"</span>,</span>
<span>                 contr <span class="op">=</span> <span class="st">"pairwise"</span><span class="op">)</span></span>
<span><span class="co">#&gt; $emmeans</span></span>
<span><span class="co">#&gt; purchase = discretionary:</span></span>
<span><span class="co">#&gt;  debttype emmean    SE   df lower.CL upper.CL</span></span>
<span><span class="co">#&gt;  credit     4.51 0.140 1497     4.24     4.78</span></span>
<span><span class="co">#&gt;  loan       3.82 0.146 1497     3.54     4.11</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; purchase = need:</span></span>
<span><span class="co">#&gt;  debttype emmean    SE   df lower.CL upper.CL</span></span>
<span><span class="co">#&gt;  credit     5.74 0.146 1497     5.45     6.02</span></span>
<span><span class="co">#&gt;  loan       5.43 0.140 1497     5.16     5.71</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Confidence level used: 0.95 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $contrasts</span></span>
<span><span class="co">#&gt; purchase = discretionary:</span></span>
<span><span class="co">#&gt;  contrast      estimate    SE   df t.ratio p.value</span></span>
<span><span class="co">#&gt;  credit - loan    0.687 0.202 1497   3.400  0.0007</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; purchase = need:</span></span>
<span><span class="co">#&gt;  contrast      estimate    SE   df t.ratio p.value</span></span>
<span><span class="co">#&gt;  credit - loan    0.305 0.202 1497   1.510  0.1318</span></span></code></pre></div>
<p>In the analysis of variance table, we only focus on the last line with the sum of squares for <code>purchase:debttype</code>. The <span class="math inline">\(F\)</span> statistic is 1.785; using the <span class="math inline">\(\mathsf{F}\)</span> (1, 1497) distribution as benchmark, we obtain a <span class="math inline">\(p\)</span>-value of 0.18 so there is no evidence the effect of purchase depends on debt type.</p>
<p>We can thus pool data and look at the effect of debt type (<code>loan</code> or <code>credit</code>) overall by combining the results for all purchase types, one of the planned comparison reported in the Supplementary material. To do this in <strong>R</strong> with the <code>emmeans</code> package, we use the <code>emmeans</code> function and we quote the factor of interest (i.e., the one we want to keep) in <code>specs</code>. By default, this will compute the estimate marginal means: the <code>contr = "pairwise"</code> indicates that we want the difference between the two, which gives us the contrasts.</p>
<p>To get the simple effects, we give both variables in <code>specs</code> as factors for which to compute subgroup means, then set additionally the <code>by</code> command to specify which variable we want separate results for. We get the difference in average between <code>credit</code> and <code>loan</code> labels for each purchase type along with the <span class="math inline">\(t\)</span> statistics for the marginal contrast and the <span class="math inline">\(p\)</span>-value. The simple effects suggest that the label has an impact on perception only for discretionary expenses rather than needed ones, which runs counter-intuitively with the lack of interaction.</p>
</div>
<div class="keyidea">
<p><strong>Summary</strong>:</p>
<ul>
<li>Complete factorial designs consist of experiments in which we manipulate multiple experimental factors at once and collect observations for each subgroup.</li>
<li>Factorial designs are more efficient than running repeatedly one-way analysis of variance with the same sample size per group.</li>
<li>Interactions occur when the effect of a variable depends on the levels of the others.</li>
<li>Interaction plots (group average per group) can help capture this difference, but beware of overinterpretation in small samples.</li>
<li>If there is an interaction, we consider differences and contrasts for each level of the other factor (<strong>simple effects</strong>).</li>
<li>If there is no interaction, we can pool observations and look at <strong>main effects</strong>.</li>
<li>A multiway analysis of variance can be treated as a one-way analysis of variance by collapsing categories; however, only specific contrasts will be of interest.</li>
<li>The number of observations increases quickly with the dimension as we increase the number of factors considered.</li>
</ul>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="contrasts-multiple-testing.html"><span class="header-section-number">4</span> Contrasts and multiple testing</a></div>
<div class="next"><a href="designs-to-reduce-the-error.html"><span class="header-section-number">6</span> Designs to reduce the error</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#complete-factorial-designs"><span class="header-section-number">5</span> Complete factorial designs</a></li>
<li><a class="nav-link" href="#efficiency-of-multiway-analysis-of-variance."><span class="header-section-number">5.1</span> Efficiency of multiway analysis of variance.</a></li>
<li><a class="nav-link" href="#interactions"><span class="header-section-number">5.2</span> Interactions</a></li>
<li><a class="nav-link" href="#model-parametrization"><span class="header-section-number">5.3</span> Model parametrization</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/lbelzile/math80667a/blob/master/05-interactions_multiway.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/lbelzile/math80667a/edit/master/05-interactions_multiway.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Experimental Design and Statistical Methods</strong>" was written by Léo Belzile. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
