<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>10 Introduction to mixed models | Experimental Design and Statistical Methods</title>
<meta name="author" content="Léo Belzile">
<meta name="description" content="This chapter considers tools for models with repeated measures from a modern perspective, using random effects for modelling. This class of model, called hierarchical models, multilevel models or...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="10 Introduction to mixed models | Experimental Design and Statistical Methods">
<meta property="og:type" content="book">
<meta property="og:description" content="This chapter considers tools for models with repeated measures from a modern perspective, using random effects for modelling. This class of model, called hierarchical models, multilevel models or...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="10 Introduction to mixed models | Experimental Design and Statistical Methods">
<meta name="twitter:description" content="This chapter considers tools for models with repeated measures from a modern perspective, using random effects for modelling. This class of model, called hierarchical models, multilevel models or...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.1/transition.js"></script><script src="libs/bs3compat-0.4.1/tabs.js"></script><script src="libs/bs3compat-0.4.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Experimental Design and Statistical Methods</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Experimental Design and Statistical Methods</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">2</span> Hypothesis testing</a></li>
<li><a class="" href="CRT.html"><span class="header-section-number">3</span> Completely randomized designs</a></li>
<li><a class="" href="contrasts-multiple-testing.html"><span class="header-section-number">4</span> Contrasts and multiple testing</a></li>
<li><a class="" href="complete-factorial-designs.html"><span class="header-section-number">5</span> Complete factorial designs</a></li>
<li><a class="" href="designs-to-reduce-the-error.html"><span class="header-section-number">6</span> Designs to reduce the error</a></li>
<li><a class="" href="effect-sizes-and-power.html"><span class="header-section-number">7</span> Effect sizes and power</a></li>
<li><a class="" href="replication-crisis.html"><span class="header-section-number">8</span> Replication crisis</a></li>
<li><a class="" href="repeated-measures-and-multivariate-models.html"><span class="header-section-number">9</span> Repeated measures and multivariate models</a></li>
<li><a class="active" href="introduction-to-mixed-models.html"><span class="header-section-number">10</span> Introduction to mixed models</a></li>
<li><a class="" href="causal-inference.html"><span class="header-section-number">11</span> Causal inference</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/lbelzile/math80667a">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="introduction-to-mixed-models" class="section level1" number="10">
<h1>
<span class="header-section-number">10</span> Introduction to mixed models<a class="anchor" aria-label="anchor" href="#introduction-to-mixed-models"><i class="fas fa-link"></i></a>
</h1>
<p>This chapter considers tools for models with repeated measures from a modern perspective, using random effects for modelling. This class of model, called hierarchical models, multilevel models or mixed models in simple scenarios, give us more flexibility to account for complex scenarios in which there may be different sources of variability.</p>
<p>For example, consider a large-scale replication study about teaching methods. We may have multiple labs partaking in a research program and each has unique characteristics. Because of these, we can expect that measurements collected within a lab will be correlated. At the same time, we can have repeated mesures for participants in the study. One can view this setup as a hierarchy, with within-subject factor within subject within lab. In such settings, the old-school approach to analysis of variance becomes difficult, if not impossible; it doesn’t easily account for the heterogeneity in the lab sample size and does not let us estimate the variability within labs.</p>
<p>We begin our journey with the same setup as for repeated measures ANOVA by considering one-way within-subject ANOVA model. We assign each participant (subject) in the study to all of the experimental treatments, in random order. If we have one experimental factor <span class="math inline">\(A\)</span> with <span class="math inline">\(n_a\)</span> levels, the model is
<span class="math display">\[\begin{align*}\underset{\text{response}\vphantom{l}}{Y_{ij}} = \underset{\text{global mean}}{\mu_{\vphantom{j}}} + \underset{\text{mean difference}}{\alpha_j} + \underset{\text{random effect for subject}}{S_{i\vphantom{j}}} + \underset{\text{error}\vphantom{l}}{\varepsilon_{ij}}.
\end{align*}\]</span>
In a random effect model, we assume that the subject effect <span class="math inline">\(S_i\)</span> is a random variable; we take <span class="math inline">\(S_i \sim \mathsf{No}(0, \sigma^2_s)\)</span> and the latter is assumed to be independent of the noise <span class="math inline">\(\varepsilon_{ij} \sim \mathsf{No}(0, \sigma^2_e)\)</span>. The model parameters that we need to estimate are the global mean <span class="math inline">\(\mu\)</span>, the mean differences <span class="math inline">\(\alpha_1, \ldots, \alpha_{n_a}\)</span>, the subject-specific variability <span class="math inline">\(\sigma^2_s\)</span> and the residual variability <span class="math inline">\(\sigma^2_e\)</span>, with the sum-to-zero constraint <span class="math inline">\(\alpha_1 + \cdots + \alpha_{n_a}=0\)</span>.</p>
<p>Inclusion of random effects introduces positive correlation between measurements: specifically, the correlation between two observations from the same subject will be <span class="math inline">\(\rho=\sigma^2_s/(\sigma^2_s+\sigma^2_e)\)</span> and zero otherwise. This correlation structure is termed compound symmetry, since the correlation between measurements, <span class="math inline">\(\rho\)</span>, is the same regardless of the order of the observations. If there are multiple random effects, the dependence structure will be more complicated.</p>
<p>In the repeated measure models, we need to first reduce measurements to a single average per within-subject factor, then fit the model by including the subject as a blocking factor. We are therefore considering subjects as fixed effects by including them as blocking factors, and estimate the mean effect for each subject: the value of <span class="math inline">\(\sigma^2_s\)</span> is estimated from the mean squared error of the subject term, but this empirical estimate can be negative. By contrast, the mixed model machinery will directly estimate the variance term, which will be constrained to be strictly positive.</p>
<div id="fixed-vs-random-effects" class="section level2" number="10.1">
<h2>
<span class="header-section-number">10.1</span> Fixed vs random effects<a class="anchor" aria-label="anchor" href="#fixed-vs-random-effects"><i class="fas fa-link"></i></a>
</h2>
<p>Mixed models include, by definition, both <strong>random</strong> and <strong>fixed</strong> effects. Fixed effects are model parameters corresponding to overall average or difference in means for the experimental conditions. These are the terms for which we want to perform hypothesis tests and compute contrasts. So far, we have only considered models with fixed effects.</p>
<p>Random effects, on the other hand, assumes that the treatments are random samples from a population of interest. If we gathered another sample, we would be looking at a new set of treatments. Random effects model the variability arising from the sampling of that population and focuses on variance and correlation parameters. Addition of random effects does not impact the population mean, but induces variability and correlation within subject. There is no consensual definition, but <span class="citation">Gelman (<a href="references.html#ref-Gelman:2005" role="doc-biblioref">2005</a>)</span> lists a handful:</p>
<blockquote>
<p>When a sample exhausts the population, the corresponding variable is fixed; when the sample is a small (i.e., negligible) part of the population the corresponding variable is random [Green and Tukey (1960)].</p>
</blockquote>
<blockquote>
<p>Effects are fixed if they are interesting in themselves or random if there is interest in the underlying population (e.g., Searle, Casella and McCulloch [(1992), Section 1.4])</p>
</blockquote>
<p>In terms of estimation, fixed effect terms are mean parameters, while all random effects will be obtained from variance and correlation parameters. In the repeated measure approach with fixed effects and blocking, we would estimate the average for each subject despite the fact that this quantity is of no interest. Estimating a mean with only a handful of measurements is a risky business and the estimated effects are sensitive to outliers.</p>
<p>Random effects would proceed to directly estimate the variability arising from different subjects. We can still get predictions for the subject-specific effect, but this prediction will be shrunk toward the global mean for that particular treatment category. As we gather more data about the subjects, the predictions will become closer to the fixed effect estimates when the number of observations per subject or group increases, but these prediction can deviate from mean estimates in the case where there are few measurements per subject.</p>
<p><span class="citation">(<a href="#ref-Oelhert:2010" role="doc-biblioref"><strong>Oelhert:2010?</strong></a>)</span> identifies the following step to perform a mixed model</p>
<ol style="list-style-type: decimal">
<li>Identify sources of variation</li>
<li>Identify whether factors are crossed are nested</li>
<li>Determine whether factors should be fixed or random</li>
<li>Figure out which interactions can exist and whether they can be fitted.</li>
</ol>
<p>To fit the model, identifiers of subjects must be declared as factors (categorical variables).</p>
<p>We say to factors are nested (<span class="math inline">\(A\)</span> within <span class="math inline">\(B\)</span>) when one can only coexist within the levels of the other: this has implications, for we cannot have interaction between the two. In between-subject experiments, factors are crossed, meaning we can assign an experimental unit or a subject to each factor combination and thus interactions can occur. For example, subjects are nested in between-level factors.</p>
<p>The next step will be in determining whether we have enough observations to support the inclusion of a random term. In a pure within-subject design, we could not include an interaction between subject and the within-factor unless we have multiple replications for each subject, as is the case here. We can therefore include both subject identifier and experimental factor, as well as their interaction. Note that in <code>lme4</code> package, the random effects are specified inside parenthesis.</p>
<div class="example">
<p><span id="exm:unlabeled-div-27" class="example"><strong>Example 10.1  (Happy fakes, remixed) </strong></span>We consider again the experiment of Amirabdolahian and Ali-Adeeb (2021) on smiling fakes and the emotion, this time from a pure mixed model perspective. This means we can simply keep all observations and model them accordingly.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-aafulldat"></span>
<img src="10-mixed_files/figure-html/fig-aafulldat-1.png" alt="Jittered scatterplot of individual measurements per participant and stimulus type." width="85%"><p class="caption">
Figure 10.1: Jittered scatterplot of individual measurements per participant and stimulus type.
</p>
</div>
<p>Figure <a href="introduction-to-mixed-models.html#fig:fig-aafulldat">10.1</a> shows the raw measurements, including what are notable outliers that may be due to data acquisition problems or instrumental manipulations. Since the experiment was performed in a non-controlled setting (pandemic) with different apparatus and everyone acting as their own technician, it is unsurprising that the signal-to-noise ratio is quite small. We will exclude here (rather arbitrarily) measurements below a latency of minus 40.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/runehaubo/lmerTestR">lmerTest</a></span><span class="op">)</span> </span>
<span><span class="co"># fit and tests for mixed models</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html">options</a></span><span class="op">(</span>contrasts <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"contr.sum"</span>, <span class="st">"contr.poly"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mixedmod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lmerTest/man/lmer.html">lmer</a></span><span class="op">(</span></span>
<span>  <span class="va">latency</span> <span class="op">~</span> <span class="va">stimulus</span> <span class="op">+</span> </span>
<span>    <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span> <span class="op">+</span> <span class="co"># random effect for subject</span></span>
<span>    <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">:</span><span class="va">stimulus</span><span class="op">)</span>, </span>
<span>  <span class="co"># random effect for interaction </span></span>
<span>  data <span class="op">=</span> <span class="fu">hecedsm</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/hecedsm/man/AA21.html">AA21</a></span> <span class="op">|&gt;</span> <span class="co">#remove outliers</span></span>
<span>    <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">latency</span> <span class="op">&gt;</span> <span class="op">-</span><span class="fl">40</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Output parameter estimates</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">mixedmod</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed model fit by REML ['lmerModLmerTest']</span></span>
<span><span class="co">#&gt; Formula: latency ~ stimulus + (1 | id) + (1 | id:stimulus)</span></span>
<span><span class="co">#&gt;    Data: dplyr::filter(hecedsm::AA21, latency &gt; -40)</span></span>
<span><span class="co">#&gt; REML criterion at convergence: 8008</span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups      Name        Std.Dev.</span></span>
<span><span class="co">#&gt;  id:stimulus (Intercept) 0.737   </span></span>
<span><span class="co">#&gt;  id          (Intercept) 2.268   </span></span>
<span><span class="co">#&gt;  Residual                6.223   </span></span>
<span><span class="co">#&gt; Number of obs: 1227, groups:  id:stimulus, 36; id, 12</span></span>
<span><span class="co">#&gt; Fixed Effects:</span></span>
<span><span class="co">#&gt; (Intercept)    stimulus1    stimulus2  </span></span>
<span><span class="co">#&gt;     -10.537       -0.253       -0.139</span></span></code></pre></div>
<p>We see that there is quite a bit of heterogeneity between participants and per stimulus participant pair, albeit less so for the interaction. All estimated variance terms are rather large.</p>
<p>We can also look globally at the statistical evidence for the</p>
<pre><code>#&gt; Type III Analysis of Variance Table with Satterthwaite's method
#&gt;          Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F)
#&gt; stimulus   65.6    32.8     2  23.3    0.85   0.44</code></pre>
<p>The global <span class="math inline">\(F\)</span> test of significance for stimulus is based on an approximation; the denominator degrees of freedom for the approximate <span class="math inline">\(F\)</span> statistic are based on Satterthwaite’s method, which provides a correction. There is again no evidence of differences between experimental conditions. This is rather unsurprising if we look at the raw data in Figure <a href="introduction-to-mixed-models.html#fig:fig-aafulldat">10.1</a>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-28" class="example"><strong>Example 10.2  (Verbalization and memorization) </strong></span>We consider a replication study of <span class="citation">Elliott et al. (<a href="references.html#ref-Elliot:2021" role="doc-biblioref">2021</a>)</span>,
which studied verbalization and verbalization of kids aged 5, 6, 7 and 10. The replication was performed in 17 different school labs, adapting a protocol of <span class="citation">Flavell, Beach, and Chinsky (<a href="references.html#ref-Flavell:1966" role="doc-biblioref">1966</a>)</span>, with an overall sample of 977 child partaking in the experiment.</p>
<p>Each participant was assigned to three tasks (<code>timing</code>): <code>delayed</code> recall with 15 seconds wait, or <code>immediate</code>, and finally a naming task (<code>point-and-name</code>). The <code>taskorder</code> variable records the order in which these were presented: the order of <code>delayed</code> and <code>immediate</code> was counterbalanced across individuals, with the naming task always occurring last. The response variable is the number of words correctly recalled out of five. The experimenters also recorded the frequency at which students spontaneously verbalized during the task (except the naming task, where they were instructed to do so).</p>
<p>The timing is a within-subject factor, whereas task order and age are between-subject factors: we are particularly interested in the speech frequency and the improvement over time (pairwise differences and trend).</p>
<p>To fit the linear mixed model with a random effect for both children <code>id</code> and <code>lab</code>: since children are nested in lab, we must specify the random effects via <code>(1 | id:lab) + (1 | lab)</code> if <code>id</code> are not unique.</p>
<p>We modify the data to keep only 5 and 6 years old students, since most older kids verbalized during the task and we would have large disbalance (14 ten years old out of 235, and 19 out of 269 seven years old). We also exclude the point-and-name task, since verbalization was part of the instruction. This leaves us with <span class="math inline">\(1419\)</span> observations and we can check that there are indeed enough children in each condition to get estimates.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">MULTI21_D2</span>, package <span class="op">=</span> <span class="st">"hecedsm"</span><span class="op">)</span></span>
<span><span class="va">MULTI21_D2_sub</span> <span class="op">&lt;-</span> <span class="va">MULTI21_D2</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span></span>
<span>    <span class="va">age</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"5yo"</span>, <span class="st">"6yo"</span><span class="op">)</span>,</span>
<span>    <span class="va">timing</span> <span class="op">!=</span> <span class="st">"point-and-name"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    verbalization <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">frequency</span> <span class="op">!=</span> <span class="st">"never"</span>,</span>
<span>                           labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"no"</span>, <span class="st">"yes"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    age <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">age</span><span class="op">)</span><span class="op">)</span> <span class="co"># drop unused age levels</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/xtabs.html">xtabs</a></span><span class="op">(</span><span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">verbalization</span>, data <span class="op">=</span> <span class="va">MULTI21_D2_sub</span><span class="op">)</span></span>
<span><span class="co">#&gt;      verbalization</span></span>
<span><span class="co">#&gt; age    no yes</span></span>
<span><span class="co">#&gt;   5yo 106 334</span></span>
<span><span class="co">#&gt;   6yo  56 450</span></span></code></pre></div>
<p>Given that we have multiple students of every age group, we can include two-way and three-way interactions in the <span class="math inline">\(2^3\)</span> design. We also include random effects for the student and the lab.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/runehaubo/lmerTestR">lmerTest</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rvlenth/emmeans">emmeans</a></span><span class="op">)</span></span>
<span><span class="va">hmod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lmerTest/man/lmer.html">lmer</a></span><span class="op">(</span></span>
<span>  <span class="va">mcorrect</span> <span class="op">~</span> <span class="va">age</span><span class="op">*</span><span class="va">timing</span><span class="op">*</span><span class="va">verbalization</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">:</span><span class="va">lab</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">lab</span><span class="op">)</span>, </span>
<span>  data <span class="op">=</span> <span class="va">MULTI21_D2_sub</span><span class="op">)</span></span>
<span><span class="co"># Parameter estimates</span></span>
<span><span class="co">#summary(hmod)</span></span></code></pre></div>
<p>We focus here on selected part of the output from <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> giving the estimated variance terms.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id:lab   (Intercept) 0.3587   0.599   </span></span>
<span><span class="co">#&gt;  lab      (Intercept) 0.0625   0.250   </span></span>
<span><span class="co">#&gt;  Residual             0.6823   0.826   </span></span>
<span><span class="co">#&gt; Number of obs: 946, groups:  id:lab, 473; lab, 17</span></span></code></pre></div>
<p>We can interpret the results as follows: the total variance is the sum of the <code>id</code>, <code>lab</code> and <code>residual</code> variances components give us an all but negligible effect of lab with 7 percent of the total variance, versus 40.5 percent for the children-specific variability. Since there are only 17 labs, and most of the individual specific variability is at the children level, the random effect for lab doesn’t add much to the correlation.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">hmod</span>, ddf <span class="op">=</span> <span class="st">"Kenward-Roger"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Type III Analysis of Variance Table with Kenward-Roger's method</span></span>
<span><span class="co">#&gt;                          Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; age                       20.50   20.50     1   459   30.05  7e-08 ***</span></span>
<span><span class="co">#&gt; timing                     3.25    3.25     1   469    4.76   0.03 *  </span></span>
<span><span class="co">#&gt; verbalization             13.61   13.61     1   459   19.94  1e-05 ***</span></span>
<span><span class="co">#&gt; age:timing                 0.24    0.24     1   469    0.36   0.55    </span></span>
<span><span class="co">#&gt; age:verbalization          0.08    0.08     1   462    0.12   0.72    </span></span>
<span><span class="co">#&gt; timing:verbalization       2.64    2.64     1   469    3.88   0.05 *  </span></span>
<span><span class="co">#&gt; age:timing:verbalization   0.27    0.27     1   469    0.40   0.53    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co"># Check estimated marginal means for age</span></span>
<span><span class="va">emm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">hmod</span>, specs <span class="op">=</span> <span class="st">"age"</span><span class="op">)</span></span>
<span><span class="va">emm</span></span>
<span><span class="co">#&gt;  age emmean     SE   df lower.CL upper.CL</span></span>
<span><span class="co">#&gt;  5yo   1.85 0.0914 35.8     1.67     2.04</span></span>
<span><span class="co">#&gt;  6yo   2.44 0.1053 60.9     2.23     2.65</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Results are averaged over the levels of: timing, verbalization </span></span>
<span><span class="co">#&gt; Degrees-of-freedom method: kenward-roger </span></span>
<span><span class="co">#&gt; Confidence level used: 0.95</span></span>
<span><span class="co"># Pairwise differences</span></span>
<span><span class="va">pairdiff</span> <span class="op">&lt;-</span> <span class="va">emm</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">pairdiff</span></span>
<span><span class="co">#&gt;  contrast  estimate    SE  df t.ratio p.value</span></span>
<span><span class="co">#&gt;  5yo - 6yo    -0.59 0.108 459  -5.480  &lt;.0001</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Results are averaged over the levels of: timing, verbalization </span></span>
<span><span class="co">#&gt; Degrees-of-freedom method: kenward-roger</span></span></code></pre></div>
<p>The type III ANOVA table shows that there is no evidence of interaction between task order, age and verbalization (no three-interaction) and a very small difference for timing and verbalization. Thus, we could compute the estimated marginal means for age with an estimated correct number of words of 1.854 (95% confidence interval of [1.669, 2.04]) words out of 5 for the 5 years olds and 2.445 (95% CI [2.234, 2.655]) words for six years old. Note that, despite the very large number children in the experiment, the degrees of freedom from the Kenward–Roger method are much fewer, respectively 35.827 and 60.944 for five and six years old.</p>
<p>The <span class="math inline">\(t\)</span>-test for the pairwise difference of the marginal effect is 0.59 words with standard error 0.108. Judging from the output, the degrees of freedom calculation for the pairwise <span class="math inline">\(t\)</span>-test are erroneous — they seem to be some average between the number of entries for the five years old (440) and six years old (506), but this fails to account for the fact that each kid is featured twice. Given the large magnitude of the ratio, this still amounts to strong result provided the standard error is correct.</p>
<p>We can easily see the limited interaction and strong main effects from the interaction plot in Figure <a href="introduction-to-mixed-models.html#fig:fig-interactionrecall">10.2</a>. The confidence intervals are of different width because of the sample inbalance.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-interactionrecall"></span>
<img src="10-mixed_files/figure-html/fig-interactionrecall-1.png" alt="Interaction plot for the recall task for younger children." width="85%"><p class="caption">
Figure 10.2: Interaction plot for the recall task for younger children.
</p>
</div>
</div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="repeated-measures-and-multivariate-models.html"><span class="header-section-number">9</span> Repeated measures and multivariate models</a></div>
<div class="next"><a href="causal-inference.html"><span class="header-section-number">11</span> Causal inference</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#introduction-to-mixed-models"><span class="header-section-number">10</span> Introduction to mixed models</a></li>
<li><a class="nav-link" href="#fixed-vs-random-effects"><span class="header-section-number">10.1</span> Fixed vs random effects</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/lbelzile/math80667a/blob/master/10-mixed.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/lbelzile/math80667a/edit/master/10-mixed.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Experimental Design and Statistical Methods</strong>" was written by Léo Belzile. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
