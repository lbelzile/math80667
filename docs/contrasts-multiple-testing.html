<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>4 Contrasts and multiple testing | Experimental Design and Statistical Methods</title>
<meta name="author" content="Léo Belzile">
<meta name="description" content="The analysis of variance model tests the (global) null hypothesis that the average of all groups is equal. In an experimental context, this implies one or more of the manipulation has a different...">
<meta name="generator" content="bookdown 0.29 with bs4_book()">
<meta property="og:title" content="4 Contrasts and multiple testing | Experimental Design and Statistical Methods">
<meta property="og:type" content="book">
<meta property="og:description" content="The analysis of variance model tests the (global) null hypothesis that the average of all groups is equal. In an experimental context, this implies one or more of the manipulation has a different...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="4 Contrasts and multiple testing | Experimental Design and Statistical Methods">
<meta name="twitter:description" content="The analysis of variance model tests the (global) null hypothesis that the average of all groups is equal. In an experimental context, this implies one or more of the manipulation has a different...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.1/transition.js"></script><script src="libs/bs3compat-0.4.1/tabs.js"></script><script src="libs/bs3compat-0.4.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Experimental Design and Statistical Methods</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Experimental Design and Statistical Methods</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">2</span> Hypothesis testing</a></li>
<li><a class="" href="CRT.html"><span class="header-section-number">3</span> Completely randomized designs</a></li>
<li><a class="active" href="contrasts-multiple-testing.html"><span class="header-section-number">4</span> Contrasts and multiple testing</a></li>
<li><a class="" href="complete-factorial-designs.html"><span class="header-section-number">5</span> Complete factorial designs</a></li>
<li><a class="" href="designs-to-reduce-the-error.html"><span class="header-section-number">6</span> Designs to reduce the error</a></li>
<li><a class="" href="effect-sizes-and-power.html"><span class="header-section-number">7</span> Effect sizes and power</a></li>
<li><a class="" href="replication-crisis.html"><span class="header-section-number">8</span> Replication crisis</a></li>
<li><a class="" href="repeated-measures-and-multivariate-models.html"><span class="header-section-number">9</span> Repeated measures and multivariate models</a></li>
<li><a class="" href="introduction-to-mixed-models.html"><span class="header-section-number">10</span> Introduction to mixed models</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/lbelzile/math80667a">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="contrasts-multiple-testing" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> Contrasts and multiple testing<a class="anchor" aria-label="anchor" href="#contrasts-multiple-testing"><i class="fas fa-link"></i></a>
</h1>
<p>The analysis of variance model tests the (global) null hypothesis that the average of all groups is equal. In an experimental context, this implies one or more of the manipulation has a different effect from the others on the mean response. Oftentimes, this isn’t interesting in itself: we could be interested in comparing different options relative to a <em>status quo</em>, or determine whether specific combinations work better than separately. The scientific question of interest that warranted the experiment may lead to a specific set of hypotheses, which can be formulated by researchers as comparisons between means of different subgroups.</p>
<div id="contrasts" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> Contrasts<a class="anchor" aria-label="anchor" href="#contrasts"><i class="fas fa-link"></i></a>
</h2>
<p>We can normally express these as <strong>contrasts</strong>. As <a href="https://stat.ethz.ch/~meier">Dr. Lukas Meier</a> puts it, if the global <span class="math inline">\(F\)</span>-test for equality of means is equivalent to a dimly lit room, contrasts are akin to spotlight that let one focus on particular aspects of differences in treatments.</p>
<p>More formally speaking, a contrast is a linear combination of averages: in plain English, this means we assign a weight to each group average and add them up. We can then build a <span class="math inline">\(t\)</span> statistic as usual by standardizing the resulting weighted sum of the group means.</p>
<p>If <span class="math inline">\(c_i\)</span> denotes the weight of group average <span class="math inline">\(\mu_i\)</span> <span class="math inline">\((i=1, \ldots, K)\)</span>, then we can write the contrast as <span class="math inline">\(C = c_1 \mu_1 + \cdots + c_K \mu_K\)</span> with the null hypothesis <span class="math inline">\(\mathscr{H}_0: C=a\)</span> for a two-sided alternative, for <span class="math inline">\(a\)</span> a numeric value like 0. The sample estimate of the linear contrast is obtained by replacing the unknown population average <span class="math inline">\(\mu_i\)</span> by the sample average of that group, <span class="math inline">\(\widehat{\mu}_i = \overline{y}_{i}\)</span>. We can easily obtain the standard error of the linear combination <span class="math inline">\(C\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Should you need the formula, the standard error assuming sample size of &lt;span class="math inline"&gt;\(n_1, \ldots, n_K\)&lt;/span&gt; and a common variance &lt;span class="math inline"&gt;\(\sigma^2\)&lt;/span&gt; is &lt;span class="math inline"&gt;\(\sqrt{\mathsf{Va}(\widehat{C})}\)&lt;/span&gt;, where &lt;span class="math display"&gt;\[\mathsf{Va}(\widehat{C}) = \widehat{\sigma}^2\left(\frac{c_1^2}{n_1} + \cdots + \frac{c_K^2}{n_K}\right).\]&lt;/span&gt;&lt;/p&gt;'><sup>29</sup></a></p>
<p>Contrasts encode research question of interest, taking the form <span class="math inline">\(\mathscr{H}_0: c_1 \mu_1 + \cdots + c_K\mu_K = a\)</span>, where the numerical value <span class="math inline">\(a\)</span> is typically zero.</p>
<div id="orthogonal-contrasts" class="section level3" number="4.1.1">
<h3>
<span class="header-section-number">4.1.1</span> Orthogonal contrasts<a class="anchor" aria-label="anchor" href="#orthogonal-contrasts"><i class="fas fa-link"></i></a>
</h3>
<p>Sometimes, linear contrasts encode disjoint bits of information about the sample: for example, one contrast that compares groups the first two groups versus one that compares the third and fourth is in effect using data from two disjoint samples, as contrasts will be based on sample averages. Whenever the contrasts vectors are orthogonal, the tests will be uncorrelated as they contain independent bits of information from the population.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The constraint &lt;span class="math inline"&gt;\(c_1 + \cdots + c_K=0\)&lt;/span&gt; ensures that linear contrasts are orthogonal to the mean, which has weight &lt;span class="math inline"&gt;\(c_i=n_i/n\)&lt;/span&gt; and for balanced samples &lt;span class="math inline"&gt;\(c_i =1/n\)&lt;/span&gt;.&lt;/p&gt;'><sup>30</sup></a> Mathematically, if we let <span class="math inline">\(c_{i}\)</span> and <span class="math inline">\(c^{*}_{i}\)</span> denote weights attached to the mean of group <span class="math inline">\(i\)</span> comprising <span class="math inline">\(n_i\)</span> observations, contrasts are orthogonal if <span class="math inline">\(c_{1}c^{*}_{1}/n_1 + \cdots + c_{K}c^{*}_K/n_K = 0\)</span>; if the sample is balanced with the same number of observations in each group, <span class="math inline">\(n/K = n_1 =\cdots = n_K\)</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;This is the dot product of the two contrast vectors&lt;/p&gt;"><sup>31</sup></a>. If we have <span class="math inline">\(K\)</span> groups, there are <span class="math inline">\(K-1\)</span> contrasts for pairwise differences, the last one being captured by the sample mean for the overall effect.If we care only about difference between groups (as opposed to the overall effect of all treatments), we impose a sum-to-zero constraint on the weights so <span class="math inline">\(c_1 + \cdots + c_K=0\)</span>. This ensures<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The sample mean for a balanced sample amounts to equi-weighted average of the groups, i.e., a contrast with weight vector &lt;span class="math inline"&gt;\((1, 1, \ldots, 1)\)&lt;/span&gt;. Thus, any contrast whose elements sum to zero is orthogonal to the global mean. End of the mathematical digression.&lt;/p&gt;'><sup>32</sup></a> Keep in mind that, although independent tests are nice mathematically, contrasts should encode the hypothesis of interest to the researchers: we choose contrasts because they are meaningful, not because they are orthogonal.</p>
<div class="example">
<p><span id="exm:unlabeled-div-17" class="example"><strong>Example 4.1  (Contrasts for encouragement on teaching) </strong></span>The <code>arithmetic</code> data example considered five different treatment groups with 9 individuals in each. Two of them were control groups, one received praise, another was reproved and the last was ignored.</p>
<p>Suppose that researchers were interested in assessing whether the experimental manipulation had an effect, and whether the impact of positive and negative feedback is the same on students.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;These would be formulated &lt;em&gt;at registration time&lt;/em&gt;, but for the sake of the argument we proceed as if they were.&lt;/p&gt;"><sup>33</sup></a></p>
<p>Suppose we have five groups in the order (control 1, control 2, praised, reproved, ignored).
We can express these hypothesis as</p>
<ul>
<li>
<span class="math inline">\(\mathscr{H}_{01}\)</span>: <span class="math inline">\(\mu_{\text{praise}} = \mu_{\text{reproved}}\)</span>
</li>
<li>
<span class="math inline">\(\mathscr{H}_{02}\)</span>:
<span class="math display">\[\begin{align*}
\frac{1}{2}(\mu_{\text{control}_1}+\mu_{\text{control}_2}) = \frac{1}{3}\mu_{\text{praised}} + \frac{1}{3}\mu_{\text{reproved}} + \frac{1}{3}\mu_{\text{ignored}}
\end{align*}\]</span>
</li>
</ul>
<p>Note that, for the hypothesis of control vs experimental manipulation, we look at average of the different groups associated with each item. Using the ordering, the weights of the contrast vector are <span class="math inline">\((1/2, 1/2, -1/3, -1/3, -1/3)\)</span> and <span class="math inline">\((0, 0, 1, -1, 0)\)</span>. There are many equivalent formulation: we could multiply the weights by any number (different from zero) and we would get the same test statistic, as the latter is standardized.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rvlenth/emmeans">emmeans</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">arithmetic</span>, package <span class="op">=</span> <span class="st">"hecedsm"</span><span class="op">)</span></span>
<span><span class="va">linmod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/aov.html">aov</a></span><span class="op">(</span><span class="va">score</span> <span class="op">~</span> <span class="va">group</span>, data <span class="op">=</span> <span class="va">arithmetic</span><span class="op">)</span></span>
<span><span class="va">linmod_emm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">linmod</span>, specs <span class="op">=</span> <span class="st">'group'</span><span class="op">)</span></span>
<span><span class="va">contrast_specif</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  controlvsmanip <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="op">-</span><span class="fl">1</span><span class="op">/</span><span class="fl">3</span>, <span class="op">-</span><span class="fl">1</span><span class="op">/</span><span class="fl">3</span>, <span class="op">-</span><span class="fl">1</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span>,</span>
<span>  praisedvsreproved <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">contrasts_res</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/contrast.html">contrast</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">linmod_emm</span>, </span>
<span>                    method <span class="op">=</span> <span class="va">contrast_specif</span><span class="op">)</span></span>
<span><span class="co"># Obtain confidence intervals instead of p-values</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">contrasts_res</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:left;">
contrast
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std. error
</th>
<th style="text-align:right;">
df
</th>
<th style="text-align:right;">
lower conf. limit
</th>
<th style="text-align:right;">
upper conf. limit
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
control vs manip
</td>
<td style="text-align:right;">
-3.33
</td>
<td style="text-align:right;">
1.05
</td>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
-5.45
</td>
<td style="text-align:right;">
-1.22
</td>
</tr>
<tr>
<td style="text-align:left;">
praised vs reproved
</td>
<td style="text-align:right;">
4.00
</td>
<td style="text-align:right;">
1.62
</td>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
7.28
</td>
</tr>
</tbody>
</table></div>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-18" class="example"><strong>Example 4.2  (Teaching to read) </strong></span>We consider data from <span class="citation">Baumann, Seifert-Kessell, and Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span>. The abstract of the paper provides a brief description of the study</p>
<blockquote>
<p>This study investigated the effectiveness of explicit instruction in think aloud as a means to promote elementary students’ comprehension monitoring abilities. Sixty-six fourth-grade students were randomly assigned to one of three experimental groups: (a) a Think-Aloud (TA) group, in which students were taught various comprehension monitoring strategies for reading stories (e.g., self-questioning, prediction, retelling, rereading) through the medium of thinking aloud; (b) a Directed reading-Thinking Activity (DRTA) group, in which students were taught a predict-verify strategy for reading and responding to stories; or (c) a Directed reading Activity (DRA) group, an instructed control, in which students engaged in a noninteractive, guided reading of stories.</p>
</blockquote>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rvlenth/emmeans">emmeans</a></span><span class="op">)</span> <span class="co">#load package</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">BSJ92</span>, package <span class="op">=</span> <span class="st">"hecedsm"</span><span class="op">)</span></span>
<span><span class="va">mod_post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/aov.html">aov</a></span><span class="op">(</span><span class="va">posttest1</span> <span class="op">~</span> <span class="va">group</span>, data <span class="op">=</span> <span class="va">BSJ92</span><span class="op">)</span></span>
<span><span class="va">emmeans_post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">mod_post</span>, </span>
<span>                        specs <span class="op">=</span> <span class="st">"group"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:print-pairwise-baumann">Table 4.1: </span>Estimated group averages with standard errors and 95% confidence intervals for post-test 1.
</caption>
<thead><tr>
<th style="text-align:left;">
Terms
</th>
<th style="text-align:right;">
Marginal mean
</th>
<th style="text-align:right;">
Standard error
</th>
<th style="text-align:right;">
Degrees of freedom
</th>
<th style="text-align:right;">
Lower limit (CI)
</th>
<th style="text-align:right;">
Upper limit (CI)
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
DR
</td>
<td style="text-align:right;">
6.68
</td>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
63
</td>
<td style="text-align:right;">
5.32
</td>
<td style="text-align:right;">
8.04
</td>
</tr>
<tr>
<td style="text-align:left;">
DRTA
</td>
<td style="text-align:right;">
9.77
</td>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
63
</td>
<td style="text-align:right;">
8.41
</td>
<td style="text-align:right;">
11.13
</td>
</tr>
<tr>
<td style="text-align:left;">
TA
</td>
<td style="text-align:right;">
7.77
</td>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
63
</td>
<td style="text-align:right;">
6.41
</td>
<td style="text-align:right;">
9.13
</td>
</tr>
</tbody>
</table></div>
<p>We can see that <code>DRTA</code> has the highest average, followed by <code>TA</code> and directed reading (<code>DR</code>).
The purpose of <span class="citation">Baumann, Seifert-Kessell, and Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span> was to make a particular comparison between treatment groups.
From the abstract:</p>
<blockquote>
<p>The primary quantitative analyses involved two planned orthogonal contrasts—effect of instruction (TA + DRTA vs. 2 x DRA) and intensity of instruction (TA vs. DRTA)—for three whole-sample dependent measures: (a) an error detection test, (b) a comprehension monitoring questionnaire, and (c) a modified cloze test.</p>
</blockquote>
<p>The hypothesis of <span class="citation">Baumann, Seifert-Kessell, and Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span> is <span class="math inline">\(\mathscr{H}_0: \mu_{\mathrm{TA}} + \mu_{\mathrm{DRTA}} = 2 \mu_{\mathrm{DRA}}\)</span>
or, rewritten slightly,
<span class="math display">\[\begin{align*}
\mathscr{H}_0: - 2 \mu_{\mathrm{DR}} + \mu_{\mathrm{DRTA}} + \mu_{\mathrm{TA}} = 0.
\end{align*}\]</span>
with weights <span class="math inline">\((-2, 1, 1)\)</span>; the order of the levels for the treatment are
(<span class="math inline">\(\mathrm{DRA}\)</span>, <span class="math inline">\(\mathrm{DRTA}\)</span>, <span class="math inline">\(\mathrm{TA}\)</span>) and it must match that of the coefficients.
An equivalent formulation is <span class="math inline">\((2, -1, -1)\)</span> or <span class="math inline">\((1, -1/2, -1/2)\)</span>: in either case, the estimated differences will be different
(up to a constant multiple or a sign change).
The vector of weights for <span class="math inline">\(\mathscr{H}_0: \mu_{\mathrm{TA}} = \mu_{\mathrm{DRTA}}\)</span>
is (<span class="math inline">\(0\)</span>, <span class="math inline">\(-1\)</span>, <span class="math inline">\(1\)</span>): the zero appears because the first component, <span class="math inline">\(\mathrm{DRA}\)</span> doesn’t appear.
The two contrasts are orthogonal since
<span class="math inline">\((-2 \times 0) + (1 \times -1) + (1 \times 1) = 0\)</span>.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Identify the order of the level of the variables</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">BSJ92</span>, <span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">group</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "DR"   "DRTA" "TA"</span></span>
<span><span class="co"># DR, DRTA, TA (alphabetical)</span></span>
<span><span class="va">contrasts_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  <span class="st">"C1: DRTA+TA vs 2DR"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, </span>
<span>  <span class="co"># Contrasts: linear combination of means, coefficients sum to zero</span></span>
<span>  <span class="co"># 2xDR = DRTA + TA =&gt; -2*DR + 1*DRTA + 1*TA = 0 and -2+1+1 = 0</span></span>
<span>  <span class="st">"C1: average (DRTA+TA) vs DR"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span><span class="op">)</span>, </span>
<span>  <span class="co">#same thing, but halved so in terms of average</span></span>
<span>  <span class="st">"C2: DRTA vs TA"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span>,</span>
<span>  <span class="st">"C2: TA vs DRTA"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span> </span>
<span>  <span class="co"># same, but sign flipped</span></span>
<span><span class="op">)</span></span>
<span><span class="va">contrasts_post</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/contrast.html">contrast</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">emmeans_post</span>,</span>
<span>           method <span class="op">=</span> <span class="va">contrasts_list</span><span class="op">)</span></span>
<span><span class="va">contrasts_summary_post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">contrasts_post</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:print-contrasts">Table 4.2: </span>Estimated contrasts for post-test 1.
</caption>
<thead><tr>
<th style="text-align:left;">
Contrast
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
Standard error
</th>
<th style="text-align:right;">
Degrees of freedom
</th>
<th style="text-align:right;">
t statistic
</th>
<th style="text-align:right;">
p-value
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
C1: DRTA+TA vs 2DR
</td>
<td style="text-align:right;">
4.18
</td>
<td style="text-align:right;">
1.67
</td>
<td style="text-align:right;">
63
</td>
<td style="text-align:right;">
2.51
</td>
<td style="text-align:right;">
0.01
</td>
</tr>
<tr>
<td style="text-align:left;">
C1: average (DRTA+TA) vs DR
</td>
<td style="text-align:right;">
2.09
</td>
<td style="text-align:right;">
0.83
</td>
<td style="text-align:right;">
63
</td>
<td style="text-align:right;">
2.51
</td>
<td style="text-align:right;">
0.01
</td>
</tr>
<tr>
<td style="text-align:left;">
C2: DRTA vs TA
</td>
<td style="text-align:right;">
2.00
</td>
<td style="text-align:right;">
0.96
</td>
<td style="text-align:right;">
63
</td>
<td style="text-align:right;">
2.08
</td>
<td style="text-align:right;">
0.04
</td>
</tr>
<tr>
<td style="text-align:left;">
C2: TA vs DRTA
</td>
<td style="text-align:right;">
-2.00
</td>
<td style="text-align:right;">
0.96
</td>
<td style="text-align:right;">
63
</td>
<td style="text-align:right;">
-2.08
</td>
<td style="text-align:right;">
0.04
</td>
</tr>
</tbody>
</table></div>
<p>We can look at these differences; since <code>DRTA</code> versus <code>TA</code> is a pairwise difference, we could have obtained the <span class="math inline">\(t\)</span>-statistic directly from the pairwise contrasts
using <code>pairs(emmeans_post)</code>. Note that the two different ways of writing the comparison between <code>DR</code> and the average of the other two methods yield different point estimates, but same inference (meaning the same <span class="math inline">\(p\)</span>-values). For contrast <span class="math inline">\(C_{1b}\)</span>, we get half the estimate (but the standard error is also halved) and likewise for the second contrasts we get an estimate of <span class="math inline">\(\mu_{\mathrm{DRTA}} - \mu_{\mathrm{TA}}\)</span> in the first case (<span class="math inline">\(C_2\)</span>) and <span class="math inline">\(\mu_{\mathrm{TA}} - \mu_{\mathrm{DRTA}}\)</span>: the difference in group averages is the same up to sign.</p>
<p>What is the conclusion of our analysis of contrasts?
It looks like the methods involving teaching aloud have a strong impact on reading comprehension relative to only directed reading. The evidence is not as strong
when we compare the method that combines directed reading-thinking activity and thinking aloud.</p>
</div>
</div>
</div>
<div id="multiple-testing" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> Multiple testing<a class="anchor" aria-label="anchor" href="#multiple-testing"><i class="fas fa-link"></i></a>
</h2>
<p>Beyond looking at the global null, we will be interested in a set of contrast statistics and typically this number can be large-ish. There is however a catch in starting to test multiple hypothesis at once.</p>
<p>If you do a <strong>single</strong> hypothesis test and the testing procedure is well calibrated (meaning that the model model assumptions hold), there is a probability of <span class="math inline">\(\alpha\)</span> of making a type I error if the null is true, meaning when there is no difference between averages in the underlying population. The problem of the above approach is that the more you look, the higher the chance of finding something: with 20 independent tests, we expect that, on average, one of them will yield a <span class="math inline">\(p\)</span>-value less than 5%. This, coupled with the tendency in the many fields to dichotomise the result of every test depending on whether <span class="math inline">\(p \leq \alpha\)</span> (statistically significant at level <span class="math inline">\(\alpha\)</span> or not leads to selective reporting of findings.</p>
<p>Not all tests are of interest, even if standard software will report all possible pairwise comparisons. However, the number of tests performed in the course of an analysis can be very large. Dr. Yoav Benjamini investigated the number of tests performed in each study of the Psychology replication project <span class="citation">(<a href="references.html#ref-Nosek:2015" role="doc-biblioref">Nosek et al. 2015</a>)</span>: this number ranged from 4 to 700, with an average of 72 per study. It is natural to ask then how many are spurious findings that correspond to type I errors. The paramount (absurd) illustration is the xkcd cartoon of Figure <a href="contrasts-multiple-testing.html#fig:xkcdsignificant">4.1</a>.</p>
<p>Not all tests are of interest, even if standard software will report all possible pairwise comparisons. If there are <span class="math inline">\(K\)</span> groups to compare and any comparison is of interest, than we could performs <span class="math inline">\(\binom{K}{2}\)</span> pairwise comparisons with <span class="math inline">\(\mathscr{H}_{0}: \mu_i = \mu_j\)</span> for <span class="math inline">\(i \neq j\)</span>. For <span class="math inline">\(K=3\)</span>, there are three such comparisons, 10 pairwise comparisons if <span class="math inline">\(K=5\)</span> and 45 pairwise comparisons if <span class="math inline">\(K=10\)</span>. Thus, some ‘discoveries’ are bound to be spurious.</p>
<p>The number of tests performed in the course of an analysis can be very large. Y. Benjamini investigated the number of tests performed in each study of the Psychology replication project <span class="citation">(<a href="references.html#ref-Nosek:2015" role="doc-biblioref">Nosek et al. 2015</a>)</span>: this number ranged from 4 to 700, with an average of 72 — most studies did not account for the fact they were performing multiple tests or selected the model. It is natural to ask then how many results are spurious findings that correspond to type I errors. The paramount (absurd) illustration is the cartoon presented in Figure <a href="contrasts-multiple-testing.html#fig:xkcdsignificant">4.1</a>: note how there is little scientific backing for the theory (thus such test shouldn’t be of interest to begin with) and likewise the selective reporting made of the conclusions, despite nuanced conclusions.</p>
<p>We can also assess mathematically the problem. Assume for simplicity that all tests are independent<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;This is the case if tests are based on different data, or if the contrasts considered are orthogonal under normality.&lt;/p&gt;"><sup>34</sup></a> and that each test is conducted at level <span class="math inline">\(\alpha\)</span>. The probability of making at least one type I error, say <span class="math inline">\(\alpha^{\star}\)</span>, is<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;The second line holds with independent observations, the second follows from the use of Boole’s inequality and does not require independent tests.&lt;/p&gt;"><sup>35</sup></a>
<span class="math display" id="eq:bonferroni">\[\begin{align}\alpha^{\star} &amp;= 1 – \text{probability of making no type I error} \\\ &amp;= 1- (1-\alpha)^m\\
&amp; \leq m\alpha
  \tag{4.1}
\end{align}\]</span></p>
<p>With <span class="math inline">\(\alpha = 5\)</span>% and <span class="math inline">\(m=4\)</span> tests, <span class="math inline">\(\alpha^{\star} \approx 0.185\)</span> whereas for <span class="math inline">\(m=72\)</span> tests, <span class="math inline">\(\alpha^{\star} \approx 0.975\)</span>: this means we are almost guaranteed even when nothing is going on to find “statistically significant” yet meaningless results.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:xkcdsignificant"></span>
<img src="figures/xkcd882_significant.png" alt="xkcd 882: Significant. The alt text is 'So, uh, we did the green study again and got no link. It was probably a--' 'RESEARCH CONFLICTED ON GREEN JELLY BEAN/ACNE LINK; MORE STUDY RECOMMENDED!'" width="85%"><p class="caption">
Figure 4.1: xkcd 882: Significant. The alt text is ‘So, uh, we did the green study again and got no link. It was probably a–’ ‘RESEARCH CONFLICTED ON GREEN JELLY BEAN/ACNE LINK; MORE STUDY RECOMMENDED!’
</p>
</div>
<p>It is sensible to try and reduce or bound the number of false positive or control the probability of getting spurious findings. We consider a <strong>family</strong> of <span class="math inline">\(m\)</span> null hypothesis <span class="math inline">\(\mathscr{H}_{01}, \ldots, \mathscr{H}_{0m}\)</span> tested. The family is simply a collection of <span class="math inline">\(m\)</span> hypothesis tests: the exact set depends on the context, but this comprises all hypothesis that are scientifically relevant and could be reported. These comparisons are called <strong>pre-planned comparisons</strong>: they should be chosen before the experiment takes place and pre-registered to avoid data dredging and selective reporting. The number of planned comparisons should be kept small relative to the number of parameters: for a one-way ANOVA, a general rule of thumb is to make no more comparisons than the number of groups, <span class="math inline">\(K\)</span>.</p>
<p>Suppose that we perform <span class="math inline">\(m\)</span> hypothesis tests in a study and define binary indicators
<span class="math display">\[\begin{align}
R_i &amp;= \begin{cases} 1 &amp; \text{if we reject the null hypothesis }  \mathscr{H}_{0i} \\
0 &amp; \text{if we fail to reject } \mathscr{H}_{0i}
\end{cases}\\
V_i &amp;=\begin{cases} 1 &amp; \text{type I error for } \mathscr{H}_{0i}\quad  (R_i=1 \text{ and  }\mathscr{H}_{0i} \text{ is true}) \\ 0 &amp; \text{otherwise}.
\end{cases}
\end{align}\]</span>
With this notation, <span class="math inline">\(R=R_1 + \cdots + R_m\)</span> simply encodes the total number of rejections (<span class="math inline">\(0 \leq R \leq m\)</span>), and <span class="math inline">\(V = V_1 + \cdots + V_m\)</span> is the number of null hypothesis rejected by mistake (<span class="math inline">\(0 \leq V \leq R\)</span>).</p>
<p>The <strong>familywise error rate</strong> is the probability of making at least one type I error per family,
<span class="math display">\[\begin{align*}
\mathsf{FWER} = \Pr(V \geq 1).
\end{align*}\]</span>
To control the familywise error rate, one must be more stringent in rejecting the null and perform each test with a smaller level <span class="math inline">\(\alpha\)</span> so that the overall or simultaneous probability is less than <span class="math inline">\(\mathsf{FWER}\)</span>.</p>
<div id="bonferronis-procedure" class="section level3" number="4.2.1">
<h3>
<span class="header-section-number">4.2.1</span> Bonferroni’s procedure<a class="anchor" aria-label="anchor" href="#bonferronis-procedure"><i class="fas fa-link"></i></a>
</h3>
<p>The easiest way (and one of the least powerful option) is to directly use the inequality in eq. <a href="contrasts-multiple-testing.html#eq:bonferroni">(4.1)</a>. If each test is performed at level <span class="math inline">\(\alpha/m\)</span>, than the family-wise error is controlled at level <span class="math inline">\(\alpha\)</span>.</p>
<p>The Bonferroni adjustment also controls the <strong>per-family error rate</strong>, which is the expected (theoretical average) number of false positive <span class="math inline">\(\mathsf{PFER} = \mathsf{E}(V)\)</span>. The latter is a more stringent criterion than the familywise error rate because <span class="math inline">\(\Pr(V \geq 1) \leq \mathsf{E}(V)\)</span>: the familywise error rate does not make a distinction between having one or multiple type I errors.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;By definition, the expected number of false positive (PFER) is &lt;span class="math inline"&gt;\(\mathsf{E}(V) = \sum_{i=1}^m i \Pr(V=i) \geq \sum_{i=1}^m \Pr(V=i) = \Pr(V \geq 1)\)&lt;/span&gt;, so larger than the probability of making at least type 1 error. Thus, any procedure that controls the per-family error rate (e.g., Bonferroni) also automatically bounds the familywise error rate.&lt;/p&gt;'><sup>36</sup></a></p>
<p>Why is Bonferroni’s procedure popular? It is conceptually easy to understand and simple, and it applies to any design and regardless of the dependence between the tests. However, the number of tests to adjust for, <span class="math inline">\(m\)</span>, must be prespecified and the procedure leads to low power when the size of the family is large. Moreover, if our sole objective is to control for the familywise error rate, then there are other procedures that are always better in the sense that they still control the <span class="math inline">\(\mathsf{FWER}\)</span> while leading to increased capacity of detection when the null is false.</p>
<p>If the raw (i.e., unadjusted) <span class="math inline">\(p\)</span>-values are reported, we reject hypothesis <span class="math inline">\(\mathscr{H}_{0i}\)</span> if <span class="math inline">\(m \times p_i \ge \alpha\)</span>: operationally, we multiply each <span class="math inline">\(p\)</span>-value by <span class="math inline">\(m\)</span> and reject if the result exceeds <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div id="holm-bonferronis-procedure" class="section level3" number="4.2.2">
<h3>
<span class="header-section-number">4.2.2</span> Holm-Bonferroni’s procedure<a class="anchor" aria-label="anchor" href="#holm-bonferronis-procedure"><i class="fas fa-link"></i></a>
</h3>
<p>The idea of Holm’s procedure is to use a sharper inequality bound and amounts to performing tests at different levels, with more stringent for smaller <span class="math inline">\(p\)</span>-values.</p>
<p>Order the <span class="math inline">\(p\)</span>-values of the family of <span class="math inline">\(m\)</span> tests from smallest to largest
<span class="math inline">\(p_{(1)} \leq \cdots \leq p_{(m)}\)</span> and test sequentially the hypotheses. Coupling Holm’s method with Bonferroni’s procedure, we compare <span class="math inline">\(p_{(1)}\)</span> to <span class="math inline">\(\alpha_{(1)} = \alpha/m\)</span>, <span class="math inline">\(p_{(2)}\)</span> to <span class="math inline">\(\alpha_{(2)}=\alpha/(m-1)\)</span>, etc.</p>
<p>If all of the <span class="math inline">\(p\)</span>-values are less than their respective levels, than we still reject each null hypothesis. Otherwise, we reject all the tests whose <span class="math inline">\(p\)</span>-values exceeds the smallest nonsignificant one. If <span class="math inline">\(p_{(j)} \geq \alpha_{(j)}\)</span> but <span class="math inline">\(p_{(i)} \leq \alpha_{(i)}\)</span> for <span class="math inline">\(i=1, \ldots, j-1\)</span> (all smaller <span class="math inline">\(p\)</span>-values), we reject the associated hypothesis <span class="math inline">\(\mathscr{H}_{0(1)}, \ldots, \mathscr{H}_{0(j-1)}\)</span> but fail to reject <span class="math inline">\(\mathscr{H}_{0(j)}, \ldots, \mathscr{H}_{0(m)}\)</span>.</p>
<p>This procedure doesn’t control the per-family error rate, but is uniformly more powerful and thus leads to increased detection than Bonferroni’s method.</p>
<p>To see this, consider a family of <span class="math inline">\(m=3\)</span> <span class="math inline">\(p\)</span>-values with values <span class="math inline">\(0.01\)</span>, <span class="math inline">\(0.04\)</span> and <span class="math inline">\(0.02\)</span>. Bonferroni’s adjustment would lead us to reject the second and third hypotheses at level <span class="math inline">\(\alpha=0.05\)</span>, but not Holm-Bonferroni.</p>
<p><strong>To be continued</strong>…</p>

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="CRT.html"><span class="header-section-number">3</span> Completely randomized designs</a></div>
<div class="next"><a href="complete-factorial-designs.html"><span class="header-section-number">5</span> Complete factorial designs</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#contrasts-multiple-testing"><span class="header-section-number">4</span> Contrasts and multiple testing</a></li>
<li>
<a class="nav-link" href="#contrasts"><span class="header-section-number">4.1</span> Contrasts</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#orthogonal-contrasts"><span class="header-section-number">4.1.1</span> Orthogonal contrasts</a></li></ul>
</li>
<li>
<a class="nav-link" href="#multiple-testing"><span class="header-section-number">4.2</span> Multiple testing</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#bonferronis-procedure"><span class="header-section-number">4.2.1</span> Bonferroni’s procedure</a></li>
<li><a class="nav-link" href="#holm-bonferronis-procedure"><span class="header-section-number">4.2.2</span> Holm-Bonferroni’s procedure</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/lbelzile/math80667a/blob/master/04-contrasts_multipletesting.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/lbelzile/math80667a/edit/master/04-contrasts_multipletesting.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Experimental Design and Statistical Methods</strong>" was written by Léo Belzile. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
