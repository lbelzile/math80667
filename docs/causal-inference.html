<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>11 Causal inference | Experimental Design and Statistical Methods</title>
<meta name="author" content="Léo Belzile">
<meta name="description" content="A pet peeve of statisticians is to state that correlation (or association) between two phenomena is not the same as causation. For example, weather forecasts of rain and the number of people...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="11 Causal inference | Experimental Design and Statistical Methods">
<meta property="og:type" content="book">
<meta property="og:description" content="A pet peeve of statisticians is to state that correlation (or association) between two phenomena is not the same as causation. For example, weather forecasts of rain and the number of people...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="11 Causal inference | Experimental Design and Statistical Methods">
<meta name="twitter:description" content="A pet peeve of statisticians is to state that correlation (or association) between two phenomena is not the same as causation. For example, weather forecasts of rain and the number of people...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.1/transition.js"></script><script src="libs/bs3compat-0.4.1/tabs.js"></script><script src="libs/bs3compat-0.4.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Experimental Design and Statistical Methods</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Experimental Design and Statistical Methods</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">2</span> Hypothesis testing</a></li>
<li><a class="" href="CRT.html"><span class="header-section-number">3</span> Completely randomized designs</a></li>
<li><a class="" href="contrasts-multiple-testing.html"><span class="header-section-number">4</span> Contrasts and multiple testing</a></li>
<li><a class="" href="complete-factorial-designs.html"><span class="header-section-number">5</span> Complete factorial designs</a></li>
<li><a class="" href="designs-to-reduce-the-error.html"><span class="header-section-number">6</span> Designs to reduce the error</a></li>
<li><a class="" href="effect-sizes-and-power.html"><span class="header-section-number">7</span> Effect sizes and power</a></li>
<li><a class="" href="replication-crisis.html"><span class="header-section-number">8</span> Replication crisis</a></li>
<li><a class="" href="repeated-measures-and-multivariate-models.html"><span class="header-section-number">9</span> Repeated measures and multivariate models</a></li>
<li><a class="" href="introduction-to-mixed-models.html"><span class="header-section-number">10</span> Introduction to mixed models</a></li>
<li><a class="active" href="causal-inference.html"><span class="header-section-number">11</span> Causal inference</a></li>
<li><a class="" href="nonparametric-tests.html"><span class="header-section-number">12</span> Nonparametric tests</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/lbelzile/math80667a">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="causal-inference" class="section level1" number="11">
<h1>
<span class="header-section-number">11</span> Causal inference<a class="anchor" aria-label="anchor" href="#causal-inference"><i class="fas fa-link"></i></a>
</h1>
<p>A pet peeve of statisticians is to state that correlation (or association) between two phenomena is not the same as causation. For example, weather forecasts of rain and the number of people carrying umbrellas in the streets are positively correlated, but the relationship is directed: if I intervene as an experimenter and force everyone around to carry umbrellas, it won’t impact weather forecasts nor the weather itself. The website <a href="https://tylervigen.com/spurious-correlations">Spurious correlations</a> by Tyler Vigen shows multiple graphs of absurd relations, many of which are simply artefact of population growth.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:xkcd2569"></span>
<img src="figures/xkcd552_correlation.png" alt="xkcd comic [552 (Correlation) by Randall Munroe](https://xkcd.com/552/). Alt text: Correlation doesn't imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing 'look over there'. Cartoon reprinted under the [CC BY-NC 2.5 license](https://creativecommons.org/licenses/by-nc/2.5/)." width="60%"><p class="caption">
Figure 2.1: xkcd comic <a href="https://xkcd.com/552/">552 (Correlation) by Randall Munroe</a>. Alt text: Correlation doesn’t imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’. Cartoon reprinted under the <a href="https://creativecommons.org/licenses/by-nc/2.5/">CC BY-NC 2.5 license</a>.
</p>
</div>
<p>Causal inference is concerned with inferring the effect of an action or manipulation (intervention, policy, or treatment) applied to an observational unit and identifying and quantifying the effect of one variable on other variables. Such action may be conceptual: we can imagine for example looking at student’s success (as measured by their grades) by comparing two policies: giving them timely feedback and encouragement, versus no feedback. In reality, only one of these two scenarios can be realized even if both can conceptually be envisioned as <strong>potential outcomes</strong>.</p>
<p>The content of this chapter is divided as follows. First, we discuss the logical interrelation between variables using directed acyclic graphs and focus on relations between triples defining confounders, colliders and mediators. We then describe how we can retrieve causal effects (in an abstract setting). Finally, we present the linear mediation model popularized by <span class="citation">Baron and Kenny (<a href="references.html#ref-Baron.Kenny:1986" role="doc-biblioref">1986</a>)</span>. We focus on the hidden assumptions that can undermine causal claims of mediation.</p>
<div id="basics-of-causal-inference" class="section level2" number="11.1">
<h2>
<span class="header-section-number">11.1</span> Basics of causal inference<a class="anchor" aria-label="anchor" href="#basics-of-causal-inference"><i class="fas fa-link"></i></a>
</h2>
<p>In an experiment, we can manipulate assignment to treatment <span class="math inline">\(a\)</span> and randomize units to each value of the treatment to avoid undue effects from other variables. The potential outcomes applies in between-subject design because experimental units are assigned to a single treatment, whereas in within-subject designs a single ordering is presented. If we denote the outcome by <span class="math inline">\(Y\)</span>, then we are effectively comparing <span class="math inline">\((Y \mid X)\)</span> for different values of the action set <span class="math inline">\(X\)</span> (for example, <span class="math inline">\(X\)</span> could be an experimental factor. We talk about causation when for treatment (<span class="math inline">\(X=j\)</span>) and control (<span class="math inline">\(X=0\)</span>), the distributions of <span class="math inline">\((Y \mid X=j)\)</span> differs from that of <span class="math inline">\((Y \mid X=0)\)</span>. The fundamental problem of causal inference is that, while we would like to study the impact of every action on our response, we can only observe the outcome for treatment <span class="math inline">\(j\)</span>, written <span class="math inline">\((Y_i \mid X=j)\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;In a within-subject design, the analog is that a single ordering can be presented.&lt;/p&gt;"><sup>48</sup></a></p>
<p>Rather than look at the individual treatment effect, we must focus on the population effects. The most common measure of causation is the <strong>average treatment effect</strong>, which is the difference between the population averages of treatment group <span class="math inline">\(j\)</span> and the control group,
<span class="math display">\[\begin{align*}
\textsf{ATE}_j = \mathsf{E}(Y \mid X=j) - \mathsf{E}(Y \mid X=0)
\end{align*}\]</span>
In experimental designs, we can target the average treatment effect if our subjects comply with their treatment assignment and if we randomize the effect and use a random sample which is representative of the population.</p>
<p>In many fields, the unconditional effect is not interesting enough to warrant publication free of other explanatory variables. It may be that the effect of the treatment is not the same for everyone: for example, a study on gender discrimination may reveal different perceptions depending on gender, in which case the average treatment effect might not be a sensible measure and we could look at conditional effects. We may also be interested in seeing how different mechanisms and pathways are impacted by treatment and how this affects the response. <span class="citation">VanderWeele (<a href="references.html#ref-Vanderweele:2015" role="doc-biblioref">2015</a>)</span> provides an excellent non-technical overview of mediation and interaction.</p>
<!--
TODO: write about conditional average treatment effect (CATE) and local average treatment effect. Discuss noncompliance and potential selection effects (selection on colliders)
-->
<p>Causal inference requires a logical conceptual model of the interrelation between the variables. We will look at directed acyclic graphs to explain concepts of confounding, collision and mediation and how they can influence our conclusions.</p>
<p>To illustrate the relationship between variables, we use diagrams consisting of directed acyclic graph (DAG). A DAG is a graph with no cycle: each node represents a variable of interest and these are linked with directed edges indicating the nature of the relation (if <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, then <span class="math inline">\(X \to Y\)</span>). Directed acyclic graphs are used to represent the data generating process that causes interdependencies, while abstracting from the statistical description of the model. This depiction of the conceptual model helps to formalize and identify the assumptions of the model. To identify a causal effect of a variable <span class="math inline">\(X\)</span> on some response <span class="math inline">\(Y\)</span>, we need to isolate the effect from that of other potential causes. Figure <a href="causal-inference.html#fig:fig-daggity">11.1</a> shows an example of DAG in a real study; the latter is a simplification or abstraction of a world view, but is already rather complicated.</p>
<!--https://bookdown.org/mike/data_analysis/causal-inference.html-->
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-daggity"></span>
<img src="figures/dagitty-model.png" alt="Directed acyclic graph of @McQuire:2020 reproduction by [Andrew Heiss](https://www.andrewheiss.com/), licensed under [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/)." width="60%"><p class="caption">
Figure 11.1: Directed acyclic graph of <span class="citation">McQuire et al. (<a href="references.html#ref-McQuire:2020" role="doc-biblioref">2020</a>)</span> reproduction by <a href="https://www.andrewheiss.com/">Andrew Heiss</a>, licensed under <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
</p>
</div>
<p>At a theoretical level, the DAG will help identify which paths and relations to control through conditioning arguments to strip the relation to that of interest. Judea Pearl <span class="citation">(e.g., <a href="references.html#ref-Pearl:2016" role="doc-biblioref">Pearl, Glymour, and Jewell 2016</a>)</span> identifies three potential relations between triples of (sets of) variables:</p>
<ul>
<li>chains (<span class="math inline">\(X \to Z\to Y\)</span>),</li>
<li>forks (<span class="math inline">\(Z \leftarrow X \rightarrow Y\)</span>) and</li>
<li>reverse forks (<span class="math inline">\(Z \rightarrow X \leftarrow Y\)</span>).</li>
</ul>
<p>These are represented in Figure <a href="causal-inference.html#fig:fig-causalrelations">11.2</a>. In the graph, <span class="math inline">\(X\)</span> represents an explanatory variable, typically the experimental factor, <span class="math inline">\(Y\)</span> is the response and <span class="math inline">\(Z\)</span> is another variable whose role depends on the logical flow between variables (collider, confounder or mediator).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-causalrelations"></span>
<img src="figures/causal_dag_aheiss.jpg" alt="Type of causal relations by Andrew Heiss, licensed under [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/)." width="100%"><p class="caption">
Figure 11.2: Type of causal relations by Andrew Heiss, licensed under <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
</p>
</div>
<p>In an experimental design, confounding effects from the experimental treatment <span class="math inline">\(X\)</span> to the response <span class="math inline">\(Y\)</span> are controlled by randomization or sample selection: all incoming arrows inside <span class="math inline">\(X\)</span> from other variables are removed. If we include additional variables in the model which happen to be colliders, then we won’t recover the causal effect of interest. Addition of mediators will let us filter the effect due to <span class="math inline">\(Z\)</span> from the direct effect of <span class="math inline">\(X\)</span>.</p>
<p>It is <em>essential</em> to determine via logic or otherwise (experiments can help!) the direction of the relationship, lest we run into trouble. Many statistical models commonly used, including regression models, cannot provide an answer to a problem that is philosophical or conceptual in nature. Indeed, correlation is symmetric and insufficient to infer the direction of the arrows in the directed acyclic graph.</p>
<p>The conclusions we will draw from statistical models depend on the nature of the relation. For example, in an observational setting, we could eliminate the effect of a confounding variable by controlling in a regression model or by stratifying for different values of the confounders in order to extract the causal estimate of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. However, the same strategy with a collider would backfire and we would get erroneous conclusions: <span class="citation">Kowal (<a href="references.html#ref-Kowal:2021" role="doc-biblioref">2021</a>)</span> reportedly found out married couples with more children were less happy. As Richard McElreath hinted, controlling for marriage (through sample selection) is incorrect since unhappy couples tend to divorce, but families with many children are less likely to divorce!</p>
<p>In a randomized experiment, we can check the average outcome of a manipulation by comparing groups: assuming random sampling, these conclusions can be broadly generalized to the population of interest from which the sample is drawn. However, it may be that the effect of the treatment depends on other variables: cultural differences, gender or education may change. In the statistical model, inclusion of interaction terms (typically product of the moderator variable with the factor encoding the experimental sub-condition) will allow us to estimate those differences.</p>
</div>
<div id="mediation" class="section level2" number="11.2">
<h2>
<span class="header-section-number">11.2</span> Mediation<a class="anchor" aria-label="anchor" href="#mediation"><i class="fas fa-link"></i></a>
</h2>
<p>In order to do inference and tests relations, we need to add to our logical causal model represented by a directed acyclic graph a data generating mechanisms that prescribes how variables how interrelated. Our ability to establish mediation will depend on the model and a set of assumptions, some of which won’t be verifiable.</p>
<p>To define in full generality the treatment and mediation effect, we need to consider the potential outcome framework. Following <span class="citation">Pearl (<a href="references.html#ref-Pearl:2014" role="doc-biblioref">2014</a>)</span>, we use <span class="math inline">\(Y_i(x, m)\)</span> to denote the potential outcome for individual <span class="math inline">\(i\)</span> with explanatory or experimental covariate/factor <span class="math inline">\(x\)</span> and mediator <span class="math inline">\(m\)</span>. Likewise, <span class="math inline">\(M_i(x)\)</span> is the potential mediator when applying treatment level <span class="math inline">\(x\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The notation is important to distinguish between association &lt;span class="math inline"&gt;\(Y \mid X\)&lt;/span&gt; when observing &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; from manipulations or interventions, &lt;span class="math inline"&gt;\(Y \mid \mathsf{do}(X)\)&lt;/span&gt; and counterfactuals &lt;span class="math inline"&gt;\(Y(X)\)&lt;/span&gt;.&lt;/p&gt;'><sup>49</sup></a></p>
<p>The <strong>total effect</strong> measures the overall impact of changes in outcome <span class="math inline">\(Y\)</span> (both through <span class="math inline">\(M\)</span> and directly) when experimentally manipulating <span class="math inline">\(X\)</span>,
<span class="math display">\[\begin{align*}\mathsf{TE}(x, x^*) = \mathsf{E}[ Y \mid \text{do}(X=x)] - \mathsf{E}[ Y \mid \text{do}(X=x^*)],
\end{align*}\]</span>
where <span class="math inline">\(x^*\)</span> is the factor level of the reference or control and <span class="math inline">\(x\)</span> is another treatment value. This definition generalizes when <span class="math inline">\(X\)</span> is a continuous variable.</p>
<p>The <strong>average controlled directed effect</strong> measures the flow along <span class="math inline">\(X \rightarrow Y\)</span>, disabling the pathway <span class="math inline">\(X \to M \to Y\)</span> by fixing the mediatior: it is
<span class="math display">\[\begin{align*}
\textsf{CDE}(m, x, x^*) &amp;=
\mathsf{E}[Y \mid \text{do}(X=x, m=m)] - \mathsf{E}[Y \mid \text{do}(X=x^*, m=m)] \\&amp;= \mathsf{E}\{Y(x,m) -Y(x^*, m)\}
\end{align*}\]</span>
This measures the expected change in response when the experimental factor changes from <span class="math inline">\(x\)</span> to <span class="math inline">\(x^*\)</span> and the mediator is set to a fixed value <span class="math inline">\(m\)</span> uniformly over the population.</p>
<p>The <strong>natural direct effect</strong>,
<span class="math display">\[\begin{align*}
\textsf{NDE}(x, x^*) = \mathsf{E}[Y\{x, M(x^*)\} - Y\{x^*,  M(x^*)\}],
\end{align*}\]</span>
is the expected change in <span class="math inline">\(Y\)</span> under treatment <span class="math inline">\(x\)</span> if <span class="math inline">\(M\)</span> is set to whatever value it would take under control <span class="math inline">\(x^*\)</span>.</p>
<p>The <strong>natural indirect effect</strong> (<span class="math inline">\(\mathsf{NIE}\)</span>) is the expected change in the response <span class="math inline">\(Y\)</span> if we set our experimental value <span class="math inline">\(X\)</span> to its control value <span class="math inline">\(x^*\)</span> and change the mediator value which it would attain under <span class="math inline">\(x\)</span>,
<span class="math display">\[\begin{align*}
\textsf{NIE}(x, x^*) = \mathsf{E}[Y\{x^*, M(x)\} - Y\{x^*,  M(x^*)\}]
\end{align*}\]</span></p>
<p>Armed with these definitions, we can consider the <strong>sequential ignorability assumption</strong>, which is decomposed into two components.</p>
<p>The first component is: given pre-treatment covariates <span class="math inline">\(W\)</span>, treatment assignment is independent of potential outcomes for mediation and outcome,
<span class="math display">\[\begin{align*}
Y_i(x', m), M_i(x) \perp\mkern-10mu\perp X_i \mid W_i = w.
\end{align*}\]</span>
In order words, the values taken by the mediator and by the response exist independently of the treatment assignment and don’t change.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The dependence on &lt;span class="math inline"&gt;\(W\)&lt;/span&gt; is used for situations where we can perform randomization based on pre-treatment assignment (i.e., we specify a mechanisms that is not equal based, but the probability of assignment is known from each individual).&lt;/p&gt;'><sup>50</sup></a></p>
<p>The second component of the sequential ignorability assumption is as follows: given pre-treatment covariates and observed treatment, mediation is independent of potential outcomes,
<span class="math display">\[\begin{align*}
Y_i(x', m) \perp\mkern-10mu\perp  M_i(x) \mid X_i =x, W_i = w
\end{align*}\]</span>
The set of assumptions from <span class="citation">Imai, Keele, and Tingley (<a href="references.html#ref-Imai:2010" role="doc-biblioref">2010</a>)</span> and <span class="citation">Pearl (<a href="references.html#ref-Pearl:2014" role="doc-biblioref">2014</a>)</span> are equivalent under randomization of treatment assignment, as we consider thereafter.</p>
<p>The total effect can be written
<span class="math display">\[\mathsf{TE}(x, x^*) = \mathsf{NDE}(x, x^*) - \mathsf{NIE}(x^*, x).\]</span>
In the linear mediation model, the reversal of argument amounts to changing the sign of the coefficient, giving an additive decomposition of the total effect as <span class="math inline">\(\mathsf{TE} = \mathsf{NDE} + \mathsf{NIE}\)</span> <span class="citation">(<a href="references.html#ref-Pearl:2014" role="doc-biblioref">Pearl 2014</a>)</span>.</p>
<p>When measuring effects in psychology and marketing, it will often be the case that the conceptual causal model includes variables that cannot be directly measured. The proxy, as in Figure <a href="causal-inference.html#fig:xkcd2652">11.3</a> add an additional layer of complexity and potential sources of confounding.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:xkcd2652"></span>
<img src="figures/xkcd2652_proxy_variable.png" alt="xkcd comic [2652 (Proxy Variable) by Randall Munroe](https://xkcd.com/2652/). Alt text: Our work has produced great answers. Now someone just needs to figure out which questions they go with. Cartoon reprinted under the [CC BY-NC 2.5 license](https://creativecommons.org/licenses/by-nc/2.5/)." width="60%"><p class="caption">
Figure 11.3: xkcd comic <a href="https://xkcd.com/2652/">2652 (Proxy Variable) by Randall Munroe</a>. Alt text: Our work has produced great answers. Now someone just needs to figure out which questions they go with. Cartoon reprinted under the <a href="https://creativecommons.org/licenses/by-nc/2.5/">CC BY-NC 2.5 license</a>.
</p>
</div>
</div>
<div id="linear-mediation-model" class="section level2" number="11.3">
<h2>
<span class="header-section-number">11.3</span> Linear mediation model<a class="anchor" aria-label="anchor" href="#linear-mediation-model"><i class="fas fa-link"></i></a>
</h2>
<p>One of the most popular model in social sciences is the linear mediation model, popularized by <span class="citation">Baron and Kenny (<a href="references.html#ref-Baron.Kenny:1986" role="doc-biblioref">1986</a>)</span> although the method predates this publication. Another inferential approach, suggested by <span class="citation">Preacher and Hayes (<a href="references.html#ref-Preacher.Hayes:2004" role="doc-biblioref">2004</a>)</span>, uses the same model with different test statistics and is extremely popular because it comes with software; Hayes’ <a href="https://www.processmacro.org/index.html">PROCESS macros for SAS, SPSS and <strong>R</strong></a> have lead to the widespread adoption by researchers. <span class="citation">Bullock, Green, and Ha (<a href="references.html#ref-Bullock.Green.Ha:2010" role="doc-biblioref">2010</a>)</span> list limitations of the approach and provide examples of instances in which the model does not have a meaningful causal interpretation.</p>
<p>The linear mediation model assumes that the effect of mediation and treatment is additive and that the response measurement is continuous. Consider covariates <span class="math inline">\(\mathbf{Z}\)</span>, experimental factor <span class="math inline">\(\mathbf{X}\)</span> corresponding to treatment and postulated mediator variable <span class="math inline">\(M\)</span>, assumed continuous. Given <strong>uncorrelated</strong> unobserved noise variables <span class="math inline">\(\varepsilon_M\)</span> and <span class="math inline">\(\varepsilon_Y\)</span>, we specify linear regression models,
<span class="math display">\[\begin{align*}
M \mid X=x &amp;= c_M + \alpha x + \varepsilon_M,\\
Y \mid X=x, M=m &amp;=  c_Y + \beta x + \gamma m + \mathbf{z}^\top\boldsymbol{\omega} + \varepsilon_Y
\end{align*}\]</span>
where we use the contrast-to-reference parametrization so that the reference category for the intercept corresponds to control (group <span class="math inline">\(x^*\)</span>) and <span class="math inline">\(x\)</span> the other category of interest, with <span class="math inline">\(\alpha\)</span> capturing the difference between <span class="math inline">\(x\)</span> and <span class="math inline">\(x^*\)</span>. The model for <span class="math inline">\(Y \mid X, M\)</span> should include additional covariates <span class="math inline">\(\mathbf{z}\)</span> to control for confounding between <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span> if the latter is suspected.</p>
<p>The parameters can be interpreted as the direct (<span class="math inline">\(\beta\)</span>), indirect (<span class="math inline">\(\alpha \gamma\)</span>) and total (<span class="math inline">\(\beta + \alpha \gamma\)</span>) effects. To see this, we plug the first equation in the second and obtain the marginal model for <span class="math inline">\(Y\)</span> given treatment <span class="math inline">\(X\)</span>,
<span class="math display">\[\begin{align}
Y \mid X=x &amp;= \underset{\text{intercept}}{(c_Y + \gamma c_M)} + \underset{\text{total effect}}{(\beta + \alpha\gamma)}\cdot x + \underset{\text{error}}{(\gamma \varepsilon_M + \varepsilon_Y)}\\
&amp;= c_Y' + \tau X + \varepsilon_Y'
\end{align}\]</span>
These parameters can be estimated using structural equation models (SEM), or more typically by running a series of linear regression (ordinary least squares).</p>
<p>The sequential ignorability in the linear mediation models boils down to “no unmeasured confounders” in the relations <span class="math inline">\(X \to Y\)</span>, <span class="math inline">\(X \to M\)</span> and <span class="math inline">\(M \to Y\)</span>: the first two are satisfied in experimental studies due to randomization, as shown in <a href="causal-inference.html#fig:fig-dag1">11.6</a>. This means <span class="math inline">\(\varepsilon_M {\perp\mkern-10mu\perp} \varepsilon_Y\)</span> must be independent and, as a result, error terms should also be uncorrelated.</p>
<p>In the linear mediation model, we can estimate the conditional direct effect corresponding to the product of coefficients <span class="math inline">\(\alpha\gamma\)</span>. Absence of mediation implies the product is zero. <span class="citation">Baron and Kenny (<a href="references.html#ref-Baron.Kenny:1986" role="doc-biblioref">1986</a>)</span> recommended using Sobel’s test statistic, a Wald-test of the form
<span class="math display">\[\begin{align*}
S  = \frac{\widehat{\alpha}\widehat{\gamma} - 0}{\mathsf{se}(\widehat{\alpha}\widehat{\gamma})} =  \frac{\widehat{\alpha}\widehat{\gamma}}{\sqrt{\widehat{\gamma}^2\mathsf{Va}(\widehat{\alpha}) + \widehat{\alpha}^2\mathsf{Va}(\widehat{\gamma}) + \mathsf{Va}(\widehat{\gamma})\mathsf{Va}(\widehat{\alpha})}} \stackrel{\cdot}{\sim}\mathsf{No}(0,1)
\end{align*}\]</span>
where <span class="math inline">\(\widehat{\alpha}\)</span>, <span class="math inline">\(\widehat{\gamma}\)</span> and their variance <span class="math inline">\(\mathsf{Va}(\widehat{\alpha})\)</span> and <span class="math inline">\(\mathsf{Va}(\widehat{\gamma})\)</span> can be obtained from the estimated coefficients and standard errors.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Sobel derived the asymptotic variance using a first-order Taylor series expansion assuming both &lt;span class="math inline"&gt;\(\alpha\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\gamma\)&lt;/span&gt; are non-zero (hence the tests!)&lt;/p&gt;'><sup>51</sup></a> The Sobel’s statistic <span class="math inline">\(S\)</span> is approximately standard normal in large samples, but the approximation is sometimes crude.</p>
<p>In the linear mediation causal model, we can estimate the total causal effect of <span class="math inline">\(X\)</span>, labelled <span class="math inline">\(\tau\)</span>, by running the linear regression of <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> as there is no confounding affecting treatment <span class="math inline">\(X\)</span> in a completely randomized experimental design. This strategy isn’t valid with observational data unless we adjust for confounders. Under no unmeasured confounders and linearity, the product <span class="math inline">\(\alpha\gamma\)</span> is also equal to the difference between the total effect and the <strong>natural direct effect</strong>, <span class="math inline">\(\tau - \beta\)</span>.</p>
<p><span class="citation">Baron and Kenny (<a href="references.html#ref-Baron.Kenny:1986" role="doc-biblioref">1986</a>)</span> suggested for <span class="math inline">\(X\)</span> and <span class="math inline">\(M\)</span> continuous breaking down the task in three separate steps:</p>
<ol style="list-style-type: decimal">
<li>fit a linear regression of <span class="math inline">\(M\)</span> on <span class="math inline">\(X\)</span> to estimate <span class="math inline">\(\alpha\)</span>
</li>
<li>fit a linear regression of <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> to estimate <span class="math inline">\(\tau\)</span>
</li>
<li>fit a linear regression of <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> and <span class="math inline">\(M\)</span> to estimate <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\gamma\)</span>.</li>
</ol>
<p>In the “<span class="citation">Baron and Kenny (<a href="references.html#ref-Baron.Kenny:1986" role="doc-biblioref">1986</a>)</span> approach”, we test <span class="math inline">\(\mathscr{H}_0: \alpha=0\)</span>, <span class="math inline">\(\mathscr{H}_0: \tau=0\)</span> and <span class="math inline">\(\mathscr{H}_0: \gamma=0\)</span> against the two-sided alternative. This approach has caveats since mediation refers to the relation <span class="math inline">\(X \to M \to Y\)</span>, so we only need to consider (joint tests of) <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\gamma\)</span> (the total effect could be zero because <span class="math inline">\(\beta = -\alpha\gamma\)</span> even if there is mediation). <span class="citation">Zhao, Lynch, and Chen (<a href="references.html#ref-Zhao.Lynch.Chen:2010" role="doc-biblioref">2010</a>)</span> review the typology of mediation.</p>
<ol style="list-style-type: decimal">
<li>complementary mediation when both direct and indirect effects are of the same sign and non-zero.</li>
<li>competitive mediation when direct and indirect effects are of opposite signs.</li>
<li>indirect-only mediation when the direct effect of <span class="math inline">\(X \to Y\)</span> is null, but the effect <span class="math inline">\(X \to M \to Y\)</span> isn’t.</li>
</ol>
<p>Previous definitions popularized by <span class="citation">Baron and Kenny (<a href="references.html#ref-Baron.Kenny:1986" role="doc-biblioref">1986</a>)</span> still found in old papers include “full mediation” for instances where <span class="math inline">\(\beta=0\)</span> and partial mediation if the direct effect is less than the total effect, meaning <span class="math inline">\(\beta &lt; \tau\)</span>.</p>
<p>To see this, let’s generate data with a binary treatment and normally distributed mediators and response with no confounding (so the data generating process matches exactly the formulation fo Baron–Kenny. We set <span class="math inline">\(\alpha=2\)</span>, <span class="math inline">\(\beta = 1/2\)</span> and <span class="math inline">\(\gamma=0\)</span>. This is an instance where the null is true (<span class="math inline">\(X\)</span> affects both <span class="math inline">\(M\)</span> and <span class="math inline">\(Y\)</span>).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-sobelsimu"></span>
<img src="11-causal-inference_files/figure-html/fig-sobelsimu-1.png" alt="Null distribution of Sobel's statistic against approximate asymptotic normal distribution with 20 observations $\alpha=0$, $\gamma=0.1$ and normal random errors." width="85%"><p class="caption">
Figure 11.4: Null distribution of Sobel’s statistic against approximate asymptotic normal distribution with 20 observations <span class="math inline">\(\alpha=0\)</span>, <span class="math inline">\(\gamma=0.1\)</span> and normal random errors.
</p>
</div>
<p>If we knew exactly the model that generated <span class="math inline">\(X\)</span>, <span class="math inline">\(M\)</span>, <span class="math inline">\(Y\)</span> and the relations between them, we could simulate multiple datasets like in Figure <a href="causal-inference.html#fig:fig-sobelsimu">11.4</a> with <span class="math inline">\(n=20\)</span> observations and compare the test statistic we obtained with the simulation-based null distribution with <span class="math inline">\(\alpha\gamma=0\)</span>. In practice we do not know the model that generated the data and furthermore we have a single dataset at hand. An alternative is the bootstrap, a form of simulation-based inference. The latter is conceptually easy to understand: we generate new datasets by resampling from the ones observed (as if it was the population). Since we want the sample size to be identical and our objective is to get heterogeneity, we sample with replacement: from one bootstrap dataset to the next, we will have multiple copies, or none, of each observation. See <span class="citation">Efron and Tibshirani (<a href="references.html#ref-Efron.Tibshirani:1993" role="doc-biblioref">1993</a>)</span> and <span class="citation">Davison and Hinkley (<a href="references.html#ref-Davison.Hinkley:1997" role="doc-biblioref">1997</a>)</span> for a more thorough treatment of the bootstrap and alternative sampling schemes for regression models. The nonparametric bootstrap procedure advocated by <span class="citation">Preacher and Hayes (<a href="references.html#ref-Preacher.Hayes:2004" role="doc-biblioref">2004</a>)</span> consists in repeating the following <span class="math inline">\(B\)</span> times:</p>
<ol style="list-style-type: decimal">
<li>sample <span class="math inline">\(n\)</span> observations <strong>with replacement</strong>, i.e., a tuple (<span class="math inline">\(X_i, M_i, Y_i)\)</span>, from the original data .</li>
<li>compute the natural indirect effect <span class="math inline">\(\widehat{\alpha}\cdot\widehat{\gamma}\)</span> on each simulated sample</li>
</ol>
<p>For a two-sided test at level <span class="math inline">\(\alpha\)</span>, compute the <span class="math inline">\(\alpha/2\)</span> and <span class="math inline">\(1-\alpha/2\)</span> quantiles of the bootstrap statistics <span class="math inline">\(\{\widehat{\alpha}_b\widehat{\gamma}_b\}_{b=1}^B\)</span>. For example, if the level is <span class="math inline">\(\alpha=5\)</span>% and we generate <span class="math inline">\(B=1000\)</span> bootstrap samples, the percentile confidence intervals bounds are the 25th and 975th ordered observations.</p>
<p>Nowadays, the asymptotic approximation (sometimes misnamed delta method<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;The latter is the name of the method used to derive the denominator of Sobel’s statistic.&lt;/p&gt;"><sup>52</sup></a>) has fallen out of fashion among practitioners, who prefer the nonparametric bootstrap coupled with the percentile method.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:bootstrap"></span>
<img src="11-causal-inference_files/figure-html/bootstrap-1.png" alt="Bootstrap distribution of indirect effect with estimate and percentile 95% confidence intervals (vertical red lines)." width="85%"><p class="caption">
Figure 11.5: Bootstrap distribution of indirect effect with estimate and percentile 95% confidence intervals (vertical red lines).
</p>
</div>
<p>The nonparametric percentile bootstrap confidence interval for <span class="math inline">\(\alpha\gamma\)</span> is [-0.08, 1.71] and thus we fail to reject the null hypothesis <span class="math inline">\(\mathscr{H}_0: \alpha \gamma=0\)</span>.</p>
<p>The inference scheme is popular, but we could also rely on different models and use the definitions of the causal effects to perform simulation-based inference; see Appendix D of <span class="citation">Imai, Keele, and Tingley (<a href="references.html#ref-Imai:2010" role="doc-biblioref">2010</a>)</span>. The latter fit two models for the mediator and the outcome, then estimate parameters. In large samples, the parameter estimators are approximately multivariate Gaussian and we can simulate parameters, use the parametric model to generate new data and potential outcomes. The average causal mediation effect can be estimated empirically based on the simulated potential outcomes.</p>
<div id="model-assumptions-2" class="section level3" number="11.3.1">
<h3>
<span class="header-section-number">11.3.1</span> Model assumptions<a class="anchor" aria-label="anchor" href="#model-assumptions-2"><i class="fas fa-link"></i></a>
</h3>
<p>We can unpack the model assumptions for the linear mediation model.</p>
<ol style="list-style-type: decimal">
<li>The <em>no unmeasured confounders</em> assumption. Plainly stated, there are no unobserved confounders and thus the error terms <span class="math inline">\(\varepsilon_M\)</span> and <span class="math inline">\(\varepsilon_Y\)</span> are independent. Additionally, when we consider observational data, we must make sure there is hidden confounders affecting either the <span class="math inline">\(M \to X\)</span> and the <span class="math inline">\(X \to Y\)</span> relation, as shown in <a href="causal-inference.html#fig:fig-dag1">11.6</a>. We can include covariates in the regression models to palliate to this, but we must only include the minimal set of confounders (and no additional mediator or collider chain).</li>
</ol>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-dag1"></span>
<img src="figures/dag1.png" alt="Directed acyclic graph representing observational settings (left) and experimental settings in which assignment is random given covariates measured pre-treatments (right). The 'no unmeasured confounder' assumption postulates such confounders are included (with the correct parametric form) in the regression models." width="85%"><p class="caption">
Figure 11.6: Directed acyclic graph representing observational settings (left) and experimental settings in which assignment is random given covariates measured pre-treatments (right). The ‘no unmeasured confounder’ assumption postulates such confounders are included (with the correct parametric form) in the regression models.
</p>
</div>
<p>Another problem would be to claim that variable <span class="math inline">\(M\)</span> is a mediator when in truth part of the effect on the outcome is due to change in another mediator. Figure <a href="causal-inference.html#fig:fig-dag2">11.7</a> shows an instance with no confounding, but multiple mediators, say <span class="math inline">\(M_1\)</span> and <span class="math inline">\(M_2\)</span>: the latter mediates the relation <span class="math inline">\(M_1 \to Y\)</span>. The linear mediation model would capture the total effect of <span class="math inline">\(M_1\)</span>, but it would be incorrect to claim that the mediation effect on <span class="math inline">\(X\)</span> is due to <span class="math inline">\(M_1\)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-dag2"></span>
<img src="figures/dag2.png" alt="Directed acyclic graph showing multiple mediators." width="45%"><p class="caption">
Figure 11.7: Directed acyclic graph showing multiple mediators.
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>The <strong>linearity assumption</strong> implies that the linear models are correctly specified and that the effect of the covariates are linear. This means that, <em>ceteris paribus</em>, the effect of an increase of one unit of <span class="math inline">\(M\)</span> on <span class="math inline">\(Y\)</span> is the same regardless of the value of <span class="math inline">\(M\)</span>. It also doesn’t depend on the level of other variables (no interaction). If the model isn’t properly specified, the linear model coefficients will capture the best linear predictor given the design and the coefficients may not be meaningful.</li>
</ol>
<p>The linearity assumption also implies that the effect is the same for every individual, so there is no treatment heterogeneity or measurement error which could lead to attenuation bias.</p>
<p>Following <span class="citation">Bullock, Green, and Ha (<a href="references.html#ref-Bullock.Green.Ha:2010" role="doc-biblioref">2010</a>)</span>, we index the regression equations by individual <span class="math inline">\(i\)</span>
<span class="math display">\[\begin{align*}
M_i\mid X_i=x &amp;= c_M + \alpha_i x + \varepsilon_{Mi},\\
Y_i \mid X_i=x, M_i=m &amp;=  c_Y + \beta_i x + \gamma_i m + \mathbf{z}_i^\top\boldsymbol{\omega} + \varepsilon_{Yi}
\end{align*}\]</span>
If <span class="math inline">\(\alpha_i\)</span> differ from one observation to the next, the average estimated by the regression could be positive, negative or null. Even in the latter case, we could have <span class="math inline">\(\gamma_i\)</span> and <span class="math inline">\(\alpha_i\)</span> positive for some observation, or both negatives so that they cancel out even if there is complementary mediation.</p>
<p>We could easily expand the model to include nonlinear effects (not for the treatment or mediator) and potential interactions, but the linear model approach will be limited. <span class="citation">Imai, Keele, and Tingley (<a href="references.html#ref-Imai:2010" role="doc-biblioref">2010</a>)</span> details a more general approach for parametric models based on simulations, as well as a nonparametric approach. Both are less restrictive than the <span class="citation">Baron and Kenny (<a href="references.html#ref-Baron.Kenny:1986" role="doc-biblioref">1986</a>)</span> model.</p>
<p>The main benefit of experimental designs is that it deconfounds the relation between treatment and other variables, but adding spurious variables could create feedback and lead to inconsistent conclusions. It’s not clear that the mediator can be manipulated experimentally, and even if it could be to estimate the <span class="math inline">\(\gamma\)</span>, one must make sure the relation is the same absent of <span class="math inline">\(X\)</span>. For example, we could estimate the indirect effect term by manipulating jointly (if possible) (<span class="math inline">\(X, M\)</span>) but even then the linearity assumption must hold for the estimates to correspond to our linear causal mediation model.</p>
</div>
<div id="example" class="section level3" number="11.3.2">
<h3>
<span class="header-section-number">11.3.2</span> Example<a class="anchor" aria-label="anchor" href="#example"><i class="fas fa-link"></i></a>
</h3>
<p>Study 2 of <span class="citation">Lee and Choi (<a href="references.html#ref-Lee.Choi:2019" role="doc-biblioref">2019</a>)</span> focus on inconsistency of photos and text descriptions for online descriptions and how this impact the product evaluation.</p>
<p>The experimental variable is the consistency of the product description and depiction, with <code>fluency</code> leading to “processing disfluency” that is expected to impact negatively judgment ratings.
Familiarity with the product brand and product is included as covariate in both mediator and outcome model (see Table 1 of <span class="citation">Lee and Choi (<a href="references.html#ref-Lee.Choi:2019" role="doc-biblioref">2019</a>)</span>).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Incidentally, reporting the coefficients allows in a Table allows one to retro-engineer the model and ensure reproducibility.&lt;/p&gt;"><sup>53</sup></a></p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">LC19_S2</span>, package <span class="op">=</span> <span class="st">"hecedsm"</span><span class="op">)</span></span>
<span><span class="va">YsMX</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">prodeval</span> <span class="op">~</span> <span class="va">fluency</span> <span class="op">+</span> <span class="va">consistency</span> <span class="op">+</span> <span class="va">familiarity</span>,</span>
<span>           data <span class="op">=</span> <span class="va">LC19_S2</span><span class="op">)</span></span>
<span><span class="va">MsX</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">fluency</span> <span class="op">~</span> <span class="va">consistency</span> <span class="op">+</span> <span class="va">familiarity</span>,</span>
<span>           data <span class="op">=</span> <span class="va">LC19_S2</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="kable_wrapper table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-8">Table 11.1: </span>Coefficients of the mediation (left) and outcome (right) models.
</caption>
<tbody><tr>
<td>
<table class="table table-sm">
<thead><tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
5.23
</td>
<td style="text-align:right;">
0.27
</td>
</tr>
<tr>
<td style="text-align:left;">
consistency
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
0.24
</td>
</tr>
<tr>
<td style="text-align:left;">
familiarity
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
0.06
</td>
</tr>
</tbody>
</table>
</td>
<td>
<table class="table table-sm">
<thead><tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
3.04
</td>
<td style="text-align:right;">
0.53
</td>
</tr>
<tr>
<td style="text-align:left;">
fluency
</td>
<td style="text-align:right;">
0.60
</td>
<td style="text-align:right;">
0.09
</td>
</tr>
<tr>
<td style="text-align:left;">
consistency
</td>
<td style="text-align:right;">
0.29
</td>
<td style="text-align:right;">
0.22
</td>
</tr>
<tr>
<td style="text-align:left;">
familiarity
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
0.05
</td>
</tr>
</tbody>
</table>
</td>
</tr></tbody>
</table></div>
<p>We can extract the effects directly from the outcome: the natural indirect effect estimate is <span class="math inline">\(\widehat{\alpha}\widehat{\gamma} = 0.48 \times 0.60\)</span> and the direct effect is <span class="math inline">\(\widehat{\beta} = 0.29\)</span>.</p>
<p>To get confidence intervals, we can use the <code>mediate</code> package <span class="citation">(<a href="references.html#ref-mediationR" role="doc-biblioref">Tingley et al. 2014</a>)</span>. The function requires the parametric model for the mediation and outcome, as well as a series of specification (the number of bootstrap samples, the type of confidence interval, the names of the levels for categorical treatment, etc.)</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">80667</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://imai.princeton.edu/projects/mechanisms.html">mediation</a></span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">linmed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mediation/man/mediate.html">mediate</a></span><span class="op">(</span></span>
<span>  model.m <span class="op">=</span> <span class="va">MsX</span>,</span>
<span>  model.y <span class="op">=</span> <span class="va">YsMX</span>,</span>
<span>  treat <span class="op">=</span> <span class="st">"consistency"</span>,</span>
<span>  mediator <span class="op">=</span> <span class="st">"fluency"</span>,</span>
<span>  sims <span class="op">=</span> <span class="fl">5000L</span>,</span>
<span>  boot <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  boot.ci.type <span class="op">=</span> <span class="st">"bca"</span>, <span class="co"># bias-corrected and accelerated (bca)</span></span>
<span>  control.value <span class="op">=</span> <span class="st">"inconsistent"</span>,</span>
<span>  treat.value <span class="op">=</span> <span class="st">"consistent"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:tbl-mediation">Table 11.2: </span>Linear causal mediation analysis: parameter estimates and nonparametric bootstrap confidence intervals and <span class="math inline">\(p\)</span>-values with the percentile method using <span class="math inline">\(B=5000\)</span> bootstrap samples.
</caption>
<thead><tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
95% CI Lower
</th>
<th style="text-align:right;">
95% CI Upper
</th>
<th style="text-align:right;">
p-value
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
ACME
</td>
<td style="text-align:right;">
0.286
</td>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
0.595
</td>
<td style="text-align:right;">
0.037
</td>
</tr>
<tr>
<td style="text-align:left;">
ADE
</td>
<td style="text-align:right;">
0.287
</td>
<td style="text-align:right;">
-0.165
</td>
<td style="text-align:right;">
0.737
</td>
<td style="text-align:right;">
0.218
</td>
</tr>
<tr>
<td style="text-align:left;">
Total Effect
</td>
<td style="text-align:right;">
0.573
</td>
<td style="text-align:right;">
0.047
</td>
<td style="text-align:right;">
1.091
</td>
<td style="text-align:right;">
0.030
</td>
</tr>
<tr>
<td style="text-align:left;">
Prop. Mediated
</td>
<td style="text-align:right;">
0.499
</td>
<td style="text-align:right;">
-0.051
</td>
<td style="text-align:right;">
1.938
</td>
<td style="text-align:right;">
0.057
</td>
</tr>
</tbody>
</table></div>
<p>Using the <code>summary</code> method, we can print the table of estimates and confidence intervals. We can see that the results are consistent with those reported in the article.</p>
</div>
</div>
<div id="moderation-and-interactions" class="section level2" number="11.4">
<h2>
<span class="header-section-number">11.4</span> Moderation and interactions<a class="anchor" aria-label="anchor" href="#moderation-and-interactions"><i class="fas fa-link"></i></a>
</h2>
<p>The causal effect <span class="math inline">\(Y \mid \mathsf{do}(X)\)</span> may be a misleading summary if another variable modifies the relation: for example, the perception of gender discrimination or racism may depend on the person background and experience and this may impact the effect of the manipulation. Such variables, say <span class="math inline">\(W\)</span>, thus have an interactive effect with the experimental factor <span class="math inline">\(X\)</span>, termed moderator in psychology.</p>
<p>In a blocking design, covariates are included that have an impact on the outcome to filter out variability, but with the assumption that they do not influence the effect of treatment. With moderators, we include the interaction.</p>
<p>If we have an experimental factor <span class="math inline">\(X\)</span> which is binary or categorical, the resulting model is a simple analysis of variance model and we can test the significance of the interaction term to assess the moderating effect of <span class="math inline">\(W\)</span>.</p>
<p>If <span class="math inline">\(W\)</span> is a mean-centered continuous variable and <span class="math inline">\(X\)</span> a categorical variable with <span class="math inline">\(k=1, \ldots, K\)</span> levels using the sum-to-zero parametrization, the linear model
<span class="math display">\[\mathsf{E}\{Y \mid \mathsf{do}(X) = k, W\} = \mu + \alpha_k + (\beta + \gamma_k)W + \varepsilon,\]</span>
includes different slopes for <span class="math inline">\(W\)</span> in each experimental group, as well as different intercepts (<span class="math inline">\(\mu + \alpha_k\)</span>) for group <span class="math inline">\(k\)</span>.</p>
<p>As an example, we consider <span class="citation">Garcia et al. (<a href="references.html#ref-Garcia:2010" role="doc-biblioref">2010</a>)</span>. These data are from a study on gender discrimination. Participants were put with a file where a women was turned down promotion in favour of male colleague despite her being clearly more experimented and qualified. The authors manipulated the decision of the participant to this decision, either choosing not to challenge the decision (no protest), a request to reconsider based on individual qualities of the applicants (individual) and a request to reconsider based on abilities of women (collective). All items were measured using scales constructed using items measured using Likert scales ranging from strongly disagree (1) to strongly agree (7).</p>
<p>The postulated mediator variable is <code>sexism</code>, the average of 6 Likert scales for the Modern Sexism Scale assessing pervasiveness of gender discrimination. We consider participants’ evaluation of the appropriateness of the response of the fictional character.</p>
<p>We fit the linear model with the interaction and display the observed slopes</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">GSBE10</span>, package <span class="op">=</span> <span class="st">"hecedsm"</span><span class="op">)</span></span>
<span><span class="va">lin_moder</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">respeval</span> <span class="op">~</span> <span class="va">protest</span><span class="op">*</span><span class="va">sexism</span>, </span>
<span>               data <span class="op">=</span> <span class="va">GSBE10</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lin_moder</span><span class="op">)</span> <span class="co"># coefficients</span></span>
<span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/Anova.html">Anova</a></span><span class="op">(</span><span class="va">lin_moder</span>, type <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="co"># tests</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:tbl-testsmoder">Table 11.3: </span>Analysis of variance table for the linear moderation model.
</caption>
<thead><tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
sumsq
</th>
<th style="text-align:right;">
df
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:left;">
p.value
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
protest
</td>
<td style="text-align:right;">
6.34
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2.45
</td>
<td style="text-align:left;">
.091
</td>
</tr>
<tr>
<td style="text-align:left;">
sexism
</td>
<td style="text-align:right;">
6.59
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5.09
</td>
<td style="text-align:left;">
.026
</td>
</tr>
<tr>
<td style="text-align:left;">
protest:sexism
</td>
<td style="text-align:right;">
12.49
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4.82
</td>
<td style="text-align:left;">
.010
</td>
</tr>
<tr>
<td style="text-align:left;">
Residuals
</td>
<td style="text-align:right;">
159.22
</td>
<td style="text-align:right;">
123
</td>
<td style="text-align:right;">
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table></div>
<div class="inline-figure"><img src="11-causal-inference_files/figure-html/unnamed-chunk-13-1.png" width="85%" style="display: block; margin: auto;"></div>
<p>Because of the interaction, comparing the levels of the experimental factor only makes sense if we fix the value of sexism (since the slopes are not parallel) and won’t necessarily be reliable outside of the range of observed values of sexism. We could look at quantiles and differences at the mean sexism,<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;This is the default with &lt;code&gt;emmeans&lt;/code&gt;&lt;/p&gt;"><sup>54</sup></a> or one standard deviation away.</p>
<p>We may be interested in the range of values of the predictor <span class="math inline">\(W\)</span> for which the difference between treatments is not statistically significant if we only have a binary treatment. The Johnson–Neyman method <span class="citation">(<a href="references.html#ref-Johnson.Neyman:1936" role="doc-biblioref">Johnson and Neyman 1936</a>)</span> considers this range, but this leads to multiple testing problems since we probe the model repeatedly. <span class="citation">Esarey and Sumner (<a href="references.html#ref-Esarey.Sumner:2018" role="doc-biblioref">2018</a>)</span> offer a method that provides control for the false discovery rate.</p>
<p>To illustrate the method, we dichotomize the manipulation pooling individual and collective protests, since these are the most similar.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://interactions.jacob-long.com">interactions</a></span><span class="op">)</span></span>
<span><span class="va">db</span> <span class="op">&lt;-</span> <span class="va">GSBE10</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    protest <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">protest</span> <span class="op">!=</span> <span class="st">"no protest"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">lin_moder2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">respeval</span> <span class="op">~</span> <span class="va">protest</span><span class="op">*</span><span class="va">sexism</span>, data <span class="op">=</span> <span class="va">db</span><span class="op">)</span></span>
<span><span class="va">jn</span> <span class="op">&lt;-</span> <span class="fu">johnson_neyman</span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">lin_moder2</span>, <span class="co"># linear model</span></span>
<span>  pred <span class="op">=</span> <span class="va">protest</span>, <span class="co"># binary experimental factor</span></span>
<span>  modx <span class="op">=</span> <span class="va">sexism</span>, <span class="co"># moderator</span></span>
<span>  control.fdr <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  mod.range <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">db</span><span class="op">$</span><span class="va">sexism</span><span class="op">)</span><span class="op">)</span> </span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig-jn"></span>
<img src="11-causal-inference_files/figure-html/fig-jn-1.png" alt="Johnson--Neyman plot for difference between protest and no protest as a function of sexism." width="85%"><p class="caption">
Figure 11.8: Johnson–Neyman plot for difference between protest and no protest as a function of sexism.
</p>
</div>
<p>The cutoff value is 4.20 with control for the false discovery rate and 4.15 without. The interval is not extended beyond the range of value for sexism, as these are not possible given the Likert scale (which starts at 1).</p>
<p>In this example, the moderator is not experimentally manipulated, but it could be. More complicated mediation model could include interactions between treatment effects or moderators and covariates, with external variables, leading to moderated mediation.</p>
<p>Interactions can be considered for pretty much any statistical model, but the usual assumptions need to hold for inference to be approximately valid.</p>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="introduction-to-mixed-models.html"><span class="header-section-number">10</span> Introduction to mixed models</a></div>
<div class="next"><a href="nonparametric-tests.html"><span class="header-section-number">12</span> Nonparametric tests</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#causal-inference"><span class="header-section-number">11</span> Causal inference</a></li>
<li><a class="nav-link" href="#basics-of-causal-inference"><span class="header-section-number">11.1</span> Basics of causal inference</a></li>
<li><a class="nav-link" href="#mediation"><span class="header-section-number">11.2</span> Mediation</a></li>
<li>
<a class="nav-link" href="#linear-mediation-model"><span class="header-section-number">11.3</span> Linear mediation model</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#model-assumptions-2"><span class="header-section-number">11.3.1</span> Model assumptions</a></li>
<li><a class="nav-link" href="#example"><span class="header-section-number">11.3.2</span> Example</a></li>
</ul>
</li>
<li><a class="nav-link" href="#moderation-and-interactions"><span class="header-section-number">11.4</span> Moderation and interactions</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/lbelzile/math80667a/blob/master/11-causal-inference.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/lbelzile/math80667a/edit/master/11-causal-inference.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Experimental Design and Statistical Methods</strong>" was written by Léo Belzile. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
