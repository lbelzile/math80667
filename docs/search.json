[{"path":"index.html","id":"preliminary-remarks","chapter":"Preliminary remarks","heading":"Preliminary remarks","text":"notes licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License last compiled 2021-08-29.objective course teach basic principles experimental designs statistical inference latter using R programming language. pay particular attention correct reporting interpretation results learn review critically scientific papers using experimental designs.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Learning terminology associated experiments.Assessing generalizability study based consideration sample characteristics, sampling scheme population.Distinguishing observational experimental studiesDescribing words four pillars experimental designs.Understanding rationale behind requirements good experimental studies translates model assumptions.field causal inference concerned inferring effect treatment variable (sometimes called independent variable) response variable (dependent variable). general, however (Cox 1958)effects investigation tend masked fluctuations outside experimenter’s control.purpose experiments arrange data collection capable disentangling differences due treatment due (often large) intrinsic variation measurements. typically expect differences treatments (thus effect) comparatively stable relative measurement variation.","code":""},{"path":"introduction.html","id":"terminology","chapter":"1 Introduction","heading":"1.1 Terminology","text":"simplest form, experimental design comparison two treatments (experimental conditions):subjects (experimental units) different groups treatment similar characteristics treated exactly way experimentation except treatment receiving. Formally, experimental unit smallest division two units may receive different treatments.observational unit smallest level (time point, individual) measurement recorded.experimental treatments conditions (also called factor, independent variable), manipulated controlled researcher. Oftentimes, control baseline treatment relative measure improvement (e.g., placebo drugs).Additional explanatories intrinsic experimental (sub-)units termed blocking factors. Controlling allows reduce variability measurements, typically leading improved inferences.different treatments administered subjects participating study, researcher measures one outcomes (also called responses dependent variables) subject.Observed differences outcome variable experimental conditions (treatments) called treatment effect (effect size).Example 1.1  (Pedagogical experience) Suppose want study effectiveness different pedagogical approaches learning. Evidence-based pedagogical researchs point active learning leads higher retention information. corroborate research hypothesis, can design experiment different sections course assigned different teaching methods. example, student class group receives teaching assignment, experimental units sections observations units individual students.treatment teaching method (traditional teaching versus flipped classroom).Potential blocking factors experiment include strength individuals, reflects prior exposure topic, knowledge, maturity, etc. measured using preliminary exam assignment students class groups completed. Additional factors worth controlling include timing classroom (morning, afternoon, evening classes) instructors.marketing department wants know value brand determining much customers willing pay product relative cheaper generic product offered store. Economic theory suggests substitution effect: customers may prefer brand product, switch generic version price tag high. check theory, one design experiment.researcher, conduct study? Identify specific product. latter, definean adequate response variablethe experimental observational unitspotential confounding variables need accounted .","code":""},{"path":"introduction.html","id":"review-of-basic-concepts","chapter":"1 Introduction","heading":"1.2 Review of basic concepts","text":"","code":""},{"path":"introduction.html","id":"variables","chapter":"1 Introduction","heading":"1.2.1 Variables","text":"choice statistical model test depends underlying type data collected. many choices: quantitative (discrete continuous) variables numeric, qualitative (binary, nominal, ordinal) can described using adjective; prefer term categorical, evocative. choice graphical representation data contingent variable type. Specifically,variable represents characteristic population, example sex individual, price item, etc.observation set measures (variables) collected identical conditions individual given time.\nFigure 1.1: Artwork Allison Horst continuous (left) discrete variables (right).\nmodels deal -called regression models, mean quantitative variable function variables, termed explanatories. two types numerical variablesa discrete variable takes countable number values, prime examples binary variables count variables.continuous variable can take (theory) infinite possible number values, even measurements rounded measured limited precision (time, width, mass). many case, also consider discrete variables continuous take enough values (e.g., money).Categorical variables take finite values. regrouped two groups, nominal ordering levels (sex, colour, country origin) ordinal ordered (Likert scale, salary scale) ordering reflected graphs tables. bundle every categorical variable using arbitrary encoding levels: modelling, variables taking \\(K\\) possible values (levels) must transformed set \\(K-1\\) binary 0/1 variables, omitted level corresponding baseline. Failing declare categorical variables favourite software common mistake, especially saved database using integers rather strings.\nFigure 1.2: Artwork Allison Horst examples categorical variables: nominal (left), ordinal (middle) binary (right).\n","code":""},{"path":"introduction.html","id":"population-sample","chapter":"1 Introduction","heading":"1.2.2 Population and samples","text":"well-designed sampling schemes results generalize beyond group observed. thus paramount importance define objective population interest want make conclusions.Generally, seek estimate characteristics population using sample (sub-group population smaller size). population interest collection individuals study targets. example, Labour Force Survey (LFS) monthly study conducted Statistics Canada, define target population “members selected household 15 years old older, whether work .” Asking every Canadian meeting definition costly process long: characteristic interest (employment) also snapshot time can vary person leaves job, enters job market become unemployed. example, collecting census impossible costly.general, therefore consider samples gather information seek obtain. purpose statistical inference draw conclusions population, using share latter accounting sources variability. pollster George Gallup made great analogy sample population:One spoonful can reflect taste whole pot, soup well-stirredA sample sub-group individuals drawn random population. won’t focus data collection, keep mind following information: sample good, must representative population study.Parcours AGIR HEC Montréal pilot project Bachelor Administration students initiated study impact flipped classroom active learning performance.think can draw conclusions efficacy teaching method comparing results students rest bachelor program? List potential issues approach addressing internal external validity, generalizability, effect lurking variables, etc.individuals selected random part sample, measurement characteristic interest also random change one sample next. larger samples typically carry information, sample size guarantee quality, following example demonstrates.Example 1.2  (Polling 1936 USA Presidential Election) Literary Digest surveyed 10 millions people mail know voting preferences 1936 USA Presidential Election. sizeable share, 2.4 millions answered, giving Alf Landon (57%) incumbent President Franklin D. Roosevelt (43%). latter nevertheless won landslide election 62% votes cast, 19% forecast error. Biased sampling differential non-response mostly responsible error: sampling frame built using ``phone number directories, drivers’ registrations, club memberships, etc.’’, skewed sample towards rich upper class white people susceptible vote GOP.contrast, Gallup correctly predicted outcome polling () 50K inhabitants. Read full story .considerations guide determining population interest study?","code":""},{"path":"introduction.html","id":"sampling","chapter":"1 Introduction","heading":"1.2.3 Sampling","text":"sampling costly, can collect limited information variable interest, drawing population sampling frame (phone books, population register, etc.) Good sampling frames can purchased sampling firms.general, randomization necessary order obtain representative sample1, one match characteristics population. Failing randomize leads introduction bias generally conclusions drawn study won’t generalizable.Even observational units selected random participate, may bias introduced due non-response. 1950s, conducting surveys relatively easier people listed telephone books; nowadays, sampling firms rely mix interactive voice response live callers, sampling frames mixing landlines, cellphones online panels together (heavy) weighting correct non-response. Sampling difficult problem engage cursorily, readers urged exercise scrutiny reading papers.Reflect choice platform used collect answers think influence composition sample returned affect non-response systematic way.examining problems related sampling, review main random sampling methods. simplest simple random sampling, whereby \\(n\\) units drawn completely random (uniformly) \\(N\\) elements sampling frame. second common scheme stratified sampling, whereby certain numbers units drawn uniformly strata, namely subgroups (e.g., gender). Finally, cluster sampling consists sampling subgroups.::: {.example name=“Illustration sampling schemes”}\nSuppose wish look student satisfaction regarding material taught introductory statistics course offered multiple sections. population consists students enrolled course given semester list provides sampling frame. can define strata consist class group. simple random sample obtaining sampling randomly abstracting class groups, stratified sample drawing randomly number class group cluster sampling drawing students selected class groups. Cluster sampling mostly useful groups similar costs associated sampling multiple strata expensive.\nFigure 1.3: Illustration three sampling schemes nine stratum: simple random sampling (left), stratified sampling (middle) cluster sampling (right).\nStratified sampling typically superior care similar proportions sampled group useful reweighting: 1.3, true proportion sampled 1/3, simple random sampling range [0.22, 0.39] among strata, compared [0.32, 0.34] stratified sample.credibility study relies large part quality data collection. customary report descriptive statistics sample description population?recent years, proliferation studies employing data obtained web experimentation plateforms Amazon’s Mechanical Turk (MTurk), point Journal Management commissioned review (Aguinis, Villamor, Ramani 2021). samples subject self-selection bias read skepticism. reserve tools paired samples (e.g., asking people perform multiple tasks presented random order) composition population relatively unimportant. make sure sample matches target population, can use statistical tests informal comparison compare repartition individuals composition obtained census.","code":""},{"path":"introduction.html","id":"study-type","chapter":"1 Introduction","heading":"1.2.4 Study type","text":"two categories studies: observational experimental. main difference two researchers collect data observational studies intervene treatment assignment data created, whereas assignment mechanism fully determined experimenter latter case.\nexample, economist studying impact interest rates price housing can look historical records sales. Similarly, surveys studying labour market also observational: people influence type job performed employees social benefits see happened. Observational studies can lead detection association, experiment researcher controls allocation mechanism randomization can lead directly establish existence causal relationship. everything else well controlled experiment, treatment effect principle caused factor.preceding paragraph shouldn’t taken mean one get meaningful conclusions observational studies. Rather, wish highlight controlling non-random allocation potential confounding much complicated, requires practitioners make stronger (sometimes unverifiable) assumptions requires using different toolbox (including, limited differences differences, propensity score weighting, instrumental variables).\nFigure 1.4: Two two classification matrix experiments based sampling study type. Material Mine Çetinkaya-Rundel OpenIntro distributed CC -SA license.\nFigure 1.4 summarizes two preceding sections. Random allocation observational units assignment treatment leads ideal studies, may impossible due ethical considerations.","code":""},{"path":"introduction.html","id":"examples-of-experimental-designs","chapter":"1 Introduction","heading":"1.3 Examples of experimental designs","text":"One earliest example statistical experiment agricultural field trial: fact, experiments ongoing since 1841 Rothamsted Experimental Station, R. . Fisher worked 14 years developed much early theory; Yates (1964) details contribution field design experiments.Section 1.4 Berger, Maurer, Celli (2018) lists various applications experimental designs variety fields.Find example scientific paper research field experimental study conducted.\n- Provide citation latter\n- Briefly describe experiment (can simply quote description database).\n- Based information provided, identify experimental units treatments.Example 1.3  (Modern experiments /B testing) modern experiments happen online, tech companies running thousands experiments ongoing basis order discover improvement interfaces lead increased profits. Harvard Business Review article (Kohavi Thomke 2017) details small tweaks display advertisements Microsoft Bing search engine landing page lead whooping 12% increase revenues. randomized control trials, termed /B experiments, involve splitting incoming traffic separate groups; group see different views webpage differ ever slightly. experimenters compare traffic click revenues. large scale, even small effects can major financial consequences can learned despite large variability customer behaviour.","code":""},{"path":"introduction.html","id":"evidence-based-policies","chapter":"1 Introduction","heading":"1.3.1 Evidence-based policies","text":"Experimental design revolves large part understanding best allocate resources choosing effective treatment lot. multiple examples randomized control experiments used policy making. Examples includeTennessee’s Student Teacher Achievement Ratio (STAR) project (Achilles et al. 2008): study looked effect student teacher ratio conclude smaller class sizes lead better outcomes.Four-year longitudinal class-size study funded Tennessee General Assembly conducted State Department Education. 7,000 students 79 schools randomly assigned one 3 interventions: small class (13 17 students per teacher), regular class (22 25 students per teacher), regular--aide class (22 25 students full-time teacher’s aide). Classroom teachers also randomly assigned classes teach. interventions initiated students entered school kindergarten continued third grade.RAND’s Health Insurance Experiment (Brook et al. 2006): study concluded cost sharing reduced “inappropriate unnecessary” medical care (overutilization), also lead areduction “appropriate needed” medical care.HIE large-scale, randomized experiment conducted 1971 1982. study, RAND recruited 2,750 families encompassing 7,700 individuals, age 65. chosen six sites across United States provide regional urban/rural balance. Participants randomly assigned one five types health insurance plans created specifically experiment. four basic types fee--service plans: One type offered free care; three types involved varying levels cost sharing — 25 percent, 50 percent, 95 percent coinsurance (percentage medical charges consumer must pay). fifth type health insurance plan nonprofit, HMO-style group cooperative. assigned HMO received care free charge. poorer families plans involved cost sharing, amount cost sharing income-adjusted one three levels: 5, 10, 15 percent income. --pocket spending capped percentages income $1,000 annually (roughly $3,000 annually adjusted 1977 2005 levels), whichever lower.Families participated experiment 3–5 years. upper age limit adults time enrollment 61, participants become eligible Medicare experiment ended. assess participant service use, costs, quality care, RAND served families’ insurer processed claims. assess participant health, RAND administered surveys beginning end experiment also conducted comprehensive physical exams. Sixty percent participants randomly chosen receive exams beginning study, received physicals end. random use physicals beginning intended control possible health effects might stimulated physical exam alone, independent participation experiment.Oregon Health Insurance Experiment (Baicker et al. 2013): study described length Section 9.5 Telling stories data Rohan Alexander (Alexander 2022).","code":""},{"path":"introduction.html","id":"planning-experiments","chapter":"1 Introduction","heading":"1.4 Planning of experiments","text":"four pillars experimental designs;Control: experiment, allocation treatment controlled experimenter, allowing direct comparisons groups.Randomization: prevent lurking variables confounders impacting conclusions, observational units randomly allocated treatment groups estimate effect causal interpretation.Replication: multiple observations treatment allocation necessary estimate variability measurements increase precision average measurement.Blocking: technique allows experimenters control variability experimental units dividing blocks blocks similar. allows us separate variability due differences levels blocking variable overall variability, leading precision gains.Underlying design experiments use techniques eliminate much possible variability detecting cause effects least amount resources allocating wisely.","code":""},{"path":"introduction.html","id":"requirements-for-good-experiments","chapter":"1 Introduction","heading":"1.5 Requirements for good experiments","text":"Section 1.2 Cox (1958) describes various requirements necessary experiments useful. areabsence systematic errorprecisionrange validitysimplicityWe review turn.","code":""},{"path":"introduction.html","id":"absence-of-systematic-error","chapter":"1 Introduction","heading":"1.5.1 Absence of systematic error","text":"point requires careful planning listing potential confounding variables affect response.Example 1.4  Suppose wish consider differences student performance two instructors. first teaches morning classes, second teaches evening, impossible disentangle effect timing instructor performance. comparisons undertaken compelling prior evidence timing impact outcome interest.first point raised Cox thus \n> ensure experimental units receiving one treatment differ systematic way receiving another treatment.point also motivates use double-blind procedures (experimenters participants unaware treatment allocation) use placebo control groups.Randomization core achieving goal, ensuring measurements independent one another also comes corolary.","code":""},{"path":"introduction.html","id":"variability","chapter":"1 Introduction","heading":"1.5.2 Variability","text":"second point listed Cox (1958) variability estimator. Much precision can captured signal noise ratio, effect size divided standard error. latter function \n() accuracy experimental work measurements apparatus intrinsic variability phenomenon study, (b) number experimental observational units, .e., sample size (c) choice design statistical procedures.Point () typically influenced experimenter outside choosing response variable obtain reliable measurements. Point (c) related method analysis, oftentimes standard unless robustness considerations. Point (b) core planning, notably choosing number units use allocation treatment different (sub)-units.","code":""},{"path":"introduction.html","id":"generalizability","chapter":"1 Introduction","heading":"1.5.3 Generalizability","text":"studies done objective generalizing findings beyond particular units analyzed. range validity thus crucially depends choice population sample drawn particular sampling scheme. Non-random sampling severely limits extrapolation results general settings. leads Cox advocate \n> just empirical knowledge treatment differences , also understanding reasons differences.Even believe factor effect, may wise introduce experiment check assumption: source variability, shouldn’t impact findings time provide robustness.look continuous treatment, probably safe draw conclusions within range doses administered. Comic 1.5 absurd, makes point.\nFigure 1.5: xkcd comic 645 (Extrapolating) Randall Munroe. Alt text: third trimester, thousands babies inside .\nExample 1.5  (Generalizability) Replication studies done university often draw participants students enrolled institutions. findings thus necessarily robust extrapolated whole population characteristics strong (familiarity technology, acquaintance administrative system, political views, etc). samples often convenience samples.Example 1.6  (Spratt-Archer barley Ireland) Example 1.9 Cox (1958) mentions recollections ``Student’’ Spratt-Archer barley, new variety barley performed well experiments Irish Department Agriculture encouraged introduced elsewhere. Fuelled district skepticism new variety, Department ran experiment comparing yield Spratt-Archer barley native race. findings surprised experimenters: native barley grew quickly resistant weeds, leading higher yields. concluded initial experiments misleading Spratt-Archer barley experimented well-farmed areas.","code":""},{"path":"introduction.html","id":"simplicity","chapter":"1 Introduction","heading":"1.5.4 Simplicity","text":"fourth requirement one simplicity design, almost invariably leads simplicity statistical analysis. Randomized control-trials often viewed golden rule determining efficacy policies treatments set assumptions make pretty minimalist due randomization. researchers management necessarily comfortable advanced statistical techniques also minimizes burden. 1.6 shows hypothetical graph efficacy Moderna MRNA vaccine Covid: difference clearly visible suitable experimental setting, conclusions easily drawn.Randomization justifies use statistical tools use weak assumptions, units measurements independent one another. Drawing conclusions observational studies, contrast experimental designs requires making often unrealistic unverifiable assumptions choice techniques required handle lack randomness often beyond toolbox applied researchers.\nFigure 1.6: xkcd comic 2400 (Statistics) Randall Munroe. Alt text: reject null hypothesis based ‘hot damn, check chart’ test.\nDefine following terms word: experimental unit, factor, effect sizeWhat main benefit experimental studies observational studies?List four pillars experimental design briefly describe .Box, Hunter, Hunter (1978) write page 103:Block can randomize .Explain benefit blocking confounding variables (possible) randomization.","code":""},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"2 Hypothesis testing","heading":"2 Hypothesis testing","text":"applied domains, empirical evidences drive advancement field data well designed experiments contribute built science. order draw conclusions favour theory, researchers turn (often unwillingly) statistics back claims. led prevalence use null hypothesis statistical testing (NHST) framework. One important aspect reproducibility crisis misuse \\(p\\)-values journal articles: falsification null hypothesis enough provide substantive findings theory.introductory statistics course typically present hypothesis tests without giving much thoughts underlying construction principles procedures, users often reductive view statistics catalogue pre-determined procedures. make culinary analogy, users focus learning recipes rather trying understand basics cookery. chapter focuses understanding key ideas related testing.","code":""},{"path":"hypothesis-testing.html","id":"distributions","chapter":"2 Hypothesis testing","heading":"2.1 Distributions","text":"","code":""},{"path":"hypothesis-testing.html","id":"sources-of-variability","chapter":"2 Hypothesis testing","heading":"2.2 Sources of variability","text":"call numerical summaries data statistics. important distinguish procedures/formulas numerical values. estimator rule formula used calculate estimate parameter quantity interest based observed data (like recipe). observed data can actually compute sample mean, , estimate — actual value. words,estimator procedure formula telling us use sample data compute estimate. estimator random since depends sample.estimate numerical value obtained apply formula observed data.example, sample mean \\(\\overline{Y}=n^{-1}(Y_1 + \\cdots + Y_n)\\) summary data. inputs function \\(\\overline{Y}\\) random, estimator also random. illustrate point, Figure 2.1 shows five simple random samples size \\(n=10\\) drawn hypothetical population mean \\(\\mu\\) standard deviation \\(\\sigma\\).\nFigure 2.1: Five samples size \\(n=10\\) drawn common population mean \\(\\mu\\) (horizontal line). colored segments show sample means sample.\ncan clearly see Figure 2.1 , \\(\\mu\\) constant, sample mean varies one sample next result sampling variability. astute eye notice sample means less dispersed around \\(\\mu\\) individual measurements. sample mean \\(\\overline{Y}\\) based many observations, information available.Simply looking values sample mean tell whole picture: must also consider variability. square root variance statistic termed standard error; confused standard deviation \\(\\sigma\\) population \\(Y\\) drawn. One can show standard error sample mean \\(\\mathsf{se}(\\overline{Y}) = \\sigma/\\sqrt{n}\\). standard deviation standard error expressed units measurements, easier interpret variance.next section, outline hypothesis testing helps us disentangle signal noise.","code":""},{"path":"hypothesis-testing.html","id":"tests","chapter":"2 Hypothesis testing","heading":"2.3 Hypothesis testing","text":"hypothesis test binary decision rule used evaluate statistical evidence provided sample make decision regarding underlying population. main steps involved :define model parametersformulate alternative null hypothesischoose calculate test statisticobtain null distribution describing behaviour test statistic \\(\\mathscr{H}_0\\)calculate p-valueconclude (reject fail reject \\(\\mathscr{H}_0\\)) context problem.good analogy hypothesis tests trial murder appointed juror.judge lets choose two mutually exclusive outcome, guilty guilty, based evidence presented court.presumption innocence applies evidences judged optic: evidence remotely plausible person innocent? burden proof lies prosecution avoid much possible judicial errors. null hypothesis \\(\\mathscr{H}_0\\) guilty, whereas alternative \\(\\mathscr{H}_a\\) guilty. reasonable doubt, verdict trial guilty.test statistic (choice test) represents summary proof. overwhelming evidence, higher chance accused declared guilty. prosecutor chooses proof best outline : choice evidence (statistic) ultimately maximize evidence, parallels power test.null distribution benchmark judge evidence (jurisprudence). Given proof, odds assuming person innocent?final step verdict. binary decision, guilty guilty. hypothesis test performed level \\(\\alpha\\), one reject (guilty) p-value less \\(\\alpha\\). Even declare person guilty, doesn’t mean defendant innocent vice-versa.","code":""},{"path":"hypothesis-testing.html","id":"hypothesis","chapter":"2 Hypothesis testing","heading":"2.3.1 Hypothesis","text":"statistical tests two hypotheses: null hypothesis (\\(\\mathscr{H}_0\\)) alternative hypothesis (\\(\\mathscr{H}_1\\)). Usually, null hypothesis single numerical value (‘status quo’) alternative ’re really interested testing. statistical hypothesis test allows us decide whether data provides enough evidence reject \\(\\mathscr{H}_0\\) favour \\(\\mathscr{H}_1\\), subject pre-specified risk error. Usually, hypothesis tests involve parameter, say \\(\\theta\\), characterizes underlying distribution population level ans whose value unknown. two-sided hypothesis test regarding parameter \\(\\theta\\) form\n\\[\\begin{align*}\n\\mathscr{H}_0: \\theta=\\theta_0 \\qquad \\text{versus} \\qquad \\mathscr{H}_a:\\theta \\neq \\theta_0.\n\\end{align*}\\]\ntesting whether \\(\\theta\\) precisely equal value \\(\\theta_0\\).completely randomized experiments single factor, testing whether mean \\(K\\) different sub-populations equal. Let \\(\\mu_1, \\ldots, \\mu_K\\) denote expectation theoretical mean \\(K\\) sub-populations. Equality means translates \n\\[\\begin{align*}\n\\mathscr{H}_0:& \\mu_1 = \\cdots = \\mu_K\n\\mathscr{H}_a:& \\text{least two means different, }\\mu_i \\neq \\mu_j (1 \\leq < j \\leq K).\n\\end{align*}\\]\nNote null hypothesis single value, whereas alternative complement, .e. potential scenarios expectations equal.One slight complication arising expectations \\(\\mu_1, \\ldots, \\mu_K\\) unknown. can assess comparing sample means group. noisy estimates expectation: inherent variability limits ability detect differences mean.","code":""},{"path":"hypothesis-testing.html","id":"test-statistic","chapter":"2 Hypothesis testing","heading":"2.3.2 Test statistic","text":"test statistic \\(T\\) function data summarize information contained sample \\(\\theta\\). form test statistic chosen know underlying distribution \\(\\mathscr{H}_0\\), , potential values taken \\(T\\) relative probability \\(\\mathscr{H}_0\\) true. Indeed, \\(Y\\) random variable value change one sample next.\nallows us determine values \\(T\\) likely \\(\\mathscr{H}_0\\) true. Many statistics consider Wald statistic, form\n\\[\\begin{align*}\nT = \\frac{\\widehat{\\theta} - \\theta_0}{\\mathrm{se}(\\widehat{\\theta})}\n\\end{align*}\\]\n\\(\\widehat{\\theta}\\) estimator \\(\\theta\\), \\(\\theta_0\\) postulated value parameter \\(\\mathrm{se}(\\widehat{\\theta})\\) estimator standard deviation test statistic \\(\\widehat{\\theta}\\).example, test whether mean population zero, set\n\\[\\begin{align*}\n\\mathscr{H}_0: \\mu=0, \\qquad  \\mathscr{H}_a:\\mu \\neq 0,\n\\end{align*}\\]\nWald statistic \n\\[\\begin{align*}\nT &= \\frac{\\overline{X}-0}{S_n/\\sqrt{n}}\n\\end{align*}\\]\n\\(\\overline{X}\\) sample mean \\(X_1, \\ldots, X_n\\),\n\\[\\begin{align*}\n\\overline{X} &= \\frac{1}{n} \\sum_{=1}^n X_i = \\frac{X_1+ \\cdots + X_n}{n}\n\\end{align*}\\]\nstandard error (mean) \\(\\overline{X}\\) \\(S_n/\\sqrt{n}\\); sample variance \\(S_n\\) estimator standard deviation \\(\\sigma\\),\n\\[\\begin{align*}\nS^2_n &= \\frac{1}{n-1} \\sum_{=1}^n (X_i-\\overline{X})^2.\n\\end{align*}\\]","code":""},{"path":"hypothesis-testing.html","id":"null-distribution-and-p-value","chapter":"2 Hypothesis testing","heading":"2.3.3 Null distribution and p-value","text":"p-value allows us decide whether observed value test statistic \\(T\\) plausible \\(\\mathscr{H}_0\\). Specifically, p-value probability test statistic equal extreme estimate computed data, assuming \\(\\mathscr{H}_0\\) true. Suppose based random sample \\(X_1, \\ldots, X_n\\) obtain statistic whose value \\(T=t\\). two-sided test \\(\\mathscr{H}_0:\\theta=\\theta_0\\) vs. \\(\\mathscr{H}_a:\\theta \\neq \\theta_0\\), p-value \\(\\mathsf{Pr}_0(|T| \\geq |t|)\\). distribution \\(T\\) symmetric around zero, p-value \n\\[\\begin{align*}\np = 2 \\times \\mathsf{Pr}_0(T \\geq |t|).\n\\end{align*}\\]Consider example two-sided test involving population mean \\(\\mathscr{H}_0:\\mu=0\\) alternative \\(\\mathscr{H}_1:\\mu \\neq 0\\). Assuming random sample comes normal (population) \\(\\mathsf{}(\\mu, \\sigma^2)\\), can shown \\(\\mathscr{H}_0\\) true (, \\(\\mu=0\\)), test statistic\n\\[\\begin{align*}\nT = \\frac{\\overline{X}}{S/\\sqrt{n}}\n\\end{align*}\\]\nfollows Student-t distribution \\(n-1\\) degrees freedom, denoted \\(\\mathsf{St}_{n-1}\\). allows us calculate p-value (either table, using statistical software). Student-t distribution symmetric zero, p-value \\(P = 2\\times\\mathsf{Pr}(T_{n-1} > |t|)\\), \\(T \\sim \\mathsf{St}_{n-1}\\).","code":""},{"path":"hypothesis-testing.html","id":"conclusion","chapter":"2 Hypothesis testing","heading":"2.3.4 Conclusion","text":"p-value allows us make decision null hypothesis. \\(\\mathscr{H}_0\\) true, p-value follows uniform distribution. Thus, p-value small, means observing outcome extreme \\(T=t\\) unlikely, ’re inclined think \\(\\mathscr{H}_0\\) true. ’s always underlying risk ’re making mistake make decision. statistic, two type errors:type error: reject \\(\\mathscr{H}_0\\) \\(\\mathscr{H}_0\\) true,type II error: fail reject \\(\\mathscr{H}_0\\) \\(\\mathscr{H}_0\\) false.hypothesis judged equally: seek avoid error type (judicial errors, corresponding condamning innocent). prevent , fix level test, \\(\\alpha\\), captures tolerance risk commiting type error: higher level test \\(\\alpha\\), often reject null hypothesis latter true. value \\(\\alpha \\(0, 1)\\) probability rejecting \\(\\mathscr{H}_0\\) \\(\\mathscr{H}_0\\) fact true,\n\\[\\begin{align*}\n\\alpha = \\mathsf{Pr}_0\\left(\\text{ reject } \\mathscr{H}_0\\right).\n\\end{align*}\\]\nlevel \\(\\alpha\\) fixed beforehand, typically \\(1\\)%, \\(5\\)% \\(10\\)%. Keep mind probability type error \\(\\alpha\\) null model \\(\\mathscr{H}_0\\) correct (sic) correspond data generating mechanism.focus type error best understood thinking costs moving away status quo: new website design branding costly implement, want make sure enough evidence better alternative.make decision, compare p-value \\(P\\) level test \\(\\alpha\\):\\(P < \\alpha\\), reject \\(\\mathscr{H}_0\\);\\(P \\geq \\alpha\\), fail reject \\(\\mathscr{H}_0\\).mix level test (probability fixed beforehand researcher) p-value. test level 5%, probability type error definition \\(\\alpha\\) depend p-value. latter conditional probability observing extreme likelihood given null distribution \\(\\mathscr{H}_0\\) true.","code":""},{"path":"hypothesis-testing.html","id":"power","chapter":"2 Hypothesis testing","heading":"2.3.5 Power","text":"two sides hypothesis test: either want show unreasonable assume null hypothesis, else want show beyond reasonable doubt difference effect significative: example, one wish demonstrate new website design (alternative hypothesis) leads significant increase sales relative status quo. ability detect improvements make discoveries depends power test: larger power, greater ability reject \\(\\mathscr{H}_0\\) latter false.Failing reject \\(\\mathscr{H}_0\\) \\(\\mathscr{H}_a\\) true (guilty verdict criminal) corresponds definition type II error, probability \\(1-\\gamma\\), say. power test probability rejecting \\(\\mathscr{H}_0\\) \\(\\mathscr{H}_0\\) false, .e.,\n\\[\\begin{align*}\n\\gamma = \\mathsf{Pr}_a(\\text{reject} \\mathscr{H}_0)\n\\end{align*}\\]\nDepending alternative models, less easy detect null hypothesis false reject favor alternative.\nFigure 2.2: Comparison null distribution (full curve) specific alternative t-test (dashed line). power corresponds area curve density alternative distribution rejection area (white).\n\nFigure 2.3: Increase power due increase mean difference null alternative hypothesis. Power area rejection region (white) alternative distribution (dashed): latter shifted right relative null distribution (full line).\n\nFigure 2.4: Increase power due increase sample size decrease standard deviation population: null distribution (full line) concentrated. Power given area (white) curve alternative distribution (dashed). general, null distribution changes sample size.\nwant choose experimental design test statistic leads high power, \\(\\gamma\\) close possible one. Minimally, power test \\(\\alpha\\) reject null hypothesis \\(\\alpha\\) fraction time even \\(\\mathscr{H}_0\\) true. Power depends many criteria, notablythe effect size: bigger difference postulated value \\(\\theta_0\\) \\(\\mathscr{H}_0\\) observed behaviour, easier departures \\(\\theta_0\\).\n(Figure 2.4);variability: less noisy data, easier detect differences curves (big differences easier spot, Figure 2.3 shows);sample size: observation, higher ability detect significative differences standard error decreases sample size \\(n\\) rate (typically) \\(n^{-1/2}\\). null distribution also becomes concentrated sample size increase. experimental designs, power may maximized specifying different sample size groupthe choice test statistic: example, rank-based statistics discard information observed values response, focusing instead relative ranking. resulting tests typically less powerful, robust model misspecification outliers.calculate power test, need single specific alternative hypothesis. special case, analytic derivations possible: example, one-sample t-test statistic \\(T=\\sqrt{n}(\\overline{X}_n-\\mu_0)/S_n \\sim \\mathcal{T}_{n-1}\\) normal sample follows noncentral Student-\\(t\\) distribution noncentrality parameter \\(\\Delta\\) expectation population \\(\\Delta + \\mu_0\\). general, closed-form expressions easily obtained compute instead power test Monte Carlo methods. given alternative, simulate repeatedly samples model, compute test statistic new samples associated p-values based postulated null hypothesis. can calculate proportion tests lead rejection null hypothesis level \\(\\alpha\\), namely percentage p-values smaller \\(\\alpha\\).","code":""},{"path":"hypothesis-testing.html","id":"confidence-interval","chapter":"2 Hypothesis testing","heading":"2.3.6 Confidence interval","text":"confidence interval alternative way present conclusions hypothesis test performed significance level \\(\\alpha\\). often combined point estimator \\(\\hat{\\theta}\\) give indication variability estimation procedure. Wald-based \\((1-\\alpha)\\) confidence intervals parameter \\(\\theta\\) form\n\\[\\begin{align*}\n\\widehat{\\theta} \\pm \\mathfrak{q}_{\\alpha/2} \\; \\mathrm{se}(\\widehat{\\theta})\n\\end{align*}\\]\n\\(\\mathfrak{q}_{\\alpha/2}\\) \\(1-\\alpha/2\\) quantile null distribution Wald statistic\n\\[\\begin{align*}\nT =\\frac{\\widehat{\\theta}-\\theta}{\\mathrm{se}(\\widehat{\\theta})},\n\\end{align*}\\]\n\\(\\theta\\) represents postulated value fixed, unknown value parameter. bounds confidence intervals random variables, since estimators parameter standard error, \\(\\widehat{\\theta}\\) \\(\\mathrm{se}(\\widehat{\\theta})\\), random variables: values vary one sample next.example, random sample \\(X_1, \\ldots, X_n\\) normal distribution \\(\\mathsf{}(\\mu, \\sigma)\\), (\\(1-\\alpha\\)) confidence interval population mean \\(\\mu\\) \n\\[\\begin{align*}\n\\overline{X} \\pm t_{n-1, \\alpha/2} \\frac{S}{\\sqrt{n}}\n\\end{align*}\\]\n\\(t_{n-1,\\alpha/2}\\) \\(1-\\alpha/2\\) quantile Student-\\(t\\) distribution \\(n-1\\) degrees freedom.interval calculated, \\(1-\\alpha\\) probability \\(\\theta\\) contained random interval \\((\\widehat{\\theta} - \\mathfrak{q}_{\\alpha/2} \\; \\mathrm{se}(\\widehat{\\theta}), \\widehat{\\theta} + \\mathfrak{q}_{\\alpha/2} \\; \\mathrm{se}(\\widehat{\\theta}))\\), \\(\\widehat{\\theta}\\) denotes estimator. obtain sample calculate confidence interval, notion probability: true value parameter \\(\\theta\\) either confidence interval . can interpret confidence interval’s follows: repeat experiment multiple times, calculate \\(1-\\alpha\\) confidence interval time, roughly \\(1-\\alpha\\) calculated confidence intervals contain true value \\(\\theta\\) repeated samples (way, flip coin, roughly 50-50 chance getting heads tails, outcome either). confidence procedure use calculate confidence intervals actual values obtain sample.\nFigure 2.5: 95% confidence intervals mean standard normal population \\(\\mathsf{}(0,1)\\), 100 random samples. average, 5% intervals fail include true mean value zero (red).\ninterested binary decision rule reject/fail reject \\(\\mathscr{H}_0\\), confidence interval equivalent p-value since leads conclusion. Whereas \\(1-\\alpha\\) confidence interval gives set values test statistic doesn’t provide enough evidence reject \\(\\mathscr{H}_0\\) level \\(\\alpha\\), p-value gives probability null obtaning result extreme postulated value precise particular value. p-value smaller \\(\\alpha\\), null value \\(\\theta\\) outside confidence interval vice-versa.example, consider difference average amount spent Y members previous generations: mean difference samples -16.49 dollars thus millenials spend . However, enough conclude different significative, can say meaningful. amount spent online varies one individual next (plausibly month month), different random samples yield different mean differences.first step analysis defining parameters corresponding quantities interest formulating null alternative hypothesis function parameters. consider test difference mean two populations, say \\(\\mu_1\\) expected amount spent generation Y \\(\\mu_2\\) older generations, respective standard errors \\(\\sigma_1\\) \\(\\sigma_2\\). next write hypothesis: researcher interested whether millenials spend , alternative hypothesis, \\(\\mathscr{H}_a: \\mu_1 > \\mu_2\\). null consists values \\(\\mathscr{H}_0: \\mu_1 \\leq \\mu_2\\), \\(\\mu_1=\\mu_2\\) matters purpose testing (?)second step choice test statistic. consider Welch (1947) statistic difference mean two samples,\n\\[\\begin{align*}\nT = \\frac{\\overline{X}_1 - \\overline{X}_2}{\\left(\\frac{S_1^2}{n_1}+\\frac{S_2^2}{n_2} \\right)^{1/2}}, \\end{align*}\\]\n\\(\\overline{X}_i\\) sample mean, \\(S_i^2\\) unbiased variance estimator \\(n_i\\) sample size group \\(\\) (\\(=1, 2\\)). mean difference two samples zero, \\(\\overline{X}_1-\\overline{X}_2\\) mean zero difference variance \\(\\sigma^2_1/n_1+\\sigma^2_2/n_2\\). sample, value statistic \\(T=-2.76\\) Since value changes one sample next, need determine value compatible null hypothesis comparing null distribution \\(T\\) (\\(\\mathscr{H}_0\\) true \\(\\mu_1-\\mu_2=0\\)). perform test level \\(\\alpha=0.05\\).third step consists obtaining benchmark determine result extreme unusual. make comparisons easier, standardize statistic mean zero variance one null hypothesis \\(\\mu_1=\\mu_2\\), obtain dimensionless measure whose behaviour know large sample. (mathematical) derivation null distribution beyond scope course, given cases. Asymptotically, \\(T\\) follows standard normal distribution \\(\\mathsf{}(0, 1)\\), exists better finite-sample approximation \\(n_1\\) \\(n_2\\) small; use Satterthwaite (1946) Student-\\(t\\) distribution null distribution.remains compute p-value. null distribution well-specified \\(\\mathscr{H}_0\\) true, random variable \\(P\\) uniform \\([0, 1]\\); thus expect obtain null something larger 0.95 5% time one-sided alternative since consider \\(\\mathscr{H}_0\\) event \\(\\mathsf{Pr}(T > t)\\). \\(p\\)-value \\(1\\) , level 5%, reject null hypothesis conclude millenials spend significantly previous generation monthly online purchases, estimated average difference -16.49.","code":""},{"path":"reproducibility-crisis.html","id":"reproducibility-crisis","chapter":"3 Reproducibility crisis","heading":"3 Reproducibility crisis","text":"Defining replicability reproducibility.Understanding scale reproducibility crisis.Recognizing common statistical fallacies.Listing strategies enhancing reproducibility.adopt terminology Claerbout Karrenbach (1992): study said reproducible external person data enough indications procedure (example, code software versions, etc.) can obtain consistent results match paper. related scientific matter replicability, process new data collected test hypothesis, potentially using different methodology. Reproducibility important enhances credibility one’s work. Extensions deal different analyses leading conclusion described Turing Way presented 3.1.\nFigure 3.1: Definition different dimensions reproducible research (Turing Way project, illustration Scriberia).\nreproducibility important? thought provoking paper, Ioannidis (2005) claimed research findings wrong. abstract paper statedThere increasing concern current published research findings false. […] framework, research finding less likely true studies conducted field smaller; effect sizes smaller; greater number lesser preselection tested relationships; greater flexibility designs, definitions, outcomes, analytical modes; greater financial interest prejudice; teams involved scientific field chase statistical significance.Since publication, collaborative efforts tried assess scale reproducibility problem reanalysing data trying replicate findings published research. example, “Reproducibility Project: Psychology” (Nosek et al. 2015)conducted replications 100 experimental correlational studies published three psychology journals using high powered designs original materials available. Replication effects half magnitude original effects, representing substantial decline. Ninety seven percent original studies significant results. Thirty six percent replications significant results; 47% original effect sizes 95% confidence interval replication effect size; 39% effects subjectively rated replicated original result; , bias original results assumed, combining original replication results left 68% significant effects. […]large share findings review replicable effects much smaller claimed, shown Figure 2 study.\nfindings show peer-review procedure foolproof: “publish--perish” mindset academia leading many researchers try achieve statistical significance costs meet 5% level criterion, whether involuntarily . problem many names: \\(p\\)-hacking, harking paraphrase story Jorge Luis Borges, garden forking paths. many degrees freedom analysis researchers refine hypothesis viewing data, conducting many unplanned comparisons reporting selected results.\nFigure 3.2: Figure 2 Nosek et al. (2015), showing scatterplot effect sizes original replication study power, rugs density plots significance 5% level.\nAnother problem selective reporting. large emphasis placed statistical significance, many studies find small effects never published, resulting gap. Figure 3.3 Zwet Cator (2021) shows \\(z\\)-scores obtained transforming confidence intervals reported Barnett Wren (2019), used data mining techniques extract confidence intervals abstracts nearly one million publication Medline published 1976 2019.\nfinding published, \\(z\\)-scores normally distributed, Figure 3.3 shows big gap bell curve approximately \\(-2\\) \\(2\\).\nFigure 3.3: Figure Zwet Cator (2021) based results Barnett Wren (2019); histogram \\(z\\)-scores one million studies Medline.\nongoing debate surrounding reproducibility crisis sparked dramatic changes academic landscape: enhance quality studies published, many journal now require authors provide code data, pre-register studies, etc. Teams lead effort (e.g., Experimental Economics Replication Project) try replicate studies, mitigated success far. inside recollection graduate student shows extent problem.course place strong emphasis identifying avoiding statistical fallacies showcasing methods enhance reproducibility. can reproducible research enhance work? one thing, workflow facilitates publication negative research, forces researchers think ahead time (receive feedback). Reproducible research data availability also leads additional citations increased credibility scientist.Among good practices arepre-registration experiments use logbook.version control systems (e.g., Git) track changes files records.archival raw data proper format accompanying documentation.Keeping logbook documenting progress helps collaborators, reviewers future-self understand decisions may seem unclear arbitrary future, even result careful thought process time made . Given pervasiveness garden forking paths, pre-registration helps prevents harking limits selective reporting unplanned tests, panacea. Critics often object pre-registration claiming binds people. misleading claim view: pre-registration doesn’t mean must stick plan exactly, merely requires explain go planned.Version control keeps records changes file can help retrieve former versions make mistakes point.\nFigure 3.4: Tweet showing widespread problems related unintentional changes raw data software.\nArchival data helps avoid unintentional irreversible manipulations original data, examples can large scale consequences illustrated Figure 3.4 (Ziemann El-Osta 2016), report flaws genetic journals due automatic conversion gene names dates Excel. problems far unique sensible data shared “” confidentiality issues, many instances data can made available licence DOI allow people reuse, cite credit work.Operating open-science environment seen opportunity make better science, offer opportunities increase impact increase publication work regardless whether results turn negative. right thing increases quality research produced, collateral benefits forces researchers validate methodology , double-check data analysis adopt good practice.Reflect workflow applied researcher designing undertaking experiments. practical aspects improve upon improve reproducibility study?","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
