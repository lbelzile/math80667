[{"path":"index.html","id":"experimental-design-and-statistical-methods","chapter":"Experimental Design and Statistical Methods","heading":"Experimental Design and Statistical Methods","text":"book web complement MATH 80667A Experimental Designs Statistical Methods Quantitative Research Management, graduate course offered joint Ph.D. program Management HEC Montréal.notes licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License last compiled Tuesday, July 19 2022.objective course teach basic principles experimental designs statistical inference using R programming language. pay particular attention correct reporting interpretation results learn review critically scientific papers using experimental designs.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"advancement science built ability study assess research hypotheses. chapter covers basic concepts experiments, starting vocabulary associated field. Emphasis placed difference experiments observations.course covers experimental designs. experiment, researcher manipulates one features (say complexity text person must read, type advertisement campaign displayed, etc.) study impact. field causal inference concerned inferring effect treatment variable (sometimes called independent variable) response variable (dependent variable). general, however (Cox 1958)effects investigation tend masked fluctuations outside experimenter’s control.purpose experiments arrange data collection capable disentangling differences due treatment due (often large) intrinsic variation measurements. typically expect differences treatments (thus effect) comparatively stable relative measurement variation.Learning objectives:Learning terminology associated experiments.Assessing generalizability study based consideration sample characteristics, sampling scheme population.Distinguishing observational experimental studies.Understanding rationale behind requirements good experimental studies.","code":""},{"path":"introduction.html","id":"study-type","chapter":"1 Introduction","heading":"1.1 Study type","text":"two main categories studies: observational experimental. main difference two treatment assignment. observational studies, feature potential cause measured, assigned experimenter. contrast, treatment assignment mechanism fully determined experimenter latter case.example, economist studying impact interest rates price housing can look historical records sales. Similarly, surveys studying labour market also observational: people influence type job performed employees social benefits see happened. Observational studies can lead detection association, experiment researcher controls allocation mechanism randomization can lead directly establish existence causal relationship. everything else well controlled experiment, treatment effect principle caused factor.1\nFigure 1.1: Two two classification matrix experiments based sampling study type. Source: Mine Çetinkaya-Rundel OpenIntro, distributed CC -SA license.\nFigure 1.1 summarizes two preceding sections. Random allocation observational units treatment random samples population lead ideal studies, may impossible due ethical considerations.","code":""},{"path":"introduction.html","id":"terminology","chapter":"1 Introduction","heading":"1.2 Terminology","text":"simplest form, experimental design comparison two treatments (experimental conditions):subjects (experimental units) different groups treatment similar characteristics treated exactly way experimentation except treatment receiving. Formally, experimental unit smallest division two units may receive different treatments.observational unit smallest level (time point, individual) measurement recorded.experimental treatments conditions (also called factor, independent variable), manipulated controlled researcher. Oftentimes, control baseline treatment relative measure improvement (e.g., placebo drugs).Additional explanatories intrinsic experimental (sub-)units termed blocking factors. Controlling allows reduce variability measurements, typically leading improved inferences.different treatments administered subjects participating study, researcher measures one outcomes (also called responses dependent variables) subject.Observed differences outcome variable experimental conditions (treatments) called treatment effect (effect size).Example 1.1  (Pedagogical experience) Suppose want study effectiveness different pedagogical approaches learning. Evidence-based pedagogical researchs point active learning leads higher retention information. corroborate research hypothesis, can design experiment different sections course assigned different teaching methods. example, student class group receives teaching assignment, experimental units sections observational units individual students. treatment teaching method (traditional teaching versus flipped classroom).Potential blocking factors experiment include strength individuals, reflects prior exposure topic, knowledge, maturity, etc. measured using preliminary exam assignment students class groups completed. Additional factors worth controlling include timing classroom (morning, afternoon, evening classes) instructors.marketing department company wants know value brand determining much customers willing pay product relative cheaper generic product offered store. Economic theory suggests substitution effect: customers may prefer brand product, switch generic version price tag high. check theory, one design experiment.researcher, conduct study? Identify specific product. latter, definean adequate response variablethe experimental observational unitspotential blocking factorsThe main reason experiments preferred collection observational data allow us, conducted properly, draw causal conclusions phenomenon interest. take random sample population interest, split randomly manipulate certain aspects, differences groups must due changes.Hariton Locascio (2018) put :Randomised controlled trials (RCTs) reference standard studying causal\nrelationships interventions outcomes randomisation eliminates much \nbias inherent study designsQuasi experimentsSometimes, impossible unethical conduct experiment. seemingly precludes study many social phenomena, effect women infantile mortality strict bans abortions. changes legislation occur (Supreme court overturning Roe Wade), offers window compare neighbouring states.Canadian economist David Card co-awarded 2021 Nobel Memorial Prize Economic Sciences work experimental economics. One cited paper Card Krueger (1994), study looked impact increase minimum wage employment figures. Card Krueger (1994) used planned increase minimum wage $0.80 USD New Jersey make comparisons neighbouring Eastern Pennsylvania counties studying 410 fast food outlets. authors found evidence negative impact employment hike.Point terminology: internal external validityA study can study causal relationships said internal validity. design, experiments desirable property random allocation treatment guarantees, randomization well performed, effect interest causal.observational studies, disentangling causal relationship difficult. Correlation causation, phenomenon complex tens variables potentially influencing factors study response.External validity refers directly generalizability conclusions study: 1.1 shows external validity directly related random sampling population","code":""},{"path":"introduction.html","id":"review-of-basic-concepts","chapter":"1 Introduction","heading":"1.3 Review of basic concepts","text":"","code":""},{"path":"introduction.html","id":"variables","chapter":"1 Introduction","heading":"1.3.1 Variables","text":"choice statistical model test depends underlying type data collected. many choices: quantitative (discrete continuous) variables numeric, qualitative (binary, nominal, ordinal) can described using adjective; prefer term categorical, evocative. choice graphical representation data contingent variable type. Specifically,variable represents characteristic population, example sex individual, price item, etc.observation set measures (variables) collected identical conditions individual given time.\nFigure 1.2: Illustration continuous (left) discrete variables (right). Artwork Allison Horst shared CC 4.0 license.\nmodels deal -called regression models, mean quantitative variable function variables, termed explanatories. two types numerical variablesa discrete variable takes countable number values, prime examples binary variables count variables.continuous variable can take (theory) infinite possible number values, even measurements rounded measured limited precision (time, width, mass). many case, also consider discrete variables continuous take enough values (e.g., money).Categorical variables take finite values. regrouped two groups, nominal ordering levels (sex, colour, country origin) ordinal ordered (Likert scale, salary scale) ordering reflected graphs tables. bundle every categorical variable using arbitrary encoding levels: modelling, variables taking \\(K\\) possible values (levels) must transformed set \\(K-1\\) binary variables \\(T_1, \\ldots, T_K\\), corresponds logical group \\(k\\) (yes = 1, = 0), omitted level corresponding baseline \\(K-1\\) indicators zero. Failing declare categorical variables software common mistake, especially saved database using integers (1,2, \\(\\ldots\\)) rather text (Monday, Tuesday, \\(\\ldots\\)).\nFigure 1.3: Examples categorical nominal (left), ordinal (middle) binary (right) variables. Artwork Allison Horst shared CC 4.0 license.\ncan characterize set potential values measurements can take, together frequency, via distribution. latter can represented graphically using histogram density plot2 data continuous, bar plot discrete categorical measurements.Example 1.2  (Die toss) distribution outcomes die toss discrete takes values \\(1, \\ldots, 6\\). outcome equally likely probability 1/6.Example 1.3  (Normal distribution) Mathematical theory suggests , general conditions, distribution sample average approximately distributed according normal (aka Gaussian) distribution: result central statistics. Normally distributed data continuous; distribution characterized bell curve, light tails symmetric around ’s mean. shape facade Hallgrímskirkja church Reykjavik, shown Figure 1.4, closely resembles density normal distribution, lead Khoa Vu call ‘normal church’ (chuckles).\nFigure 1.4: Photography Hallgrímskirkja church Reykjavik, Iceland Dolf van der Haven, reproduced CC -ND-NC 2.0 license.\nnormal distribution fully characterized two parameters: average \\(\\mu\\) standard deviation \\(\\sigma\\). left panel Figure 1.5 shows arbitrary continuous distribution values random sample \\(n=1000\\) draws. right panel shows histogram sample mean value based large number random samples size \\(n=25\\), drawn distribution. superimposed black curve normal density curve whose parameters match given central limit theorem: approximation seemingly quite accurate.fact explains omnipresence normal distribution introductory data science courses, well prevalence sample mean sample variance key summary statistics.3\nFigure 1.5: Graphical representation distribution continuous variable, histogram sample \\(n=1000\\) observations drawn distribution (left) distribution sample mean, obtained repeatedly drawing random sample \\(n=25\\) observations computing average (right). curve shows normal distribution approximation based central limit theorem.\nOne key aspect, often neglected studies, discussion metric used measurement response. previous research may identified instruments (like questionnaires) particular wording studying particular aspect individuals, lot free room researchers choose may impact conclusions. example, one uses Likert scale, range scale? coarse choice may lead limited capability detect, truthfulness, may\nlarger intrinsic measurement finer scale.Likewise, many continuous measures (say fMRI signal) can discretized provide single numerical value. Choosing average signal, range, etc. outcome variable may lead different conclusions.Choosing particular instrument metric principle done studying (apriori) distribution values chosen metric using pilot study: give researchers grasp variability measures.heart analysis measurements. data presented course cleaned oftentimes choice explanatory variable factor evident context. applications, however, choice always trivial.","code":""},{"path":"introduction.html","id":"population-sample","chapter":"1 Introduction","heading":"1.3.2 Population and samples","text":"well-designed sampling schemes results generalize beyond group observed. thus paramount importance define objective population interest want make conclusions.Generally, seek estimate characteristics population using sample (sub-group population smaller size). population interest collection individuals study targets. example, Labour Force Survey (LFS) monthly study conducted Statistics Canada, define target population “members selected household 15 years old older, whether work .” Asking every Canadian meeting definition costly process long: characteristic interest (employment) also snapshot time can vary person leaves job, enters job market become unemployed. example, collecting census impossible costly.general, therefore consider samples gather information seek obtain. purpose statistical inference draw conclusions population, using share latter accounting sources variability. pollster George Gallup made great analogy sample population:One spoonful can reflect taste whole pot, soup well-stirredA sample sub-group individuals drawn random population. won’t focus data collection, keep mind following information: sample good, must representative population study.Parcours AGIR HEC Montréal pilot project Bachelor Administration students initiated study impact flipped classroom active learning performance.think can draw conclusions efficacy teaching method comparing results students rest bachelor program? List potential issues approach addressing internal external validity, generalizability, effect lurking variables, etc.individuals selected random part sample, measurement characteristic interest also random change one sample next. larger samples typically carry information, sample size guarantee quality, following example demonstrates.Example 1.4  (Polling 1936 USA Presidential Election) Literary Digest surveyed 10 millions people mail know voting preferences 1936 USA Presidential Election. sizeable share, 2.4 millions answered, giving Alf Landon (57%) incumbent President Franklin D. Roosevelt (43%). latter nevertheless won landslide election 62% votes cast, 19% forecast error. Biased sampling differential non-response mostly responsible error: sampling frame built using ``phone number directories, drivers’ registrations, club memberships, etc.’’, skewed sample towards rich upper class white people susceptible vote GOP.contrast, Gallup correctly predicted outcome polling () 50K inhabitants. Read full story .considerations guide determining population interest study?","code":""},{"path":"introduction.html","id":"sampling","chapter":"1 Introduction","heading":"1.3.3 Sampling","text":"sampling costly, can collect limited information variable interest, drawing population sampling frame (phone books, population register, etc.) Good sampling frames can purchased sampling firms.general, randomization necessary order obtain representative sample4, one match characteristics population. Failing randomize leads introduction bias generally conclusions drawn study won’t generalizable.Even observational units selected random participate, may bias introduced due non-response. 1950s, conducting surveys relatively easier people listed telephone books; nowadays, sampling firms rely mix interactive voice response live callers, sampling frames mixing landlines, cellphones online panels together (heavy) weighting correct non-response. Sampling difficult problem engage cursorily, readers urged exercise scrutiny reading papers.Reflect choice platform used collect answers think influence composition sample returned affect non-response systematic way.examining problems related sampling, review main random sampling methods. simplest simple random sampling, whereby \\(n\\) units drawn completely random (uniformly) \\(N\\) elements sampling frame. second common scheme stratified sampling, whereby certain numbers units drawn uniformly strata, namely subgroups (e.g., gender). Finally, cluster sampling consists sampling subgroups.Example 1.5  (Illustration sampling schemes) Suppose wish look student satisfaction regarding material taught introductory statistics course offered multiple sections. population consists students enrolled course given semester list provides sampling frame. can define strata consist class group. simple random sample obtaining sampling randomly abstracting class groups, stratified sample drawing randomly number class group cluster sampling drawing students selected class groups. Cluster sampling mostly useful groups similar costs associated sampling multiple strata expensive.\nFigure 1.6: Illustration three sampling schemes nine groups: simple random sampling (left), stratified sampling (middle) cluster sampling (right). middle, grouping corresponds stratum (e.g., age bands) whereas right contains cluster (e.g., villages classrooms)\nStratified sampling typically superior care similar proportions sampled group useful reweighting: 1.6, true proportion sampled 1/3, simple random sampling range [0.22, 0.39] among strata, compared [0.32, 0.34] stratified sample.credibility study relies large part quality data collection. customary report descriptive statistics sample description population?instances sampling, non-random avoided whenever possible. include convenience samples, consisting observational units easy access include (e.g., friends, students university, passerby street). Much like anecdotal reports, observational units need representative whole population difficult understand relate latter.recent years, proliferation studies employing data obtained web experimentation plateforms Amazon’s Mechanical Turk (MTurk), point Journal Management commissioned review (Aguinis, Villamor, Ramani 2021). samples subject self-selection bias read skepticism. reserve tools paired samples (e.g., asking people perform multiple tasks presented random order) composition population relatively unimportant. make sure sample matches target population, can use statistical tests informal comparison compare repartition individuals composition obtained census.","code":""},{"path":"introduction.html","id":"examples-of-experimental-designs","chapter":"1 Introduction","heading":"1.4 Examples of experimental designs","text":"field experimental design long history, starting agricultural field trials.Example 1.6  (Agricultural field trials Rothamsted Research Station.) Rothamsted Research Station UK conducting experiments since 1843. Ronald . Fisher, worked 14 years Rothamsted 1919, developed much statistical theory underlying experimental design, inspired work . Yates (1964) provides recollection contribution field.\nFigure 1.7: 1958 plan Highfield Ley–Arable Experiment. Source: Rothamsted Research Station, reproduced CC 4.0 license.\nExperimental design revolves large part understanding best allocate resources, determine impact policies choosing effective “treatment” series option.Example 1.7  (Modern experiments /B testing) modern experiments happen online, tech companies running thousands experiments ongoing basis order discover improvement interfaces lead increased profits. Harvard Business Review article (Kohavi Thomke 2017) details small tweaks display advertisements Microsoft Bing search engine landing page lead whooping 12% increase revenues. randomized control trials, termed /B experiments, involve splitting incoming traffic separate groups; group see different views webpage differ ever slightly. experimenters compare traffic click revenues. large scale, even small effects can major financial consequences can learned despite large variability customer behaviour.also multiple examples randomized control experiments used policy making.Example 1.8  (Experiments wellness programs) Song Baicker (2019) conducted large randomized trial period 18 months study impact wellness programs US companies. industry, worth 8 billions USD, significantly increased following passage Affordable Care Act, aka Obamacare. findings vulgarized press release Jake Miller Harvard News & Research: show , seemingly impact physical activity well-, evidence changes absenteeism, job tenure job performance. Jones, Molitor, Reif (2019) reach similar conclusion.findings strikingly different previous observational studies, found increase participation sportive activities, increased job duration, reduced medical spendings.Example 1.9  (STAR) Tennessee’s Student Teacher Achievement Ratio (STAR) project (Achilles et al. 2008) another important example large scale experiment broad ramifications. study suggested smaller class sizes lead better outcomes pupils.7,000 students 79 schools randomly assigned one 3 interventions: small class (13 17 students per teacher), regular class (22 25 students per teacher), regular--aide class (22 25 students full-time teacher’s aide). Classroom teachers also randomly assigned classes teach. interventions initiated students entered school kindergarten continued third grade.Example 1.10  (RAND health care programs) large-scale multiyear experiment conducted RAND Corporation (Brook et al. 2006), participants paid share health care used fewer health services comparison group given free care. study concluded cost sharing reduced “inappropriate unnecessary” medical care (overutilization), also reduced “appropriate needed” medical care.HIE large-scale, randomized experiment conducted 1971 1982. study, RAND recruited 2,750 families encompassing 7,700 individuals, age 65. chosen six sites across United States provide regional urban/rural balance. Participants randomly assigned one five types health insurance plans created specifically experiment. four basic types fee--service plans: One type offered free care; three types involved varying levels cost sharing — 25 percent, 50 percent, 95 percent coinsurance (percentage medical charges consumer must pay). fifth type health insurance plan nonprofit, HMO-style group cooperative. assigned HMO received care free charge. poorer families plans involved cost sharing, amount cost sharing income-adjusted one three levels: 5, 10, 15 percent income. --pocket spending capped percentages income $1,000 annually (roughly $3,000 annually adjusted 1977 2005 levels), whichever lower.Families participated experiment 3–5 years. upper age limit adults time enrollment 61, participants become eligible Medicare experiment ended. assess participant service use, costs, quality care, RAND served families’ insurer processed claims. assess participant health, RAND administered surveys beginning end experiment also conducted comprehensive physical exams. Sixty percent participants randomly chosen receive exams beginning study, received physicals end. random use physicals beginning intended control possible health effects might stimulated physical exam alone, independent participation experiment.many greath examples dedicated section Chapter 10 Telling stories data Rohan Alexander (Alexander 2022). Section 1.4 Berger, Maurer, Celli (2018) also lists various applications experimental designs variety fields.","code":""},{"path":"introduction.html","id":"requirements-for-good-experiments","chapter":"1 Introduction","heading":"1.5 Requirements for good experiments","text":"Section 1.2 Cox (1958) describes various requirements necessary experiments useful. areabsence systematic errorprecisionrange validitysimplicityWe review turn.","code":""},{"path":"introduction.html","id":"absence-of-systematic-error","chapter":"1 Introduction","heading":"1.5.1 Absence of systematic error","text":"point requires careful planning listing potential confounding variables affect response.Example 1.11  Suppose wish consider differences student performance two instructors. first teaches morning classes, second teaches evening, impossible disentangle effect timing instructor performance. comparisons undertaken compelling prior evidence timing impact outcome interest.first point raised Cox thus weensure experimental units receiving one treatment differ systematic way receiving another treatment.point also motivates use double-blind procedures (experimenters participants unaware treatment allocation) use placebo control groups (avoid psychological effects, etc. associated receiving treatment lack thereof participants).Randomization core achieving goal, ensuring measurements independent one another also comes corollary.","code":""},{"path":"introduction.html","id":"variability","chapter":"1 Introduction","heading":"1.5.2 Variability","text":"second point listed Cox (1958) variability estimator. Much precision can captured signal--noise ratio, effect size divided standard error; terms defined rigourously latter, intuition ’s easier detect something signal large background noise low. latter function ofthe accuracy experimental work measurements apparatus intrinsic variability phenomenon study,number experimental observational units, .e., sample size andthe choice design statistical procedures.Point () typically influenced experimenter outside choosing response variable obtain reliable measurements. Point (c) related method analysis, oftentimes standard unless robustness considerations. Point (b) core planning, notably choosing number units use allocation treatment different (sub)-units.","code":""},{"path":"introduction.html","id":"generalizability","chapter":"1 Introduction","heading":"1.5.3 Generalizability","text":"studies done objective generalizing findings beyond particular units analyzed. range validity thus crucially depends choice population sample drawn particular sampling scheme. Non-random sampling severely limits extrapolation results general settings. leads Cox advocate havingnot just empirical knowledge treatment differences , also understanding reasons differences.Even believe factor effect, may wise introduce experiment check assumption: source variability, shouldn’t impact findings time provide robustness.look continuous treatment, probably safe draw conclusions within range doses administered. Comic 1.8 absurd, makes point.\nFigure 1.8: xkcd comic 605 (Extrapolating) Randall Munroe. Alt text: third trimester, thousands babies inside . Cartoon reprinted CC -NC 2.5 license.\nExample 1.12  (Generalizability) Replication studies done university often draw participants students enrolled institutions. findings thus necessarily robust extrapolated whole population characteristics strong (familiarity technology, acquaintance administrative system, political views, etc). samples often convenience samples.Example 1.13  (Spratt-Archer barley Ireland) Example 1.9 Cox (1958) mentions recollections “Student”5 Spratt-Archer barley, new variety barley performed well experiments whose culture Irish Department Agriculture encouraged. Fuelled district skepticism new variety, Department ran experiment comparing yield Spratt-Archer barley native race. findings surprised experimenters: native barley grew quickly resistant weeds, leading higher yields. concluded initial experiments misleading Spratt-Archer barley experimented well-farmed areas, exempt nuisance.","code":""},{"path":"introduction.html","id":"simplicity","chapter":"1 Introduction","heading":"1.5.4 Simplicity","text":"fourth requirement one simplicity design, almost invariably leads simplicity statistical analysis. Randomized control-trials often viewed golden rule determining efficacy policies treatments set assumptions make pretty minimalist due randomization. researchers management necessarily comfortable advanced statistical techniques also minimizes burden. Figure 1.9 shows hypothetical graph efficacy Moderna MRNA vaccine Covid: difference clearly visible suitable experimental setting, conclusions easily drawn.Randomization justifies use statistical tools use weak assumptions, units measurements independent one another. Drawing conclusions observational studies, contrast experimental designs requires making often unrealistic unverifiable assumptions choice techniques required handle lack randomness often beyond toolbox applied researchers.\nFigure 1.9: xkcd comic 2400 (Statistics) Randall Munroe. Alt text: reject null hypothesis based ‘hot damn, check chart’ test. Cartoon reprinted CC -NC 2.5 license.\nDefine following terms word: experimental unit, factor, treatmentWhat main benefit experimental studies observational studies?","code":""},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"2 Hypothesis testing","heading":"2 Hypothesis testing","text":"applied domains, empirical evidences drive advancement field data well designed experiments contribute built science. order draw conclusions favour theory, researchers turn (often unwillingly) statistics back claims. led prevalence use null hypothesis statistical testing (NHST) framework. One important aspect reproducibility crisis misuse \\(p\\)-values journal articles: falsification null hypothesis enough provide substantive findings theory.introductory statistics course typically present hypothesis tests without giving much thoughts underlying construction principles procedures, users often reductive view statistics catalogue pre-determined procedures. make culinary analogy, users focus learning recipes rather trying understand basics cookery. chapter focuses understanding key ideas related testing.Learning objectives:Understanding role uncertainty decision making.Understanding importance signal--noise ratio measure evidence.Knowing basic ingredients hypothesis testing capable correctly formulating identifying components paper.Correctly interpreting \\(p\\)-values confidence intervals parameter.","code":""},{"path":"hypothesis-testing.html","id":"hypothesis","chapter":"2 Hypothesis testing","heading":"2.1 Hypothesis","text":"first step design formulating research question. Generally, hypothesis specify potential differences population characteristics due intervention (treatment) researcher wants quantify. step researchers decide sample size, choice response variable metric measurement, write study plan, etc.important note research questions answered simple tools. Researchers wishing perform innovative methodological research contact experts consult statisticians collect data get information best proceed mind avoid risk making misleading false claims based incorrect analysis data collection.\nFigure 2.1: xkcd comic 2569 (Hypothesis generation) Randall Munroe. Alt text: Frazzled scientists requesting everyone please stop generating hypotheses little bit work backlog. Cartoon reprinted CC -NC 2.5 license.\n","code":""},{"path":"hypothesis-testing.html","id":"sampling-variability","chapter":"2 Hypothesis testing","heading":"2.2 Sampling variability","text":"Given data, researcher interested estimating particular characteristics population. can characterize set potential values measurements can take, together frequency, via distribution.hypothesis test focus one multiple characteristics. Suppose two groups, control treatment, whose population averages \\(\\mu_C\\) \\(\\mu_T\\) wish compare.Example 2.1  (/B testing) Consider two webpage design: one current version (status quo) implementation contains clickable banner location eyetracker suggest viewers eyes spend time attention. number clicks headlines generate longer viewing, thus higher revenues advertisement. characteristic interest average click conversation rate webpage design.fairly simple redirect traffic random fraction gets assigned new design study. suitable period time, data can analyzed see new webpage generates clicks.People commonly look difference average, say \\(\\delta=\\mu_T - \\mu_C\\) measure effectiveness treatment.6 properly randomized observations subgroup nothing else changes, measures impact treatment. sample hand whole population, don’t know sure values \\(\\mu_C\\) \\(\\mu_T\\). quantities exist, unknown us best can estimate using random samples drawn population.call numerical summaries data statistics. important distinguish procedures/formulas numerical values. estimator rule formula used calculate estimate parameter quantity interest based observed data (like recipe cake). observed data can actually compute sample mean, , estimate — actual value (cake), single realization random. words,estimand conceptual target, like population characteristic interest.estimator procedure formula telling us transform sample data numerical summary proxy target.estimate number, numerical value obtained apply formula observed data.\nFigure 2.2: Estimand (left), estimator (middle) estimate (right) illustrated cakes based original idea Simon Grund. Cake photos shared CC -NC 2.0 license.\nexample, may use estimand population average \\(Y_1, \\ldots\\), say \\(\\mu\\). estimator sample mean sample, .e., sum elements divided sample size, \\(\\overline{Y}=(Y_1 + \\cdots + Y_n)/n\\). estimate numerical value, say 4.3.inputs estimator random, output also random change one sample next: even repeat recipe, won’t get exact result every time.\nFigure 1.8: xkcd comic 2581 (Health Stats) Randall Munroe. Alt text: live forever hearts, pushing little extra blood toward left hands now give squeeze. Cartoon reprinted CC -NC 2.5 license.\nillustrate point, Figure 2.3 shows five simple random samples size \\(n=10\\) drawn hypothetical population mean \\(\\mu\\) standard deviation \\(\\sigma\\), along sample mean \\(\\overline{y}\\). Thus, sampling variability implies sample means subgroups always differ even share characteristics. can view sampling variability noise: goal extract signal (typically differences means) accounting spurious results due background noise.\nFigure 2.3: Five samples size \\(n=10\\) drawn common population mean \\(\\mu\\) (horizontal line). colored segments show sample means sample.\ncan clearly see Figure 2.3 , even sample drawn population, sample mean varies one sample next result sampling variability. astute eye might even notice sample means less dispersed around full black horizontal line representing overall average \\(\\mu\\) individual measurements. fundamental principle statistics: information accumulates get data sample mean \\(\\overline{Y}\\) based multiple observations.Values sample mean don’t tell whole picture studying differences mean (groups, relative postulated reference value) enough draw conclusions. settings, guarantee sample mean equal ’s true value changes one sample next: guarantee average equal population average. Depending choice measurement variability population, may considerable differences one observation next means observed difference fluke.get idea certain something , consider variability observation \\(Y_i\\). variance typically denoted \\(\\sigma^2\\) standard deviation, \\(\\sigma\\), expressed unit measurements.sample variance \\(S_n\\) estimator standard deviation \\(\\sigma\\), \n\\[\\begin{align*}\nS^2_n &= \\frac{1}{n-1} \\sum_{=1}^n (Y_i-\\overline{Y})^2\n\\end{align*}\\]\nsum squared difference observations sample average, scaled factor proportional sample size.standard deviation statistic termed standard error; confused standard deviation \\(\\sigma\\) population sample observations \\(Y_1, \\ldots, Y_n\\) drawn. standard deviation standard error expressed units measurements, easier interpret variance. Since standard error function sample size, however good practice report estimated standard deviation reports.\nFigure 2.4: Histograms 10 random samples size \\(n=20\\) discrete uniform distribution.\nEven drawn population, 10 samples Figure 2.4 look quite different. thing play sample variability: since \\(n=20\\) observations total, average 10% observations 10 bins, bins empty others counts expected. fluctuation due randomness, chance.can thus detect whether see compatible model think generated data? key collect observations: bar height sample proportion, average 0/1 values ones indicating observation bin zero otherwise.Consider now happens increase sample size: top panel Figure 2.5 shows uniform samples increasing samples size. histogram looks like true underlying distribution (flat, bin equal frequency) sample size increases. sample distribution points nearly indistinguishable theoretical one (straight line) \\(n=10 000\\).7 bottom panel, hand, isn’t uniform distribution larger samples come closer population distribution. couldn’t spotted difference first two plots, since sampling variability important; , lack data bins attributed chance, comparable graph data truly uniform. line practical applications, limited sample size restricts capacity disentangle real differences sampling variability. must embrace uncertainty: next section, outline hypothesis testing helps us disentangle signal noise.\nFigure 2.5: Histograms data uniform distribution (top) non-uniform (bottom) increasing sample sizes 10, 100, 1000 10 000 (left right).\n","code":""},{"path":"hypothesis-testing.html","id":"tests","chapter":"2 Hypothesis testing","heading":"2.3 Hypothesis testing","text":"hypothesis test binary decision rule (yes/) used evaluate statistical evidence provided sample make decision regarding underlying population. main steps involved :define model parametersformulate alternative null hypothesischoose calculate test statisticobtain null distribution describing behaviour test statistic \\(\\mathscr{H}_0\\)calculate p-valueconclude (reject fail reject \\(\\mathscr{H}_0\\)) context problem.good analogy hypothesis tests trial murder appointed juror.judge lets choose two mutually exclusive outcome, guilty guilty, based evidence presented court.presumption innocence applies evidences judged optic: evidence remotely plausible person innocent? burden proof lies prosecution avoid much possible judicial errors. null hypothesis \\(\\mathscr{H}_0\\) guilty, whereas alternative \\(\\mathscr{H}_a\\) guilty. reasonable doubt, verdict trial guilty.test statistic (choice test) represents summary proof. overwhelming evidence, higher chance accused declared guilty. prosecutor chooses proof best outline : choice evidence (statistic) ultimately maximize evidence, parallels power test.null distribution benchmark judge evidence (jurisprudence). Given proof, odds assuming person innocent? Since possibly different every test, common report instead p-value, gives level evidence uniform scale easily interpreted.final step verdict, binary decision outcomes: guilty guilty. hypothesis test performed level \\(\\alpha\\), one reject (guilty) p-value less \\(\\alpha\\). Even declare person guilty, doesn’t mean defendant innocent vice-versa.","code":""},{"path":"hypothesis-testing.html","id":"hypothesis-1","chapter":"2 Hypothesis testing","heading":"2.3.1 Hypothesis","text":"statistical tests two hypotheses: null hypothesis (\\(\\mathscr{H}_0\\)) alternative hypothesis (\\(\\mathscr{H}_a\\)). Usually, null hypothesis (‘status quo’) single numerical value. alternative ’re really interested testing. 2.3, consider whether five groups mean \\(\\mathscr{H}_0: \\mu_1 = \\mu_2 = \\cdots = \\mu_5\\) alternative least two different. two outcomes mutually exclusive cover possible scenarios. statistical hypothesis test allows us decide whether data provides enough evidence reject \\(\\mathscr{H}_0\\) favor \\(\\mathscr{H}_a\\), subject pre-specified risk error: know differences just due sampling variability Figure 2.3 data simulated, practice need assess evidence using numerical summary.Example 2.3  (/B testing (continued)) follow-/B test experiment. Given \\(\\mu_1\\) population average click conversation rate current webpage \\(\\mu_2\\) redesign, interested one-sided hypothesis \\(\\mathscr{H}_0: \\mu_2 \\geq \\mu_1\\). logical: given costs associated changes interface resulting disruption, want implement changes improve webpage design allow us generate revenues.One-sided hypothesis directional: care specific direction, \\(\\mathscr{H}_a: \\mu_2 \\leq \\mu_1\\). Indeed, experiment suggests conversion rate worst new webpage design, won’t go forward.Since neither population values known us, can work instead \\(\\mathscr{H}_0: \\mu_2-\\mu_1 \\geq 0\\). can use estimator difference \\(\\mu_2-\\mu_1\\) difference sample average subgroup.null hypothesis interval, suffices consider beneficial scenario, \\(\\mu_2-\\mu_1=0\\). Indeed, can disprove difference see increase click rate updated version, extreme cases automatically discarded favour alternative new design better.","code":""},{"path":"hypothesis-testing.html","id":"test-statistic","chapter":"2 Hypothesis testing","heading":"2.3.2 Test statistic","text":"test statistic \\(T\\) function data takes data input outputs summary information contained sample characteristic interest, say population mean. order assess whether numerical value \\(T\\) unusual, need know potential values taken \\(T\\) relative probability \\(\\mathscr{H}_0\\) true. need know values expect , e.g., difference averages different groups: requires benchmark.Many statistics consider form8\n\\[\\begin{align*}\nT = \\frac{\\text{estimated effect}- \\text{postulated effect}}{\\text{estimated effect variability}} = \\frac{\\widehat{\\theta} - \\theta_0}{\\mathrm{se}(\\widehat{\\theta})}\n\\end{align*}\\]\n\\(\\widehat{\\theta}\\) estimator \\(\\theta\\), \\(\\theta_0\\) postulated value parameter \\(\\mathrm{se}(\\widehat{\\theta})\\) standard error test statistic \\(\\widehat{\\theta}\\). quantity designed , difference, \\(T\\) approximately mean zero variance one. standardization makes comparison easier; fact, form test statistic chosen doesn’t depend units used.example, interested mean differences treatment group control group, denoted \\(\\mu_T\\) \\(\\mu_C\\), \\(\\theta = \\mu_T-\\mu_C\\) \\(\\mathscr{H}_0: \\mu_T = \\mu_C\\) corresponds \\(\\mathscr{H}_0: \\theta = 0\\) difference. two-sample \\(t\\)-test numerator \\(\\widehat{\\theta} = \\overline{Y}_T - \\overline{Y}_C\\), \\(\\overline{Y}_T\\) sample average treatment group \\(\\overline{Y}_C\\) control group.numerator thus consist difference sample means denominator standard error quantity, calculated using software.9","code":""},{"path":"hypothesis-testing.html","id":"null-distribution-and-p-value","chapter":"2 Hypothesis testing","heading":"2.3.3 Null distribution and p-value","text":"p-value allows us decide whether observed value test statistic \\(T\\) plausible \\(\\mathscr{H}_0\\). Specifically, p-value probability test statistic equal extreme estimate computed data, assuming \\(\\mathscr{H}_0\\) true. Suppose based random sample \\(Y_1, \\ldots, Y_n\\) obtain statistic whose value \\(T=t\\). two-sided test \\(\\mathscr{H}_0:\\theta=\\theta_0\\) vs. \\(\\mathscr{H}_a:\\theta \\neq \\theta_0\\), p-value \\(\\mathsf{Pr}_0(|T| \\geq |t|)\\).10How determine null distribution given true data generating mechanism unknown us? ask statistician! simple cases, might possible enumerate possible outcomes thus quantity degree outlyingness observed statistic. general settings, can resort simulations probability theory: central limit theorem says sample mean behaves like normal random variable mean \\(\\mu\\) standard deviation \\(\\sigma/\\sqrt{n}\\) \\(n\\) large enough. central limit theorem broader applications since statistics can viewed form average transformation thereof, fact used derive benchmarks commonly used tests. software use approximations proxy default: normal, Student’s \\(t\\), \\(\\chi^2\\) \\(F\\) distributions reference distributions arise often.\nFigure 2.6: Density p-values null hypothesis (left) alternative signal--noise ratio 0.5 (right). probability rejection obtained calculating area density curve zero \\(\\alpha=0.1\\), 0.1. null, model calibrated distribution p-values uniform (.e., flat rectangle height 1), meaning values unit interval equally likely. alternative (right), small p-values likely observed.\ngenerally three ways obtaining null distributions assessing degree evidence null hypothesisexact calculationslarge sample theory (aka ‘asymptotics’ statistical lingo)simulationWhile desirable, first method applicable simple cases (counting probability getting two six throw two fair die). second method commonly used due generality ease use (particularly older times computing power scarce), fares poorly small sample sizes (‘small’ context test-dependent). last approach can used approximate null distribution many scenarios, adds layer randomness extra computations costs sometimes worth .","code":""},{"path":"hypothesis-testing.html","id":"conclusion","chapter":"2 Hypothesis testing","heading":"2.3.4 Conclusion","text":"p-value allows us make decision null hypothesis. \\(\\mathscr{H}_0\\) true, p-value follows uniform distribution, shown Figure 2.6. Thus, p-value small, means observing outcome extreme \\(T=t\\) unlikely, ’re inclined think \\(\\mathscr{H}_0\\) true. ’s always underlying risk ’re making mistake make decision. statistic, two type errors:type error: reject null hypothesis \\(\\mathscr{H}_0\\) null true,type II error: fail reject null hypothesis \\(\\mathscr{H}_0\\) alternative true.two hypothesis judged equally: seek avoid error type (judicial errors, corresponding condamning innocent). prevent , fix level test, \\(\\alpha\\), captures tolerance risk commiting type error: higher level test \\(\\alpha\\), often reject null hypothesis latter true. value \\(\\alpha \\(0, 1)\\) probability rejecting \\(\\mathscr{H}_0\\) \\(\\mathscr{H}_0\\) fact true,\n\\[\\begin{align*}\n\\alpha = \\mathsf{Pr}_0\\left(\\text{ reject } \\mathscr{H}_0\\right).\n\\end{align*}\\]\nlevel \\(\\alpha\\) fixed beforehand, typically \\(1\\)%, \\(5\\)% \\(10\\)%. Keep mind probability type error \\(\\alpha\\) null model \\(\\mathscr{H}_0\\) correct (sic) correspond data generating mechanism.focus type error best understood thinking costs moving away status quo: new website design branding costly implement, want make sure enough evidence proposal better alternative lead increased traffic revenues.make decision, compare p-value \\(P\\) level test \\(\\alpha\\):\\(P < \\alpha\\), reject \\(\\mathscr{H}_0\\);\\(P \\geq \\alpha\\), fail reject \\(\\mathscr{H}_0\\).mix level test (probability fixed beforehand researcher) p-value. test level 5%, probability type error (condemning innocent mistake) definition \\(\\alpha\\) depend p-value. latter conditional probability observing extreme statistic given null distribution \\(\\mathscr{H}_0\\) true.American Statistical Association (ASA) published \nlist principles guiding (mis)interpretation p-values, reproduced :P-values measure probability studied hypothesis true.Scientific conclusions business policy decisions based whether p-value passes specific threshold.P-values related analyses reported selectively.p-value, statistical significance, measure size effect importance result.Example 2.4  (Gender inequality permutation tests) consider data Rosen Jerdee (1974), look sex role stereotypes impacts promotion opportunities women candidates. experiment took place 1972 experimental units, consisted 95 male bank supervisors, submitted various memorandums asked provide ratings decisions based information provided.interested Experiment 1 related promotion employees: managers requested decide whether promote employee become branch manager based recommendations ratings potential customer employee relations.authors intervention focused description nature (complexity) manager’s job (either simple complex) sex candidate (male female): files otherwise similar.consider simplicity sex factor aggregate job \\(n=93\\) replies. Table 2.1 shows counts possibility.\nTable 2.1: Promotion recommandation branch manager based sex applicant.\nnull hypothesis interest sex impact, probability promotion men women. Let \\(p_{\\text{m}}\\) \\(p_{\\text{w}}\\) denote respective probabilities; can thus write mathematically null hypothesis \\(\\mathscr{H}_0: p_{\\text{m}} = p_{\\text{w}}\\) alternative \\(\\mathscr{H}_a: p_{\\text{m}} \\neq p_{\\text{w}}\\).test statistic typically employed two two contingency tables chi-square test11, compares overall proportions promoted subgroup. sample proportion male 32/42 = ~76%, compared 19/49 ~49% female. seems difference 16% large, spurious: standard error sample proportions roughly 3.2% male 3.4% female.discrimination based sex, expect proportion people promoted overall; 51/93 =0.55 pooled sample. simply test mean difference, rely instead Pearson contingency \\(X^2_p\\) (aka chi-square) test, compares expected counts (based equal promotion rates) observed counts, suitably standardized. discrepancy large expected observed, casts doubt validity null hypothesis.\nTable 2.2: Chi-square test experiment 1 Rosen Jerdee (1974)\ncounts cell large, null distribution chi-square test well approximated \\(\\chi^2\\) distribution. output test includes value statistic, degrees freedom \\(\\chi^2\\) approximation p-value, gives probability random draw \\(\\chi^2_1\\) distribution larger observed test statistic assuming null hypothesis true. p-value small, 0.001, means result quite unlikely happen chance sex-discrimination.alternative test statistics used, among odds ratio. odds event ratio number success failure: example, number promoted held files. odds promotion male 32/12, whereas female 19/30. odds ratio male versus female thus \\(\\mathsf{}=\\) (32/12) / (19/30)= 4.21. null hypothesis, \\(\\mathscr{H}_0: \\mathsf{}=\\) 1 (probability promoted) (?)Fisher’s test assumes row sum totals fixed (, number promoted/withheld files male/female fixed design stage) uses derive exact probability observing particular configuration proportion success . numerical value Fisher’s exact test, obtained running fisher.test(dat_exper1), different obtained earlier, null distribution12. contrary, p-value close one reported \\(\\chi^2\\) test Table 2.2.\nTable 2.3: Fisher’s exact test experiment 1 Rosen Jerdee (1974)\nYet another alternative obtain benchmark assess outlyingness observed odds ratio use simulations. Consider database containing raw data 93 rows, one manager, indicator action sex hypothetical employee presented task.\nTable 2.4: First five rows database long format experiment 1 Rosen Jerdee.\nnull hypothesis, sex incidence action manager. means get idea “-” world shuffling sex labels repeatedly. Thus, obtain benchmark repeating following steps multiple times:permute labels sex,recreate contingency table aggregating counts,calculate odds ratio simulated table.\nFigure 2.7: Histogram simulated null distribution odds ratio statistic obtained using permutation test; vertical red line indicates sample odds ratio.\nhistogram Figure 2.7 shows distribution odds ratio based 10 000 permutations. Reassuringly, get roughly approximate p-value, 0.002.13The article concluded (light experiments)Results confirmed hypothesis male administrators tend discriminate female employees personnel decisions involving promotion, development, supervision.first experiment, managers also asked rank applications potential employee customer relations using Likert scale six items ranging (1) extremely unfavorable (6) extremely favorable. However, averages reported Table 1 along (Rosen Jerdee 1974)Mean rating male candidate 4.73 compared mean rating 4.25 female candidate (\\(F=4.76\\), \\(\\text{df} = 1/80\\), \\(p < .05\\))degrees freedom (80) much compared number observations, implying non-response isn’t discussed.Partial selective reporting statistical procedures hinders reproducibility. general, presentation explicitly state name test statistic employed, sample size, mean variance estimates, null distribution used assess significance parameters, . Without , left speculate.","code":"\n## Create a 2x2 matrix (contingency table) with the counts\ndat_exper1 <- matrix(c(32L, 12L, 19L, 30L), ncol = 2, nrow = 2, byrow = TRUE)\n# Calculate the statistic on data\nobs_stat <- chisq.test(x = dat_exper1, correct = FALSE)\n# Tidy output to get a tibble\ntest_res <- broom::tidy(obs_stat)"},{"path":"hypothesis-testing.html","id":"confidence-intervals","chapter":"2 Hypothesis testing","heading":"2.4 Confidence intervals","text":"confidence interval alternative way present conclusions hypothesis test performed significance level \\(\\alpha\\) giving range values null isn’t rejected chosen level. often combined point estimator \\(\\hat{\\theta}\\) give indication variability estimation procedure. Wald-based \\((1-\\alpha)\\) confidence intervals parameter \\(\\theta\\) form\n\\[\\begin{align*}\n\\widehat{\\theta} \\pm \\mathfrak{q}_{\\alpha/2} \\; \\mathrm{se}(\\widehat{\\theta})\n\\end{align*}\\]\n\\(\\mathfrak{q}_{\\alpha/2}\\) \\(1-\\alpha/2\\) quantile null distribution Wald statistic\n\\[\\begin{align*}\nT =\\frac{\\widehat{\\theta}-\\theta}{\\mathrm{se}(\\widehat{\\theta})},\n\\end{align*}\\]\n\\(\\theta\\) represents postulated value fixed, unknown value parameter. bounds confidence intervals random variables, since estimators parameter standard error, \\(\\widehat{\\theta}\\) \\(\\mathrm{se}(\\widehat{\\theta})\\), random variables: values vary one sample next.interval calculated, \\(1-\\alpha\\) probability \\(\\theta\\) contained random interval \\((\\widehat{\\theta} - \\mathfrak{q}_{\\alpha/2} \\; \\mathrm{se}(\\widehat{\\theta}), \\widehat{\\theta} + \\mathfrak{q}_{\\alpha/2} \\; \\mathrm{se}(\\widehat{\\theta}))\\), \\(\\widehat{\\theta}\\) denotes estimator. obtain sample calculate confidence interval, notion probability: true value parameter \\(\\theta\\) either confidence interval . can interpret confidence interval’s follows: repeat experiment multiple times, calculate \\(1-\\alpha\\) confidence interval time, roughly \\(1-\\alpha\\) calculated confidence intervals contain true value \\(\\theta\\) repeated samples (way, flip coin, roughly 50-50 chance getting heads tails, outcome either). confidence procedure use calculate confidence intervals actual values obtain sample.\nFigure 2.8: 95% confidence intervals mean standard normal population 100 random samples. average, 5% intervals fail include true mean value zero (red).\ninterested binary decision rule reject/fail reject \\(\\mathscr{H}_0\\), confidence interval equivalent p-value since leads conclusion. Whereas \\(1-\\alpha\\) confidence interval gives set values test statistic doesn’t provide enough evidence reject \\(\\mathscr{H}_0\\) level \\(\\alpha\\), p-value gives probability null obtaining result extreme postulated value precise particular value. p-value smaller \\(\\alpha\\), null value \\(\\theta\\) outside confidence interval vice-versa.","code":""},{"path":"hypothesis-testing.html","id":"power","chapter":"2 Hypothesis testing","heading":"2.5 Power","text":"two sides hypothesis test: either want show unreasonable assume null hypothesis, else want show beyond reasonable doubt difference effect significative: example, one wish demonstrate new website design (alternative hypothesis) leads significant increase sales relative status quo. ability detect improvements make discoveries depends power test: larger power, greater ability reject \\(\\mathscr{H}_0\\) latter false.Failing reject \\(\\mathscr{H}_0\\) \\(\\mathscr{H}_a\\) true (guilty verdict criminal) corresponds definition type II error, say. power test probability correctly rejecting null hypothesis \\(\\mathscr{H}_0\\) \\(\\mathscr{H}_0\\) false, .e.,\n\\[\\begin{align*}\n\\mathsf{Pr}_a(\\text{reject} \\mathscr{H}_0)\n\\end{align*}\\]\nDepending alternative models, less easy detect null hypothesis false reject favor alternative.\nPower thus measure ability detect real effects.\nFigure 2.9: Comparison null distribution (full curve) specific alternative t-test (dashed line). power corresponds area curve density alternative distribution rejection area (white).\n\nFigure 2.10: Increase power due increase mean difference null alternative hypothesis. Power area rejection region (white) alternative distribution (dashed): latter shifted right relative null distribution (full line).\n\nFigure 2.11: Increase power due increase sample size decrease standard deviation population: null distribution (full line) concentrated. Power given area (white) curve alternative distribution (dashed). general, null distribution changes sample size.\nwant choose experimental design test statistic leads high power, power close possible one. Minimally, power test \\(\\alpha\\) reject null hypothesis \\(\\alpha\\) fraction time even \\(\\mathscr{H}_0\\) true. Power depends many criteria, notablythe effect size: bigger difference postulated value \\(\\theta_0\\) \\(\\mathscr{H}_0\\) observed behaviour, easier departures \\(\\theta_0\\).\n(Figure 2.11); ’s easier spot elephant room mouse.variability: less noisy data, easier detect differences curves (big differences easier spot, Figure 2.10 shows);sample size: observation, higher ability detect significative differences amount evidence increases gather observations.14 experimental designs, power also depends many observations allocated group.15the choice test statistic: plethora possible statistics choose summary evidence null hypothesis. clearly inferior, less powerful choice may preferable. example, rank-based statistics discard information observed values response, focusing instead relative ranking. resulting tests typically less powerful, less sensible model assumption, model misspecification outliers.Changing value \\(\\alpha\\) impact power, since larger values \\(\\alpha\\) move cutoff towards bulk distribution. entails higher percentage rejection also alternative false. However, value \\(\\alpha\\) fixed beforehand control type error (avoid judicial mistakes). power corresponds red shaded area right panel Figure 2.12, become larger moved cutoff value lower, corresponding larger \\(\\alpha\\).\nFigure 2.12: Densities null (left) alternative (right) distributions one-way analysis variance: group means different, curve gets shifted right. shaded blue area type error (null hypothesis) type II error (alternative hypothesis); power area red shaded region.\nExample 2.5  (Surprise Reaching ) (Liu:2022?) studies social interactions impact surprise people reaching contact unexpected. Experiment 1 focuses questionnaires experimental condition perceived appreciation reaching someone (vs reached ). study used questionnaire administered 200 American adults recruited Prolific Academic platform. response index consists average four questions measured Likert scale ranging 1 7, higher values indicating higher appreciation.can begin inspecting summary statistics sociodemographic variables (gender age) assess whether sample representative general population whole. proportion (including non-binary people) much higher census reports, population skews much younger.Since two groups, initiator responder, dealing pairwise comparison. logical test one use t-test, variant thereof. show perform compare results obtained using different test statistics.","code":"#> # A tibble: 3 × 4\n#>   gender   min   max  mean\n#>   <fct>  <dbl> <dbl> <dbl>\n#> 1 Male      18    78  32.0\n#> 2 Female    19    68  36.5\n#> 3 Other     24    30  27.7\n#> # A tibble: 2 × 4\n#>   role       mean    sd     n\n#>   <fct>     <dbl> <dbl> <int>\n#> 1 initiator  5.50  1.28   103\n#> 2 responder  5.87  1.27    97\n#> # A tibble: 2 × 6\n#>   term         df  sumsq meansq statistic p.value\n#>   <chr>     <dbl>  <dbl>  <dbl>     <dbl>   <dbl>\n#> 1 role          1   6.87   6.87      4.21  0.0414\n#> 2 Residuals   198 323.     1.63     NA    NA"},{"path":"hypothesis-testing.html","id":"conclusion-1","chapter":"2 Hypothesis testing","heading":"2.6 Conclusion","text":"Richard McElreath first chapter book (McElreath 2020) draws parallel statistical tests golems (.e., robots): neitherdiscern context inapropriate answers. just knows procedure […] just ’s told.responsibility therefore lies user correctly use statistical procedures aware limitations","code":""},{"path":"CRT.html","id":"CRT","chapter":"3 Completely randomized designs","heading":"3 Completely randomized designs","text":"chapter focuses experiments potentially multiple factors interest manipulated experimenter study impact. allocation observational units treatment combination completely random, resulting experiment completely randomized design.time, interest comparing average response treatment combination: underlies analysis variance model.objective present basic concepts surrounding hypothesis test, model validation, multiple testing, interplay power, effect size sample size, etc. easiest possible model build intuition concepts. readily generalized complicated linear models.one-way analysis variance describes simple experimental setup one can consider: completely randomized experiments one factor, solely interested effect single treatment variable multiple levels.focus comparisons average single outcome variable \\(K\\) different treatments levels, defining sub-population differing treatment received.","code":""},{"path":"CRT.html","id":"one-way-analysis-of-variance","chapter":"3 Completely randomized designs","heading":"3.1 One-way analysis of variance","text":"one-way analysis variance compares sample averages treatment group \\(T_1, \\ldots, T_K\\) try determine population averages . Since \\(K\\) groups, \\(K\\) averages (one per group) estimate.Let \\(\\mu_1, \\ldots, \\mu_K\\) denote theoretical (unknown) mean (aka expectation) \\(K\\) sub-populations defined different treatments. Lack difference treatments equivalent equality means, translates hypotheses\n\\[\\begin{align*}\n\\mathscr{H}_0: & \\mu_1 = \\cdots = \\mu_K \\\\\n\\mathscr{H}_a: & \\text{least two treatments different averages, }\n\\end{align*}\\]\nnull hypothesis , usual, single numerical value, \\(\\mu\\). alternative consists potential scenarios expectations equal. Going \\(K\\) averages one requires imposing \\(K-1\\) restrictions (number equality signs), value global mean \\(\\mu\\) left unspecified.","code":""},{"path":"CRT.html","id":"parametrizations-and-contrasts","chapter":"3 Completely randomized designs","heading":"3.1.1 Parametrizations and contrasts","text":"natural parametrization terms group averages: (theoretical unknown) average treatment \\(T_j\\) \\(\\mu_j\\), obtain \\(K\\) parameters \\(\\mu_1, \\ldots, \\mu_K\\) whose estimates sample averages \\(\\widehat{\\mu}_1, \\ldots, \\widehat{\\mu}_K\\). One slight complication arising values population average unknown, formulation ill-suited hypothesis testing none \\(\\mu_i\\) values known practice need make comparisons terms known numerical value.common parametrization terms constrasts (mean differences) relative reference group (say \\(T_1\\)). theoretical average group written \\(\\mu_1 + a_i\\) treatment \\(T_i\\), \\(a_1=0\\) \\(T_1\\) \\(a_i = \\mu_i-\\mu_1\\) otherwise. parameters \\(\\mu_1, a_2, \\ldots, a_K\\).equivalent formulation writes treatment group average subpopulation \\(j\\) \\(\\mu_j = \\mu + \\delta_j\\), \\(\\delta_j\\) difference treatment average \\(\\mu_j\\) global average groups. Imposing constraint \\(\\delta_1 + \\cdots + \\delta_K=0\\) ensures average effects equals \\(\\mu\\). Thus, know \\(K-1\\) \\(\\{\\delta_1, \\ldots, \\delta_K\\}\\), automatically can deduce last one.Example 3.1  (Impact encouragement teaching) R, lm function fits linear model based formula form response ~ explanatory. explanatory categorical (.e., factor), parameters model intercept, sample average baseline group parameters simply contrasts, .e., \\(a_i\\)’s.sum--zero parametrization obtained contrasts = list(... = contr.sum), ellipsis replaced name categorical variable; easier alternative aov, enforces parametrization default. sum--zero parametrization, intercept average treatment average, \\((\\widehat{\\mu}_1 + \\cdots + \\widehat{\\mu}_5)/5\\); need coincide (overall) mean response \\(\\widehat{\\mu} = \\overline{y}\\) unless sample number observations group .16 coefficients sum--zero parametrization differences intercept group means.show function call fit one-way ANOVA different parametrizations along sample average arithmetic group (two controls taught separately groups praised, reproved ignored third class). Note omitted category changes depending parametrization.\nTable 3.1: Coefficients analysis variance model arithmetic scores using different parametrizations.\ncan still assess hypothesis comparing sample means group, noisy estimates expectation: inherent variability limit ability detect differences mean signal--noise ratio small.","code":"\nmod_contrast <- lm(score ~ group, \n                   data = arithmetic)\nmod_sum2zero <- lm(score ~ group, \n                   data = arithmetic,\n                   contrasts = list(group = contr.sum))"},{"path":"CRT.html","id":"sum-of-squares-decomposition","chapter":"3 Completely randomized designs","heading":"3.1.2 Sum of squares decomposition","text":"following section can safely skipped first reading: attempts shed light \\(F\\)-test statistic works summary evidence: isn’t straightforward way appears.usual notation sum squares decomposition follows: suppose \\(y_{ik}\\) represents \\(\\)th person \\(k\\)th treatment group (\\(k=1, \\ldots, K\\)) sample size \\(n\\) can split groups \\(n_1, \\ldots, n_K\\); case balanced sample, \\(n_1=\\cdots=n_K = n/K\\). denote \\(\\widehat{\\mu}_k\\) sample average group \\(k\\) \\(\\widehat{\\mu}\\) overall average \\((y_{11} + \\cdots + y_{n_KK})/n = \\sum_k \\sum_i y_{ik}\\), \\(\\sum_i\\) denotes sum individuals group.\nnull model, groups mean, natural estimator sample average \\(\\widehat{\\mu}\\) likewise group averages \\(\\widehat{\\mu}_1, \\ldots, \\widehat{\\mu}_K\\) correct estimators group (potentially) different mean. complex, parameters, always fit better possibility accommodate differences observed group, even spurious.\nsum squares measures (squared) distance observation fitted values, terminology total, within sum squares linked decomposition\n\\[\\begin{align*}\n\\underset{\\text{total sum squares} }{\\sum_{}\\sum_{k} (y_{ik} - \\widehat{\\mu})^2} &= \\underset{\\text{within sum squares} }{\\sum_i \\sum_k (y_{ik} - \\widehat{\\mu}_k)^2} +  \\underset{\\text{sum squares} }{\\sum_k n_i (\\widehat{\\mu}_k - \\widehat{\\mu})^2}.\n\\end{align*}\\]\nterm left measure variability null model \\((\\mu_1 = \\cdots = \\mu_K)\\) observations predicted overall average \\(\\widehat{\\mu}\\). within sum squares measures distance observations group mean, describes alternative model group (potentially) different average, variability.can measure much worst alternative model (different average per group) relative null calculating sum square. quantity varies sample size (observations, larger ) must standardize usual quantity suitable benchmark.\\(F\\)-statistic \n\\[\\begin{align}\nF &= \\frac{\\text{-group variability}}{\\text{within-group variability}} \\\\&= \\frac{\\text{sum squares}/(K-1)}{\\text{within sum squares}/(n-K)}\n\\tag{3.1}\n\\end{align}\\]Heuristically, mean difference (null hypothesis), numerator estimator population variance, denominator (3.1). many observations (relatively fewer groups), ratio eq.(3.1) approximately one average , large enough sample, null distribution F-statistic approximately F-distribution, whose shape governed two parameters named degrees freedom appear eq.(3.1) scaling factors ensure proper standardization. first number restrictions imposed null hypothesis (\\(K-1\\), number groups minus one one-way analysis variance), second number observations minus number parameters estimates mean (\\(n-K\\), \\(n\\) overall sample size \\(K\\) number groups).17Figure 3.1 shows difference distances can encompass information null wrong. sum squares obtained computing squared length vectors adding . left panel shows strong signal--noise ratio, , average, black segments much longer colored ones. indicates model obtained letting group mean much better . picture right panel clear: average, colored arrows shorter, difference length much smaller relative colored arrows.\nFigure 3.1: Observations drawn three groups model strong (left) weak (right) signal--noise ratio, along sample mean (colored horizontal segments) overall average (horizontal line). Arrows indicate magnitude difference observation (group/average) mean.\nreliable \\(F\\)-statistic approximation? can assess simulating null model, repeatedly drawing samples similar characteristics (mean overall variance) computing test statistic replicate. However, one sample hand little numerical exercise wouldn’t work practice.distributions null alternative except location shift, instead resort permutation-based approach generate alternative samples simply shuffling labels. see Figure 3.2 histogram \\(F\\)-statistic values obtained 10 000 permutations closely matches large-sample \\(F\\)-distribution average 20 observations per group (right). However, smaller samples (left), theoretical null underdispersed relative permutation based distribution, latter viewed accurate setting.\nFigure 3.2: One-way analysis variance sample size 20 (left) 100 (right), split five groups. histogram shows computed test values based 10 000 permutations, compared density large-sample F-distribution.\n","code":""},{"path":"CRT.html","id":"graphical-representation","chapter":"3 Completely randomized designs","heading":"3.2 Graphical representation","text":"represent data publication? purpose visualization provide intuition extends beyond reported descriptive statistics check model assumptions. time, interested averages dispersion, plotting raw data can insightful. also important keep mind summary statistics estimators population quantities perhaps unreliable (much variable) small samples meaningful quantities. Since mean estimates likely reported text, graphics used convey additional information data. samples extremely large, graphics typically used present salient features distributions.\nFigure 3.3: Two graphical representations arithmetic data: dynamite plot (left) showing sample average one standard error , dot plot sample mean (right).\none-way analysis variance, outcome continuous numerical variable, whereas treatment explanatory categorical variable. Basic graphics include dot plots, histograms density plots, rugs raw data. can produce one graph level factor.Scatterplots good option observations get overlaid. multiple workarounds, involving transparency, bubble plots discrete data ties, adding noise (jitter) every observation drawing values using thin line data continuous.Journals plagued poor visualisations, prime example infamous dynamite plot: consists bar plot one standard error interval. problem (summary statistics) hide precious information spread values taken data, many different data give rise average quite different nature. height bar sample average bars extend beyond one standard error: makes little sense end comparing areas, whereas mean single number. right panel Figure 3.3 shows instead dot plot data, .e., sample values ties stacked clarity, along sample average 95% confidence interval latter line underneath. example, enough observations per group produce histograms: summary nine numbers isn’t really needed. Weissgerber et al. (2015) discusses alternative solutions can referenced fighting reviewers insist bad visualizations.lot data, sometimes help represent selected summary statistics group data. box--whiskers plot (boxplot) commonly used graphic representing whole data distribution using five numbersThe box gives quartiles, say \\(q_1\\), \\(q_2\\) (median) \\(q_3\\) distribution: 50% observations smaller larger \\(q_2\\), 25% smaller \\(q_1\\) 75% smaller \\(q_3\\) sample.whiskers extend \\(1.5\\) times box width (\\(q_3-q_1\\)) (largest observation smaller \\(q_3+1.5(q_3-q_1)\\), etc.)Observations beyond whiskers represented dots circles, sometimes termed outliers. However, beware terminology: larger sample size, values fall outside whiskers (0.7% normal data). drawback boxplots, conceived time big data didn’t exist. want combine boxplots raw data, remove display outliers avoid artefacts.\nFigure 3.4: Box--whiskers plot\nWeissgerber et al. (2019) contains many examples build effective visualizations, including highlighting particular aspects using color, jittering, transparency adequately select display zone.","code":""},{"path":"CRT.html","id":"pairwise-tests","chapter":"3 Completely randomized designs","heading":"3.3 Pairwise tests","text":"global test equality mean one-way ANOVA leads rejection null, conclusion one group different mean. However, test indicate groups differ rest say many different. different options: one custom contrasts, special instance pairwise comparisons.interested looking difference (population) average group \\(\\) \\(j\\), say. null hypothesis difference translate \\(\\mu_i-\\mu_j=0\\), numerator statistic estimator \\(\\widehat{\\mu}_i - \\widehat{\\mu}_j\\) difference sample mean, minus zero.Assuming equal variances, two-sample \\(t\\)-test statistic \n\\[\\begin{align*}\nt_{ij} = \\frac{(\\widehat{\\mu}_i - \\widehat{\\mu}_j) - 0}{\\mathsf{se}(\\widehat{\\mu}_i - \\widehat{\\mu}_j)} =\\frac{\\widehat{\\mu}_i - \\widehat{\\mu}_j}{\\widehat{\\sigma} \\left(\\frac{1}{n_i} + \\frac{1}{n_j}\\right)^{1/2}},\n\\end{align*}\\]\n\\(\\widehat{\\mu}_i\\) \\(n_i\\) respectively sample average number observations group \\(\\), \\(\\widehat{\\sigma}\\) estimator standard deviation derived using whole sample (assuming equal variance). usual, denominator \\(t_{ij}\\) standard error \\(\\widehat{\\mu}_i - \\widehat{\\mu}_j\\), whose postulated difference zero. can compare value observed statistic Student-\\(t\\) distribution \\(n-K\\) degrees freedom, denoted \\(\\mathsf{St}(n-K)\\). two-sided alternative, reject \\(|t_{ij}| > \\mathfrak{t}_{1-\\alpha/2}\\), \\(\\mathfrak{t}_{1-\\alpha/2}\\) \\(1-\\alpha/2\\) quantile \\(\\mathsf{St}(n-K)\\).Figure 3.5 shows density benchmark distribution pairwise comparisons mean arithmetic data. blue area curve defines set values fail reject null hypothesis, whereas values test statistic falling red area lead rejection level \\(5\\)%.\nFigure 3.5: Student-t null distribution rejection region t-test.\nfail reject \\(\\mathscr{H}_0\\) \\(\\mathfrak{t}_{\\alpha/2} \\leq t_{ij} \\leq \\mathfrak{t}_{1-\\alpha/2}\\)18: gives us another way presenting conclusion terms set mean differences \\(\\delta_{ij} = \\mu_i - \\mu_j\\) \n\\[\\begin{align*}\n\\mathfrak{t}_{\\alpha/2} \\leq \\frac{\\widehat{\\delta}_{ij} - \\delta_{ij}}{\\mathsf{se}\\left(\\widehat{\\delta}_{ij}\\right)} \\leq \\mathfrak{t}_{1-\\alpha/2}\n\\end{align*}\\]\nequivalent upon rearranging \\((1-\\alpha)\\) confidence interval \\(\\delta\\),\n\\[\\begin{align*}\n\\mathsf{CI} = \\left[\\widehat{\\delta}_{ij} + \\mathfrak{t}_{\\alpha/2}\\mathsf{se}\\left(\\widehat{\\delta}_{ij}\\right), \\widehat{\\delta}_{ij} + \\mathfrak{t}_{1-\\alpha/2}\\mathsf{se}\\left(\\widehat{\\delta}_{ij}\\right)\\right].\n\\end{align*}\\]Example 3.2  (Pairwise comparison) consider pairwise average difference scores praised (group C) reproved (group D) arithmetic study. sample averages respectively \\(\\widehat{\\mu}_C = 27.4\\) \\(\\widehat{\\mu}_D = 23.4\\) estimated pooled standard deviation five groups \\(1.15\\). Thus, estimated average difference groups \\(C\\) \\(D\\) \\(\\widehat{\\delta}_{CD} = 4\\) standard error difference \\(\\mathsf{se}(\\widehat{\\delta}_{CD}) = 1.6216\\); calculated software.take null hypothesis \\(\\mathscr{H}_0: \\delta_{CD}=0\\), \\(t\\) statistic \n\\[\\begin{align*}t=\\frac{\\widehat{\\delta}_{CD} - 0}{\\mathsf{se}(\\widehat{\\delta}_{CD})} = \\frac{4}{1.6216}=2.467\n\\end{align*}\\]\n\\(p\\)-value \\(p=0.018\\). therefore reject null hypothesis level \\(\\alpha=0.05\\) conclude significant difference (level \\(\\alpha=0.05\\)) average scores students praised reproved.","code":""},{"path":"CRT.html","id":"model-assumptions","chapter":"3 Completely randomized designs","heading":"3.4 Model assumptions","text":"far, brushed model assumptions carpet. necessary requirements inference valid: statement related p-values, etc. approximately hold set assumptions met first place. section devoted discussion assumptions, showcasing examples things can go wrong.basic assumption designs can decompose outcome two components (Cox 1958)\n\\[\\begin{align}\n\\begin{pmatrix} \\text{quantity depending} \\\\\n\\text{treatment used}\\end{pmatrix} +\n\\begin{pmatrix} \\text{quantity depending } \\\\\n\\text{particular unit}\n\\end{pmatrix}\n\\tag{3.2}\n\\end{align}\\]\nadditive decomposition assumes unit unaffected treatment units average effect treatment constant. Thus, justified use difference sample mean estimate treatment effect since average, individual effect zero.customary write \\(\\)th observation \\(k\\)th group one-way analysis variance model \n\\(Y_{ik} = \\mu_k + \\varepsilon_{ik}\\),\nerror term, accounts unexplained variability individual differences, mean zero variance \\(\\sigma^2\\). Many graphical diagnostics use residuals, .e., variant observations minus group mean \\(y_{ik} - \\widehat{\\mu}_k\\), look violation assumptions.\nFigure 3.6: Data satisfying assumptions one-way analysis variance model, additive effects, independent observations common variance.\ngenerally, test statistic may make assumptions. \\(F\\)-test global null \\(\\mu_1 = \\cdots \\mu_K\\) assumes \\(\\)th observation group \\(k\\), say \\(y_{ik}\\), average \\(\\mathsf{E}(Y_{ik}) = \\mu_k\\) variance \\(\\mathsf{Va}(Y_{ik}) = \\sigma^2\\). latter estimated using residuals, \\(\\widehat{\\sigma}^2 = \\sum_k\\sum_i (y_{ik} - \\widehat{\\mu}_k)^2/(n-K)\\). assumptions, \\(F\\)-test statistic global null \\(\\mu_1 = \\cdots = \\mu_K\\) powerful uses data get precise estimation variability. Generally, may considerations power may guide choice test statistic, including robustness (sensitivity extremes outliers). unequal variance, statistics \\(F\\)-test statistic may powerful.","code":""},{"path":"CRT.html","id":"additivity","chapter":"3 Completely randomized designs","heading":"3.4.1 Additivity","text":"Example 3.3  (Additivity transformations) Chapter 2 Cox (1958) discusses assumption additivity provides useful examples showing taken granted. One , Example 2.3, scenario experimental units participants asked provide ranking different kindergarden students capacity interact others games, ranked scale 0 100. random group students receives additional orthopedagogical support, balance business--usual setting (control group). Since intrinsic differences student level, one consider paired experiment take outcome difference sociability scores beginning end school year.One can expect treatment impact people low sociability skills struggling make contacts: student scored 50 initially might see improvement 20 points support relative 10 business--usual scenario, whereas another well integrated scored high initially may see improvement 5 (s)assigned support group. implies treatment effects constant scale, violation additivity assumption. One way deal via transformations: Cox (1958) discusses transformation \\(\\log\\{(x+0.5)/(50-x)\\}\\) reduce warping due scale.Another example experiments effect treatment multiplicative, output form\n\\[\\begin{align*}\n\\begin{pmatrix} \\text{quantity depending } \\\\\n\\text{particular unit}\n\\end{pmatrix} \\times\n\\begin{pmatrix} \\text{quantity depending} \\\\\n\\text{treatment used}\\end{pmatrix}\n\\end{align*}\\]\nUsually, arises positive responses treatments, case taking natural logarithms sides, \\(\\log(xy) = \\log x + \\log y\\) yielding additive decomposition.Example 3.4  (Inadequacy additivity based context) example adapted Cox (1958), Example 2.2. Children suffering attention deficit hyperactivity disorder (ADHD) may receive medication increase attention span, measured scale 0 100, 0 indicating normal attention span. experiment can designed assess impact standardized dose laboratory comparing performances students series task , placebo. make case, suppose students ADHD fall two categories: low symptoms strong symptoms. low symptom group, average attention 8 per cent drug 12 per cent placebo, whereas people strong symptoms, average 40 per cent among treated 60 per cent placebo. two categories equally represented experiment population, estimate average reduction 12 percent score (thus higher attention span among treated). Yet, quantity artificial, better measure symptoms treatment 2/3 control (ratio proportions).Equation (3.2) also implies effect treatment constant individuals. often isn’t case: experimental study impact teaching delivery type (online, hybrid, person), may response choice delivery mode depends different preferences learning types (auditory, visual, kinestetic, etc.) Thus, recording additional measurements susceptible interact may useful; likewise, treatment allotment must factor variability wish make detectable. solution setup complex model (two-way analysis variance, general linear model) stratify explanatory variable (example, compute difference within level).\nFigure 3.7: Difference average response; treatment seems lead decrease response variable, stratification age group reveals occurs less 25 group, seemingly reversed effect adults. Thus, marginal model implied one-way analysis variance misleading.\n","code":""},{"path":"CRT.html","id":"heterogeneity","chapter":"3 Completely randomized designs","heading":"3.4.2 Heterogeneity","text":"one-way ANOVA builds fact variance group equal, upon recentering, can estimate variance residuals \\(y_{ik} - \\widehat{\\mu}_k\\). Specifically, unbiased variance estimator denominator \\(F\\)-statistic formula, .e., within sum squares divided \\(n-K\\) \\(n\\) total number observations \\(K\\) number groups comparison.time , consider hypothesis tests homogeneity (equal) variance assumption. commonly used tests Bartlett’s test19 Levene’s test (robust alternative, less sensitive outliers). tests, null distribution \\(\\mathscr{H}_0: \\sigma^2_1 = \\cdots = \\sigma^2_K\\) alternative least two differ. Bartlett test statistic \\(\\chi^2\\) null distribution \\(K-1\\) degrees freedom, whereas Levene’s test \\(F\\)-distribution (\\(K\\), \\(n-K\\)) degrees freedom: equivalent computing one-way ANOVA \\(F\\)-statistic absolute value centered residuals, \\(|y_{ik} - \\widehat{\\mu}_k|\\), observations.can see cases \\(p\\)-values large enough dismiss concern inequality variance. However, latter problem, can proceed test statistic require variances equal. common choice modification due Satterthwaite called Welch’s ANOVA. commonly encountered case two groups (\\(K=2\\)) default option R t.test oneway.test (option var.equal = TRUE).happens example arithmetic data use instead usual \\(F\\) statistic? , evidence overwhelming changes conclusion. Generally, drawback using Welch’s ANOVA usual need enough observations group reliably estimate separate variance20. Welch’s ANOVA, estimate \\(2K\\) parameters (one mean one variance per group), rather \\(K+1\\) parameters one-way ANOVA (one mean per group, one overall variance).Notice degrees freedom denominator decreased. use pairwise.t.test argument pool.sd=FALSE, amounts running Welch \\(t\\)-tests separately pair variable.impacts unequal variance use \\(F\\)-test instead? one, pooled variance based weighted average variance group, weight function sample size. can lead size distortion (meaning proportion type error nominal level \\(\\alpha\\) claimed) potential loss power. following toy example illustrates .\nFigure 3.8: Histogram null distribution \\(p\\)-values obtained simulation using classical analysis variance \\(F\\)-test (left) Welch’s unequal variance alternative (right), based 10 000 simulations. simulated sample consist 50 observations \\(\\mathsf{}(0, 1)\\) distribution 10 observations \\(\\mathsf{}(0, 9)\\). uniform distribution 5% 20 bins used display.\nconsider simplicity problem \\(K=2\\) groups, two-sample \\(t\\)-test. simulated 50 observations \\(\\mathsf{}(0, 1)\\) distribution 10 observations \\(\\mathsf{}(0, 9)\\), comparing distribution \\(p\\)-values Welch \\(F\\)-test statistics. Figure 3.8 shows results. percentage \\(p\\)-values less \\(\\alpha=0.05\\) based 10 000 replicates estimated 4.76% Welch statistic, far level. contrast, reject 28.95% time one-way ANOVA global \\(F\\)-test: large share innocents sentenced jail based false premises! size distortion always striking, heterogeneity accounted design requiring sufficient sample sizes (whenever costs permits) group able estimate variance reliably using adequate statistic.alternative graphical ways checking assumption equal variance, many including standardized residuals \\(r_{ik} = (y_{ik} - \\widehat{\\mu}_k)/\\widehat{\\sigma}\\) fitted values \\(\\widehat{\\mu}_k\\). cover later sections.","code":"\nbartlett.test(score ~ group,\n              data = arithmetic)\n#> \n#>  Bartlett test of homogeneity of variances\n#> \n#> data:  score by group\n#> Bartlett's K-squared = 2, df = 4, p-value = 0.7\n\ncar::leveneTest(score ~ group,\n                data = arithmetic,\n                center = mean)\n#> Levene's Test for Homogeneity of Variance (center = mean)\n#>       Df F value Pr(>F)\n#> group  4    1.57    0.2\n#>       40\n# compare with one-way ANOVA\nmod <- lm(score ~ group, data = arithmetic)\narithmetic$absresid <- abs(resid(mod)) #|y_{ik}-mean_k|\noneway.test(absresid ~ group, \n            data = arithmetic,\n            var.equal = TRUE)\n#> \n#>  One-way analysis of means\n#> \n#> data:  absresid and group\n#> F = 2, num df = 4, denom df = 40, p-value = 0.2\n# Welch ANOVA\noneway.test(score ~ group, data = arithmetic, \n            var.equal = FALSE)\n#> \n#>  One-way analysis of means (not assuming equal variances)\n#> \n#> data:  score and group\n#> F = 19, num df = 4, denom df = 20, p-value = 2e-06\n# Usual F-test statistic\noneway.test(score ~ group, data = arithmetic, \n            var.equal = TRUE)\n#> \n#>  One-way analysis of means\n#> \n#> data:  score and group\n#> F = 15, num df = 4, denom df = 40, p-value = 1e-07"},{"path":"CRT.html","id":"normality","chapter":"3 Completely randomized designs","heading":"3.4.3 Normality","text":"persistent yet incorrect claim literature data (either response, explanatory ) must normal order use (-called parameter) statistical tests like one-way analysis variable \\(F\\)-test. normal data equal variances, eponymous distributions \\(F\\) \\(t\\) tests exact: knowing exact distribution due harm convenient mathematical derivations. However, condition **unnecessary: results hold approximately large samples central limit theorem. probability results dictates , general conditions nearly universally met, sample mean behaves like normal distribution large samples. applet lets explore impact underlying population data drawn interplay sample size central limit theorem kicks . can view Figure 3.2, simulated theoretical large-sample distributions undistinguishable approximately 20 observations per group.many authors may advocate rules thumbs (sample size \\(n>20\\) \\(n>30\\) per group, say), rules arbitrary: approximation much worst \\(n=19\\) \\(n=20\\). large must sample size approximation hold? largely depends distribution population: extremes, skewness, etc. , larger number observation must order approximation valid. Figure 3.9 shows skewed right bimodal distribution distribution sample mean repeated sampling. Even \\(n=5\\) observations (bottom left), approximation bad may still far \\(n=50\\) heavy-tailed data.\nFigure 3.9: Graphical representation central limit theorem. Top left: density underlying population samples drawn. Top right: sample 20 observations sample mean (vertical red). Bottom panels: histogram sample averages samples size 5 (left) 20 (right) normal approximation superimposed. sample size increases, normal approximation mean accurate standard error decreases.\nimportant keep mind statistical statements typically approximate reliability depends sample size: small sample may hampers strength conclusions. default graphic checking whether sample matches postulated distribution quantile-quantile plot.","code":""},{"path":"CRT.html","id":"independence","chapter":"3 Completely randomized designs","heading":"3.4.4 Independence","text":"allowed talk independence Quebecer21, simply means knowing value one observation tells us nothing value sample. Independence may fail hold case group structure (family dyads, cluster sampling) common characteristics simply case repeated measurements. Random assignment treatment thus key ensure measure holds, ensuring measurement phase spillover.Example 3.6  (Independence measurements) many hidden ways measurements can impact response. Physical devices need calibrated use (scales, microscope) require tuning: measurements done different experimenters different days, may impact add systematic shift means whole batch.Special care must taken whenever group testing used, blocking potential impacts can salvage analysis.impact dependence measurements? Heuristically, correlated measurements carry less information independent ones. extreme case, additional information measurements identical. reason makes difference following: denominator \\(F\\)-test sample variance, based within sum squares divided \\(n-K\\). observation counted 10 times, say, real number measurements \\(n\\) \\(F\\) statistic gets multiplied factor 10.22\nFigure 3.10: Size \\(F\\)-test equality means one way ANOVA data equicorrelation model (within group observations correlated, group observations independent). nominal level test 5%.\nlack independence can also drastic consequences inference lead false conclusions: Figure 3.10 shows example correlated samples within group (equivalently repeated measurements individuals) 25 observations per group. \\(y\\)-axis shows size test, meaning proportion times null rejected. , since data generated null model (equal mean) equal variance, inflation number spurious discoveries, false alarm type error alarming inflation substantial even limited correlation measurements.","code":""},{"path":"replication-crisis.html","id":"replication-crisis","chapter":"4 Replication crisis","heading":"4 Replication crisis","text":"recent years, many team efforts performed -called replications existing methodological papers assess robustness findings. Perhaps unsurprisingly, many replications failed yield anything like authors used claim, found much weaker findings. chapter examines causes lack replicability.Defining replicability reproducibility.Understanding scale replication crisis.Recognizing common statistical fallacies.Listing strategies enhancing reproducibility.adopt terminology Claerbout Karrenbach (1992): study said reproducible external person data enough indications procedure (example, code software versions, etc.) can obtain consistent results match paper. related scientific matter replicability, process new data collected test hypothesis, potentially using different methodology. Reproducibility important enhances credibility one’s work. Extensions deal different analyses leading conclusion described Turing Way presented 4.1.\nFigure 4.1: Definition different dimensions reproducible research (Turing Way project, illustration Scriberia).\nreproducibility replicability important? thought provoking paper, Ioannidis (2005) claimed research findings wrong. abstract paper statedThere increasing concern current published research findings false. […] framework, research finding less likely true studies conducted field smaller; effect sizes smaller; greater number lesser preselection tested relationships; greater flexibility designs, definitions, outcomes, analytical modes; greater financial interest prejudice; teams involved scientific field chase statistical significance.Since publication, collaborative efforts tried assess scale problem reanalysing data trying replicate findings published research. example, “Reproducibility [sic] Project: Psychology” (Nosek et al. 2015)conducted replications 100 experimental correlational studies published three psychology journals using high powered designs original materials available. Replication effects half magnitude original effects, representing substantial decline. Ninety seven percent original studies significant results. Thirty six percent replications significant results; 47% original effect sizes 95% confidence interval replication effect size; 39% effects subjectively rated replicated original result; , bias original results assumed, combining original replication results left 68% significant effects. […]large share findings review replicable effects much smaller claimed, shown Figure 2 study.\nfindings show peer-review procedure foolproof: “publish--perish” mindset academia leading many researchers try achieve statistical significance costs meet 5% level criterion, whether involuntarily . problem many names: \\(p\\)-hacking, harking paraphrase story Jorge Luis Borges, garden forking paths. many degrees freedom analysis researchers refine hypothesis viewing data, conducting many unplanned comparisons reporting selected results.\nFigure 4.2: Figure 2 Nosek et al. (2015), showing scatterplot effect sizes original replication study power, rugs density plots significance 5% level.\nAnother problem selective reporting. large emphasis placed statistical significance, many studies find small effects never published, resulting gap. Figure 4.3 Zwet Cator (2021) shows \\(z\\)-scores obtained transforming confidence intervals reported Barnett Wren (2019). authors used data mining techniques extract confidence intervals abstracts nearly one million publication Medline published 1976 2019. experiments yielded effect due natural variability, \\(z\\)-scores normally distributed, Figure 4.3 shows big gap bell curve approximately \\(-2\\) \\(2\\), indicative selective reporting. fact results lead \\(p < 0.05\\) published called file-drawer problem.\nFigure 4.3: Figure Zwet Cator (2021) based results Barnett Wren (2019); histogram \\(z\\)-scores one million studies Medline.\nongoing debate surrounding reproducibility crisis sparked dramatic changes academic landscape: enhance quality studies published, many journal now require authors provide code data, pre-register studies, etc. Teams lead effort (e.g., Experimental Economics Replication Project) try replicate studies, mitigated success far. inside recollection graduate student shows extent problem.course place strong emphasis identifying avoiding statistical fallacies showcasing methods enhance reproducibility. can reproducible research enhance work? one thing, workflow facilitates publication negative research, forces researchers think ahead time (receive feedback). Reproducible research data availability also leads additional citations increased credibility scientist.Among good practices arepre-registration experiments use logbook.clear reporting key aspects experiment (choice metric, number items Likert scale, etc.)version control systems (e.g., Git) track changes files records.archival raw data proper format accompanying documentation.Keeping logbook documenting progress helps collaborators, reviewers future-self understand decisions may seem unclear arbitrary future, even result careful thought process time made . Given pervasiveness garden forking paths, pre-registration helps prevents harking limits selective reporting unplanned tests, panacea. Critics often object pre-registration claiming binds people. misleading claim view: pre-registration doesn’t mean must stick plan exactly, merely requires explain go planned anything.Version control keeps records changes file can help retrieve former versions make mistakes point.\nFigure 4.4: Tweet showing widespread problems related unintentional changes raw data software.\nArchival data helps avoid unintentional irreversible manipulations original data, examples can large scale consequences illustrated Figure 4.4 (Ziemann El-Osta 2016), report flaws genetic journals due automatic conversion gene names dates Excel. problems far unique. sensitive data shared “” confidentiality issues, many instances data can made available licence DOI allow people reuse , cite credit work.enforce reproducibility, many journals now policy regarding data, material code availability. journals encourage , trend recent years enforce. example, Nature require following reported published papers:\nFigure 4.5: Screenshot Nature Reporting summary statistics, reproduced CC 4.0 license.\nOperating open-science environment seen opportunity make better science, offer opportunities increase impact increase likelihood work gets published regardless whether results turn negative. right thing increases quality research produced, collateral benefits forces researchers validate methodology , double-check data analysis adopt good practice.Reflect workflow applied researcher designing undertaking experiments. practical aspects improve upon improve reproducibility study?","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
